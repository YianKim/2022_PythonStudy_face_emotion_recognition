{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YianKim/2022_PythonStudy_face_emotion_recognition/blob/main/v2_Emotion_Recognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5FQpjWg4Ld6m"
      },
      "source": [
        "## 구글 드라이브\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SyTEuhg7fR9P",
        "outputId": "1560c4c7-b924-4d4c-fddd-800e4ae1708f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UQy7KUb6NBs-"
      },
      "source": [
        "## 라이브러리 불러오기\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "XRPQRtXGmm2W"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import PIL\n",
        "import pickle\n",
        "import random\n",
        "\n",
        "from keras.layers.core import Lambda\n",
        "from keras import backend as K\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.regularizers import l2\n",
        "from keras.layers import Activation\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Reshape\n",
        "from keras.layers import LSTM\n",
        "from keras import optimizers\n",
        "from keras.callbacks import ReduceLROnPlateau, EarlyStopping, TensorBoard, ModelCheckpoint\n",
        "from sklearn.metrics import accuracy_score\n",
        "from keras.models import load_model\n",
        "\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xpAjYytuPDaU"
      },
      "source": [
        "## 데이터 불러오기\n",
        "\n",
        "FER2013.csv : 35887 images\n",
        "\n",
        "![Dataset overview](https://i.imgur.com/vqlEXw2.png) \n",
        "\n",
        "48*48 이미지. value 0~255\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "H2XHQzzzrRyF"
      },
      "outputs": [],
      "source": [
        "def load_data(dataset_path):\n",
        "  \n",
        "  #classes = ['Angry', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprsie', 'Neutral']\n",
        "\n",
        "  data = []\n",
        "  test_data = []\n",
        "  test_labels = []\n",
        "  labels =[]\n",
        "\n",
        "  with open(dataset_path, 'r') as file:\n",
        "      for line_no, line in enumerate(file.readlines()):\n",
        "          if 0 < line_no <= 35887:\n",
        "            curr_class, line, set_type = line.split(',')\n",
        "            image_data = np.asarray([int(x) for x in line.split()]).reshape(48, 48)\n",
        "            image_data =image_data.astype(np.uint8)/255.0\n",
        "\n",
        "            if (set_type.strip() == 'PrivateTest'):\n",
        "              \n",
        "              test_data.append(image_data)\n",
        "              test_labels.append(curr_class)\n",
        "            else:\n",
        "              data.append(image_data)\n",
        "              labels.append(curr_class)\n",
        "      \n",
        "      test_data = np.expand_dims(test_data, -1)\n",
        "      test_labels = to_categorical(test_labels, num_classes = 7)\n",
        "      data = np.expand_dims(data, -1)   \n",
        "      labels = to_categorical(labels, num_classes = 7)\n",
        "    \n",
        "      return np.array(data), np.array(labels), np.array(test_data), np.array(test_labels)\n",
        "\n",
        "dataset_path = \"/content/drive/MyDrive/파이썬스터디 프로젝트/fer2013.csv/fer2013.csv\"\n",
        "train_data, train_labels, test_data, test_labels = load_data(dataset_path)\n",
        "#train_data, test_data, train_labels, test_labels = train_test_split(data, labels, test_size = test_size,random_state = seed)\n",
        "\n",
        "#평가용\n",
        "test_labels2 = np.argmax(test_labels, axis=1)\n",
        "\n",
        "# print(\"Number of images in Training set:\", len(train_data))\n",
        "# print(\"Number of images in Test set:\", len(test_data))\n",
        "\n",
        "with open('/content/drive/MyDrive/파이썬스터디 프로젝트/aug_array1.pkl', 'rb') as f:\n",
        "\taug_array1 = pickle.load(f)\n",
        " \n",
        "train_data_aug = np.concatenate((train_data, aug_array1), axis=0)\n",
        "train_labels_aug = np.concatenate((train_labels, train_labels), axis=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CNN v2.\n",
        "\n",
        "A. Vulpe-Grigoraşi and O. Grigore, \"Convolutional Neural Network Hyperparameters optimization for Facial Emotion Recognition,\" 2021 12th International Symposium on Advanced Topics in Electrical Engineering (ATEE), 2021, pp. 1-5, doi: 10.1109/ATEE52255.2021.9425073."
      ],
      "metadata": {
        "id": "Sa7KYMfrkKU5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# def PermaDropout(rate):\n",
        "#     return Lambda(lambda x: K.dropout(x, level=rate))"
      ],
      "metadata": {
        "id": "zn3v_W8wJQ68"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# #######HYPERPARAMATERS###########\n",
        "# epochs = 30\n",
        "# batch_size = 64\n",
        "# learning_rate = 0.001\n",
        "# #################################\n",
        "  \n",
        "# model = Sequential()\n",
        "    \n",
        "# model.add(Conv2D(256, (3, 3), activation='relu', input_shape=(48, 48, 1), kernel_regularizer=l2(0.01)))\n",
        "# model.add(Conv2D(512, (3, 3), padding='same', activation='relu'))\n",
        "# model.add(BatchNormalization())\n",
        "# model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "# model.add(PermaDropout(0.4))\n",
        "\n",
        "# model.add(Conv2D(384, (3, 3), padding='same', activation='relu'))\n",
        "# model.add(BatchNormalization())\n",
        "# model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "# model.add(PermaDropout(0.4))\n",
        "\n",
        "# model.add(Conv2D(192, (3, 3), padding='same', activation='relu'))\n",
        "# model.add(BatchNormalization())\n",
        "# model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "# model.add(PermaDropout(0.4))\n",
        "\n",
        "# model.add(Conv2D(384, (3, 3), padding='same', activation='relu'))\n",
        "# model.add(BatchNormalization())\n",
        "# model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "# model.add(PermaDropout(0.4))\n",
        "\n",
        "# model.add(Flatten())\n",
        "# model.add(Dense(256, activation='relu'))\n",
        "# model.add(BatchNormalization())\n",
        "# model.add(PermaDropout(0.3))\n",
        "# model.add(Dense(7, activation='softmax'))\n",
        "\n",
        "# adam = keras.optimizers.Adam(learning_rate)\n",
        "# model.compile(optimizer = adam, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
        "    \n",
        "# # print(model.summary())\n",
        "\n",
        "# lr_reducer = ReduceLROnPlateau(monitor='val_loss', factor=0.9, patience=3)\n",
        "# early_stopper = EarlyStopping(monitor='val_accuracy', min_delta=0, patience=30, mode='auto')\n",
        "# checkpointer = ModelCheckpoint('weights.hd5', monitor='val_loss', verbose=1, save_best_only=True)\n",
        "\n",
        "# model.fit(\n",
        "#           train_data_aug,\n",
        "#           train_labels_aug,\n",
        "#           epochs = epochs,\n",
        "#           batch_size = batch_size,\n",
        "#           validation_split = 0.3,\n",
        "#           shuffle = True,\n",
        "# #           callbacks=[lr_reducer, checkpointer, early_stopper]\n",
        "#           callbacks=[lr_reducer, early_stopper]\n",
        "#           )"
      ],
      "metadata": {
        "id": "L5scE9yKkIZb"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model.save('/content/drive/MyDrive/파이썬스터디 프로젝트/cnn_base_model_v2.h5')"
      ],
      "metadata": {
        "id": "LVOc3hYIkXrl"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model = keras.models.load_model('/content/drive/MyDrive/파이썬스터디 프로젝트/cnn_base_model_v2.h5')"
      ],
      "metadata": {
        "id": "n5D8i_BCkdjS"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TD8ppILhFUrz"
      },
      "source": [
        "## 모델 결과\n",
        "\n",
        "CNN\n",
        "1. no augmentation : 62~63%\n",
        "2. 2x augmentation : 67~68%\n",
        "3. 4x augmentation : 67~68%\n",
        "\n",
        "CNN v2 with MC Dropout, 30 times\n",
        "1. 2x augmentation : 67~68%"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def model_eval():\n",
        "  pred_mu = model.predict(test_data)\n",
        "  for i in range(1, 30):\n",
        "    pred_mu += model.predict(test_data)\n",
        "  pred_mu = pred_mu/30\n",
        "  predicted_test_labels = np.argmax(pred_mu, axis=1)\n",
        "  return(accuracy_score(test_labels2, predicted_test_labels))"
      ],
      "metadata": {
        "id": "7Ljx2EWA2v2n"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "OzhQw9NOWjl3"
      },
      "outputs": [],
      "source": [
        "# model = keras.models.load_model('/content/drive/MyDrive/파이썬스터디 프로젝트/cnn_base_model_v2.h5')\n",
        "# model_eval()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B9MfwvYALW8x"
      },
      "source": [
        "## 준지도 pseudo labeling (self train)\n",
        "\n",
        "모델성능이 70% 미만 -> 틀렸을 가능성이 높은 데이터들은 사용 X (최대한 70% 안에 있는 것을 맞춰서 사용)\n",
        "\n",
        "수 회 예측결과의 분산이 작은 이미지일수록 기존 데이터셋(labeled)과 비슷하고, 분산이 클 수록 새로운 이미지일까?"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "dataselection 함수\n",
        "\n",
        "1. model과 data_no_label을 받고\n",
        "\n",
        "2. uncertainty에 따라 그룹을 나눠주는 함수"
      ],
      "metadata": {
        "id": "-FaArGPM5PQF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def dataselection(cutoff):\n",
        "\n",
        "  # predict\n",
        "  pred1 = model.predict(data_no_label)\n",
        "  pred2 = model.predict(data_no_label)\n",
        "  pred3 = model.predict(data_no_label)\n",
        "  pred4 = model.predict(data_no_label)\n",
        "  pred5 = model.predict(data_no_label)\n",
        "  pred6 = model.predict(data_no_label)\n",
        "  pred7 = model.predict(data_no_label)\n",
        "  pred8 = model.predict(data_no_label)\n",
        "  pred9 = model.predict(data_no_label)\n",
        "  pred10 = model.predict(data_no_label)\n",
        "  pred_mu = (pred1+pred2+pred3+pred4+pred5+pred6+pred7+pred8+pred9+pred10)/10\n",
        "  pred_var=[]\n",
        "\n",
        "  for i in range(data_no_label.shape[0]):\n",
        "    temp = np.max(list(pred_mu[i]))\n",
        "    temp = list(pred_mu[i]).index(temp)\n",
        "    pred_var.append(np.var([pred1[i][temp],pred2[i][temp],pred3[i][temp],pred4[i][temp],pred5[i][temp],\n",
        "                            pred6[i][temp],pred7[i][temp],pred8[i][temp],pred9[i][temp],pred10[i][temp]]))\n",
        "  \n",
        "  group_a = []\n",
        "  group_a_label = []\n",
        "  group_b = []\n",
        "  group_b_label = []\n",
        "\n",
        "  var_25 = np.percentile(pred_var,cutoff)\n",
        "  for i in range(len(pred_var)):\n",
        "    if pred_var[i] < var_25:\n",
        "      group_a.append(i)\n",
        "      group_a_label.append(list(pred_mu[i]).index(np.max(list(pred_mu[i]))))\n",
        "    else:\n",
        "      group_b.append(i)\n",
        "      group_b_label.append(list(pred_mu[i]).index(np.max(list(pred_mu[i]))))\n",
        "\n",
        "  a_train = data_no_label[group_a]\n",
        "  b_train = data_no_label[group_b]\n",
        "  a_label = []\n",
        "  b_label = []\n",
        "\n",
        "  for i in group_a_label:\n",
        "    temp = [0,0,0,0,0,0,0]\n",
        "    temp[i] = 1\n",
        "    a_label.append(temp)\n",
        "  for i in group_b_label:\n",
        "    temp = [0,0,0,0,0,0,0]\n",
        "    temp[i] = 1\n",
        "    b_label.append(temp)\n",
        "\n",
        "  a_label = np.array(a_label)\n",
        "  b_label = np.array(b_label)\n",
        "\n",
        "  return(a_train, a_label, b_train, b_label)"
      ],
      "metadata": {
        "id": "7t0bwmvA3Akj"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1\n"
      ],
      "metadata": {
        "id": "fX2A4ATHM8mS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# with open('/content/drive/MyDrive/파이썬스터디 프로젝트/face_array.pkl', 'rb') as f:\n",
        "# \tdata_no_label = pickle.load(f)\n",
        "# model = keras.models.load_model('/content/drive/MyDrive/파이썬스터디 프로젝트/cnn_base_model_v2.h5')"
      ],
      "metadata": {
        "id": "H-4aNkdbwfAf"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# a_train, a_label, b_train, b_label = dataselection(25)\n",
        "\n",
        "# with open('/content/drive/MyDrive/파이썬스터디 프로젝트/a_train2.pkl', 'wb') as f:\n",
        "#   pickle.dump(a_train, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "# with open('/content/drive/MyDrive/파이썬스터디 프로젝트/a_label2.pkl', 'wb') as f:\n",
        "#   pickle.dump(a_label, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "# with open('/content/drive/MyDrive/파이썬스터디 프로젝트/b_train2.pkl', 'wb') as f:\n",
        "#   pickle.dump(b_train, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "# with open('/content/drive/MyDrive/파이썬스터디 프로젝트/b_label2.pkl', 'wb') as f:\n",
        "#   pickle.dump(b_label, f, protocol=pickle.HIGHEST_PROTOCOL)"
      ],
      "metadata": {
        "id": "eBed2AL2iXda"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/drive/MyDrive/파이썬스터디 프로젝트/a_train2.pkl', 'rb') as f:\n",
        "\ta_train = pickle.load(f)\n",
        " \n",
        "with open('/content/drive/MyDrive/파이썬스터디 프로젝트/a_label2.pkl', 'rb') as f:\n",
        "\ta_label = pickle.load(f)\n",
        " \n",
        "with open('/content/drive/MyDrive/파이썬스터디 프로젝트/b_train2.pkl', 'rb') as f:\n",
        "\tb_train = pickle.load(f)\n",
        " \n",
        "with open('/content/drive/MyDrive/파이썬스터디 프로젝트/b_label2.pkl', 'rb') as f:\n",
        "\tb_label = pickle.load(f)"
      ],
      "metadata": {
        "id": "T7kDb_kQiXuc"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a_train = np.concatenate((train_data_aug, a_train), 0)\n",
        "a_label = np.concatenate((train_labels_aug, a_label), 0)"
      ],
      "metadata": {
        "id": "DzgcJnQiQRLO"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model = keras.models.load_model('/content/drive/MyDrive/파이썬스터디 프로젝트/cnn_base_model_v2.h5')\n",
        "\n",
        "# #######HYPERPARAMATERS###########\n",
        "# epochs = 10 #재학습\n",
        "# batch_size = 64\n",
        "# learning_rate = 1e-7 #재학습\n",
        "# #################################\n",
        "\n",
        "# lr_reducer = ReduceLROnPlateau(monitor='val_loss', factor=0.9, patience=3)\n",
        "# early_stopper = EarlyStopping(monitor='val_acc', min_delta=0, patience=6, mode='auto')\n",
        "# checkpointer = ModelCheckpoint('/content/drive/MyDrive/파이썬스터디 프로젝트/Model/weights.hd5', monitor='val_loss', verbose=1, save_best_only=True)\n",
        "\n",
        "# model.fit(\n",
        "#           a_train,\n",
        "#           a_label,\n",
        "#           epochs = epochs,\n",
        "#           batch_size = batch_size,\n",
        "#           # validation_split = 0.5,\n",
        "#           shuffle = True,\n",
        "#           # callbacks=[lr_reducer, checkpointer, early_stopper],\n",
        "#           # class_weight=class_weight\n",
        "#           )"
      ],
      "metadata": {
        "id": "BhIJ-TbzfEgQ"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model.save('/content/drive/MyDrive/파이썬스터디 프로젝트/cnn_220113_model_v2.h5')"
      ],
      "metadata": {
        "id": "MEVm4GRpskds"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "67~68%"
      ],
      "metadata": {
        "id": "_u4HzNR6c2XB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# model = keras.models.load_model('/content/drive/MyDrive/파이썬스터디 프로젝트/cnn_220113_model_v2.h5')\n",
        "# model_eval()"
      ],
      "metadata": {
        "id": "qC5XR37jQ2BN"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2"
      ],
      "metadata": {
        "id": "xkoGfxkjrTvK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# model = keras.models.load_model('/content/drive/MyDrive/파이썬스터디 프로젝트/cnn_220113_model_v2.h5')\n",
        "# data_no_label = b_train"
      ],
      "metadata": {
        "id": "D_u6jE0erRHP"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_aug = a_train\n",
        "train_labels_aug = a_label"
      ],
      "metadata": {
        "id": "8m5LP_V9haik"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# a_train, a_label, b_train, b_label = dataselection(33)\n",
        "\n",
        "# with open('/content/drive/MyDrive/파이썬스터디 프로젝트/a_train3.pkl', 'wb') as f:\n",
        "#   pickle.dump(a_train, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "# with open('/content/drive/MyDrive/파이썬스터디 프로젝트/a_label3.pkl', 'wb') as f:\n",
        "#   pickle.dump(a_label, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "# with open('/content/drive/MyDrive/파이썬스터디 프로젝트/b_train3.pkl', 'wb') as f:\n",
        "#   pickle.dump(b_train, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "# with open('/content/drive/MyDrive/파이썬스터디 프로젝트/b_label3.pkl', 'wb') as f:\n",
        "#   pickle.dump(b_label, f, protocol=pickle.HIGHEST_PROTOCOL)"
      ],
      "metadata": {
        "id": "kC9ql5k8uj2X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/drive/MyDrive/파이썬스터디 프로젝트/a_train3.pkl', 'rb') as f:\n",
        "\ta_train = pickle.load(f)\n",
        " \n",
        "with open('/content/drive/MyDrive/파이썬스터디 프로젝트/a_label3.pkl', 'rb') as f:\n",
        "\ta_label = pickle.load(f)\n",
        " \n",
        "with open('/content/drive/MyDrive/파이썬스터디 프로젝트/b_train3.pkl', 'rb') as f:\n",
        "\tb_train = pickle.load(f)\n",
        " \n",
        "with open('/content/drive/MyDrive/파이썬스터디 프로젝트/b_label3.pkl', 'rb') as f:\n",
        "\tb_label = pickle.load(f)"
      ],
      "metadata": {
        "id": "FI6xnFH3u_fo"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a_train = np.concatenate((train_data_aug, a_train), 0)\n",
        "a_label = np.concatenate((train_labels_aug, a_label), 0)"
      ],
      "metadata": {
        "id": "6VC9-BZBTh1g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model = keras.models.load_model('/content/drive/MyDrive/파이썬스터디 프로젝트/cnn_220113_model_v2.h5')\n",
        "\n",
        "# #######HYPERPARAMATERS###########\n",
        "# epochs = 10 #재학습\n",
        "# batch_size = 64\n",
        "# learning_rate = 0.1**7 #재학습\n",
        "# #################################\n",
        "\n",
        "# lr_reducer = ReduceLROnPlateau(monitor='val_loss', factor=0.9, patience=3)\n",
        "# early_stopper = EarlyStopping(monitor='val_acc', min_delta=0, patience=6, mode='auto')\n",
        "# checkpointer = ModelCheckpoint('/content/drive/MyDrive/파이썬스터디 프로젝트/Model/weights.hd5', monitor='val_loss', verbose=1, save_best_only=True)\n",
        "\n",
        "# model.fit(\n",
        "#           a_train,\n",
        "#           a_label,\n",
        "#           epochs = epochs,\n",
        "#           batch_size = batch_size,\n",
        "#           # validation_split = 0.5,\n",
        "#           shuffle = True,\n",
        "#           # callbacks=[lr_reducer, checkpointer, early_stopper],\n",
        "#           # class_weight=class_weight\n",
        "#           )"
      ],
      "metadata": {
        "id": "rjmSA0qqsenu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model.save('/content/drive/MyDrive/파이썬스터디 프로젝트/cnn_220114_model_v2.h5')"
      ],
      "metadata": {
        "id": "-rcxXsD7spBR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "68~69%"
      ],
      "metadata": {
        "id": "DpJS_a3PcxkM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# model = keras.models.load_model('/content/drive/MyDrive/파이썬스터디 프로젝트/cnn_220114_model_v2.h5')\n",
        "# model_eval()"
      ],
      "metadata": {
        "id": "Enp2PMywst2i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3"
      ],
      "metadata": {
        "id": "1JHdwlOedG6l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# model = keras.models.load_model('/content/drive/MyDrive/파이썬스터디 프로젝트/cnn_220114_model_v2.h5')\n",
        "# data_no_label = b_train"
      ],
      "metadata": {
        "id": "WY10pUhmdG6n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_aug = a_train\n",
        "train_labels_aug = a_label"
      ],
      "metadata": {
        "id": "3zZfdI2dhlHg"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# a_train, a_label, b_train, b_label = dataselection(50)\n",
        "\n",
        "# with open('/content/drive/MyDrive/파이썬스터디 프로젝트/a_train4.pkl', 'wb') as f:\n",
        "#   pickle.dump(a_train, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "# with open('/content/drive/MyDrive/파이썬스터디 프로젝트/a_label4.pkl', 'wb') as f:\n",
        "#   pickle.dump(a_label, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "# with open('/content/drive/MyDrive/파이썬스터디 프로젝트/b_train4.pkl', 'wb') as f:\n",
        "#   pickle.dump(b_train, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "# with open('/content/drive/MyDrive/파이썬스터디 프로젝트/b_label4.pkl', 'wb') as f:\n",
        "#   pickle.dump(b_label, f, protocol=pickle.HIGHEST_PROTOCOL)"
      ],
      "metadata": {
        "id": "ipoaFeUkdG6p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/drive/MyDrive/파이썬스터디 프로젝트/a_train4.pkl', 'rb') as f:\n",
        "\ta_train = pickle.load(f)\n",
        " \n",
        "with open('/content/drive/MyDrive/파이썬스터디 프로젝트/a_label4.pkl', 'rb') as f:\n",
        "\ta_label = pickle.load(f)\n",
        " \n",
        "with open('/content/drive/MyDrive/파이썬스터디 프로젝트/b_train4.pkl', 'rb') as f:\n",
        "\tb_train = pickle.load(f)\n",
        " \n",
        "with open('/content/drive/MyDrive/파이썬스터디 프로젝트/b_label4.pkl', 'rb') as f:\n",
        "\tb_label = pickle.load(f)"
      ],
      "metadata": {
        "id": "ZfWqmUV4dG6p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a_train = np.concatenate((train_data_aug, a_train), 0)\n",
        "a_label = np.concatenate((train_labels_aug, a_label), 0)"
      ],
      "metadata": {
        "id": "i0RDPJYzdG6p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model = keras.models.load_model('/content/drive/MyDrive/파이썬스터디 프로젝트/cnn_220114_model_v2.h5')\n",
        "\n",
        "# #######HYPERPARAMATERS###########\n",
        "# epochs = 10 #재학습\n",
        "# batch_size = 64\n",
        "# learning_rate = 0.1**7 #재학습\n",
        "# #################################\n",
        "\n",
        "# lr_reducer = ReduceLROnPlateau(monitor='val_loss', factor=0.9, patience=3)\n",
        "# early_stopper = EarlyStopping(monitor='val_acc', min_delta=0, patience=6, mode='auto')\n",
        "# checkpointer = ModelCheckpoint('/content/drive/MyDrive/파이썬스터디 프로젝트/Model/weights.hd5', monitor='val_loss', verbose=1, save_best_only=True)\n",
        "\n",
        "# model.fit(\n",
        "#           a_train,\n",
        "#           a_label,\n",
        "#           epochs = epochs,\n",
        "#           batch_size = batch_size,\n",
        "#           # validation_split = 0.5,\n",
        "#           shuffle = True,\n",
        "#           # callbacks=[lr_reducer, checkpointer, early_stopper],\n",
        "#           # class_weight=class_weight\n",
        "#           )"
      ],
      "metadata": {
        "id": "r9dHEuobdG6p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model.save('/content/drive/MyDrive/파이썬스터디 프로젝트/cnn_220115_model_v2.h5')"
      ],
      "metadata": {
        "id": "VxSqUxNhdG6q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "67~68%"
      ],
      "metadata": {
        "id": "RzLvpeJ6dG6r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# model = keras.models.load_model('/content/drive/MyDrive/파이썬스터디 프로젝트/cnn_220115_model_v2.h5')\n",
        "# model_eval()"
      ],
      "metadata": {
        "id": "DstEj5fjdG6r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba762caa-b331-4699-cf8a-ff78759db31b"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.679019225410978"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "v2.Emotion_Recognition.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}