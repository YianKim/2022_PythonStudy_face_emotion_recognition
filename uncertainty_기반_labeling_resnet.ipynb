{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YianKim/2022_uncertainty_aware_semisupervise/blob/main/uncertainty_%EA%B8%B0%EB%B0%98_labeling_resnet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UQy7KUb6NBs-"
      },
      "source": [
        "## 라이브러리 불러오기\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XRPQRtXGmm2W"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import PIL\n",
        "import pickle\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "from collections import Counter\n",
        "\n",
        "from keras.layers.core import Lambda\n",
        "from keras import backend as K\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.regularizers import l2\n",
        "from keras.layers import Activation\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Reshape\n",
        "from keras.layers import LSTM\n",
        "from keras import optimizers\n",
        "from keras.callbacks import ReduceLROnPlateau, EarlyStopping, TensorBoard, ModelCheckpoint\n",
        "from sklearn.metrics import *\n",
        "from keras.models import load_model\n",
        "\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xpAjYytuPDaU"
      },
      "source": [
        "## 데이터 불러오기\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e6b1qO5dSAyP"
      },
      "outputs": [],
      "source": [
        "fashion_mnist = keras.datasets.fashion_mnist\n",
        "(data, labels), (test_data, test_labels) = fashion_mnist.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B-e24WMOTQ4d"
      },
      "outputs": [],
      "source": [
        "train_data = data[range(10000)].reshape([10000,28,28,1])\n",
        "train_labels = labels[range(10000)].reshape([10000,1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EhhKskDITIEm"
      },
      "outputs": [],
      "source": [
        "unlab_data = data[range(10000,60000)].reshape([50000,28,28,1])\n",
        "unlab_labels = labels[range(10000,60000)].reshape([50000,1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W5aNLvjxVUq0"
      },
      "outputs": [],
      "source": [
        "test_data = test_data.reshape([10000,28,28,1])\n",
        "test_labels = test_labels.reshape([10000,1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2K2wXxMmUxRV"
      },
      "outputs": [],
      "source": [
        "train_labels2 = []\n",
        "unlab_labels2 = []\n",
        "test_labels2 = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8c9LL8JVThd-"
      },
      "outputs": [],
      "source": [
        "for i in range(10000):\n",
        "  white = [0,0,0,0,0,0,0,0,0,0]\n",
        "  white[train_labels[i][0]] = 1\n",
        "  train_labels2.append(white)\n",
        "\n",
        "for i in range(50000):\n",
        "  white = [0,0,0,0,0,0,0,0,0,0]\n",
        "  white[unlab_labels[i][0]] = 1\n",
        "  unlab_labels2.append(white)\n",
        "\n",
        "for i in range(10000):\n",
        "  white = [0,0,0,0,0,0,0,0,0,0]\n",
        "  white[test_labels[i][0]] = 1\n",
        "  test_labels2.append(white)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iULFrchUU5nt"
      },
      "outputs": [],
      "source": [
        "train_labels = np.array(train_labels2)\n",
        "unlab_labels = np.array(unlab_labels2)\n",
        "test_labels = np.array(test_labels2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hIAa0HMvS5CT"
      },
      "source": [
        "## resnet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P64aH7gGPPTY"
      },
      "outputs": [],
      "source": [
        "from tensorflow import Tensor\n",
        "from tensorflow.keras.layers import Input, Conv2D, ReLU, BatchNormalization,\\\n",
        "                                    Add, AveragePooling2D, Flatten, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "def PermaDropout(rate):\n",
        "    return Lambda(lambda x: K.dropout(x, level=rate))\n",
        "\n",
        "def relu_bn(inputs: Tensor) -> Tensor:\n",
        "    relu = ReLU()(inputs)\n",
        "    bn = BatchNormalization()(relu)\n",
        "    return bn\n",
        "\n",
        "def residual_block(x: Tensor, downsample: bool, filters: int, kernel_size: int = 3) -> Tensor:\n",
        "    y = Conv2D(kernel_size=kernel_size,\n",
        "               strides= (1 if not downsample else 2),\n",
        "               filters=filters,\n",
        "               padding=\"same\")(x)\n",
        "    y = relu_bn(y)\n",
        "    y = Conv2D(kernel_size=kernel_size,\n",
        "               strides=1,\n",
        "               filters=filters,\n",
        "               padding=\"same\")(y)\n",
        "\n",
        "    if downsample:\n",
        "        x = Conv2D(kernel_size=1,\n",
        "                   strides=2,\n",
        "                   filters=filters,\n",
        "                   padding=\"same\")(x)\n",
        "    out = Add()([x, y])\n",
        "    out = relu_bn(out)\n",
        "    return out\n",
        "\n",
        "def create_res_net():\n",
        "    \n",
        "    inputs = Input(shape=(28, 28, 1))\n",
        "    num_filters = 64\n",
        "    \n",
        "    t = BatchNormalization()(inputs)\n",
        "    t = Conv2D(kernel_size=3,\n",
        "               strides=1,\n",
        "               filters=num_filters,\n",
        "               padding=\"same\")(t)\n",
        "    t = relu_bn(t)\n",
        "    t = PermaDropout(0.5)(t)\n",
        "    \n",
        "    num_blocks_list = [2, 5, 5, 2]\n",
        "    for i in range(len(num_blocks_list)):\n",
        "        num_blocks = num_blocks_list[i]\n",
        "        for j in range(num_blocks):\n",
        "            t = residual_block(t, downsample=(j==0 and i!=0), filters=num_filters)\n",
        "        num_filters *= 2\n",
        "        t = PermaDropout(0.5)(t)\n",
        "    \n",
        "    t = AveragePooling2D(4)(t)\n",
        "    t = Flatten()(t)\n",
        "    outputs = Dense(10, activation='softmax')(t)\n",
        "    \n",
        "    model = Model(inputs, outputs)\n",
        "\n",
        "    model.compile(\n",
        "        optimizer='adam',\n",
        "        loss='categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_NNvVlDJSCt5",
        "outputId": "32c074f5-dd43-4f22-a8ae-8872e126b4a3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 28, 28, 1)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 28, 28, 1)    4           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 28, 28, 64)   640         batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "re_lu (ReLU)                    (None, 28, 28, 64)   0           conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 28, 28, 64)   256         re_lu[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "lambda (Lambda)                 (None, 28, 28, 64)   0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 28, 28, 64)   36928       lambda[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_1 (ReLU)                  (None, 28, 28, 64)   0           conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 28, 28, 64)   256         re_lu_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 28, 28, 64)   36928       batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "add (Add)                       (None, 28, 28, 64)   0           lambda[0][0]                     \n",
            "                                                                 conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_2 (ReLU)                  (None, 28, 28, 64)   0           add[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 28, 28, 64)   256         re_lu_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 28, 28, 64)   36928       batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_3 (ReLU)                  (None, 28, 28, 64)   0           conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 28, 28, 64)   256         re_lu_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 28, 28, 64)   36928       batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 28, 28, 64)   0           batch_normalization_3[0][0]      \n",
            "                                                                 conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_4 (ReLU)                  (None, 28, 28, 64)   0           add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 28, 28, 64)   256         re_lu_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lambda_1 (Lambda)               (None, 28, 28, 64)   0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 14, 14, 128)  73856       lambda_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_5 (ReLU)                  (None, 14, 14, 128)  0           conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 14, 14, 128)  512         re_lu_5[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 14, 14, 128)  8320        lambda_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 14, 14, 128)  147584      batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 14, 14, 128)  0           conv2d_7[0][0]                   \n",
            "                                                                 conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_6 (ReLU)                  (None, 14, 14, 128)  0           add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 14, 14, 128)  512         re_lu_6[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 14, 14, 128)  147584      batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_7 (ReLU)                  (None, 14, 14, 128)  0           conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 14, 14, 128)  512         re_lu_7[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 14, 14, 128)  147584      batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 14, 14, 128)  0           batch_normalization_7[0][0]      \n",
            "                                                                 conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_8 (ReLU)                  (None, 14, 14, 128)  0           add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 14, 14, 128)  512         re_lu_8[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 14, 14, 128)  147584      batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_9 (ReLU)                  (None, 14, 14, 128)  0           conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 14, 14, 128)  512         re_lu_9[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 14, 14, 128)  147584      batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, 14, 14, 128)  0           batch_normalization_9[0][0]      \n",
            "                                                                 conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_10 (ReLU)                 (None, 14, 14, 128)  0           add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 14, 14, 128)  512         re_lu_10[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 14, 14, 128)  147584      batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_11 (ReLU)                 (None, 14, 14, 128)  0           conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 14, 14, 128)  512         re_lu_11[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 14, 14, 128)  147584      batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, 14, 14, 128)  0           batch_normalization_11[0][0]     \n",
            "                                                                 conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_12 (ReLU)                 (None, 14, 14, 128)  0           add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 14, 14, 128)  512         re_lu_12[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 14, 14, 128)  147584      batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_13 (ReLU)                 (None, 14, 14, 128)  0           conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 14, 14, 128)  512         re_lu_13[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 14, 14, 128)  147584      batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "add_6 (Add)                     (None, 14, 14, 128)  0           batch_normalization_13[0][0]     \n",
            "                                                                 conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_14 (ReLU)                 (None, 14, 14, 128)  0           add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 14, 14, 128)  512         re_lu_14[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_2 (Lambda)               (None, 14, 14, 128)  0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 7, 7, 256)    295168      lambda_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_15 (ReLU)                 (None, 7, 7, 256)    0           conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 7, 7, 256)    1024        re_lu_15[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 7, 7, 256)    33024       lambda_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 7, 7, 256)    590080      batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "add_7 (Add)                     (None, 7, 7, 256)    0           conv2d_18[0][0]                  \n",
            "                                                                 conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_16 (ReLU)                 (None, 7, 7, 256)    0           add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 7, 7, 256)    1024        re_lu_16[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 7, 7, 256)    590080      batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_17 (ReLU)                 (None, 7, 7, 256)    0           conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 7, 7, 256)    1024        re_lu_17[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 7, 7, 256)    590080      batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "add_8 (Add)                     (None, 7, 7, 256)    0           batch_normalization_17[0][0]     \n",
            "                                                                 conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_18 (ReLU)                 (None, 7, 7, 256)    0           add_8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 7, 7, 256)    1024        re_lu_18[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 7, 7, 256)    590080      batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_19 (ReLU)                 (None, 7, 7, 256)    0           conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 7, 7, 256)    1024        re_lu_19[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 7, 7, 256)    590080      batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "add_9 (Add)                     (None, 7, 7, 256)    0           batch_normalization_19[0][0]     \n",
            "                                                                 conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_20 (ReLU)                 (None, 7, 7, 256)    0           add_9[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 7, 7, 256)    1024        re_lu_20[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 7, 7, 256)    590080      batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_21 (ReLU)                 (None, 7, 7, 256)    0           conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 7, 7, 256)    1024        re_lu_21[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 7, 7, 256)    590080      batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "add_10 (Add)                    (None, 7, 7, 256)    0           batch_normalization_21[0][0]     \n",
            "                                                                 conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_22 (ReLU)                 (None, 7, 7, 256)    0           add_10[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 7, 7, 256)    1024        re_lu_22[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 7, 7, 256)    590080      batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_23 (ReLU)                 (None, 7, 7, 256)    0           conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, 7, 7, 256)    1024        re_lu_23[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 7, 7, 256)    590080      batch_normalization_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "add_11 (Add)                    (None, 7, 7, 256)    0           batch_normalization_23[0][0]     \n",
            "                                                                 conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_24 (ReLU)                 (None, 7, 7, 256)    0           add_11[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, 7, 7, 256)    1024        re_lu_24[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3 (Lambda)               (None, 7, 7, 256)    0           batch_normalization_25[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 4, 4, 512)    1180160     lambda_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_25 (ReLU)                 (None, 4, 4, 512)    0           conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, 4, 4, 512)    2048        re_lu_25[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 4, 4, 512)    131584      lambda_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 4, 4, 512)    2359808     batch_normalization_26[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "add_12 (Add)                    (None, 4, 4, 512)    0           conv2d_29[0][0]                  \n",
            "                                                                 conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_26 (ReLU)                 (None, 4, 4, 512)    0           add_12[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_27 (BatchNo (None, 4, 4, 512)    2048        re_lu_26[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 4, 4, 512)    2359808     batch_normalization_27[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_27 (ReLU)                 (None, 4, 4, 512)    0           conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_28 (BatchNo (None, 4, 4, 512)    2048        re_lu_27[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 4, 4, 512)    2359808     batch_normalization_28[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "add_13 (Add)                    (None, 4, 4, 512)    0           batch_normalization_27[0][0]     \n",
            "                                                                 conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_28 (ReLU)                 (None, 4, 4, 512)    0           add_13[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_29 (BatchNo (None, 4, 4, 512)    2048        re_lu_28[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_4 (Lambda)               (None, 4, 4, 512)    0           batch_normalization_29[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d (AveragePooli (None, 1, 1, 512)    0           lambda_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 512)          0           average_pooling2d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 10)           5130        flatten[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 15,618,830\n",
            "Trainable params: 15,606,412\n",
            "Non-trainable params: 12,418\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model = create_res_net() # or create_plain_net()\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "KwkScUQtSJfJ",
        "outputId": "56ee06a0-7ecb-414e-d73f-bfb16bdf562a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_7596/748745187.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mearly_stopper\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mEarlyStopping\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'val_accuracy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_delta\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'auto'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m model.fit(\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain_labels\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda3\\envs\\gpu\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1182\u001b[0m                 _r=1):\n\u001b[0;32m   1183\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1184\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1185\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1186\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda3\\envs\\gpu\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    883\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    884\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 885\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    886\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda3\\envs\\gpu\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    948\u001b[0m         \u001b[1;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    949\u001b[0m         \u001b[1;31m# stateless function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 950\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    951\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    952\u001b[0m       \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfiltered_flat_args\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda3\\envs\\gpu\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3037\u001b[0m       (graph_function,\n\u001b[0;32m   3038\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 3039\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   3040\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   3041\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda3\\envs\\gpu\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1961\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1962\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1963\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1964\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1965\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
            "\u001b[1;32m~\\anaconda3\\envs\\gpu\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    589\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    590\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 591\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda3\\envs\\gpu\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "lr_reducer = ReduceLROnPlateau(monitor='val_loss', factor=0.9, patience=3)\n",
        "early_stopper = EarlyStopping(monitor='val_accuracy', min_delta=0, patience=30, mode='auto')\n",
        "\n",
        "model.fit(\n",
        "    x=train_data,\n",
        "    y=train_labels,\n",
        "    epochs=500,\n",
        "    verbose=1,\n",
        "    validation_split=0.3,\n",
        "    batch_size=64,\n",
        "    callbacks=[lr_reducer, early_stopper]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uY9o0L1zlu7j"
      },
      "outputs": [],
      "source": [
        "model.save('labeling_resnet.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TD8ppILhFUrz"
      },
      "source": [
        "## 모델 결과"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Ljx2EWA2v2n"
      },
      "outputs": [],
      "source": [
        "def model_eval():\n",
        "  pred_mu = model.predict(test_data)\n",
        "  for i in range(1, 30):\n",
        "    pred_mu += model.predict(test_data)\n",
        "  pred_mu = pred_mu/30\n",
        "  predicted_test_labels = np.argmax(pred_mu, axis=1)\n",
        "  return(accuracy_score(np.argmax(test_labels, axis=1), predicted_test_labels))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OzhQw9NOWjl3"
      },
      "outputs": [],
      "source": [
        "model = keras.models.load_model('labeling_resnet.h5')\n",
        "model_eval()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rcbs04885lTu"
      },
      "source": [
        "# 라벨링"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mAtfoQKLZDJC"
      },
      "source": [
        "## 라벨링; 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GKJgmFGWhlfl"
      },
      "outputs": [],
      "source": [
        "model = keras.models.load_model('labeling_resnet.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J_Jb5VX9ZC3y"
      },
      "outputs": [],
      "source": [
        "# Vars : 분산들\n",
        "# Outs : 결과 값들\n",
        "\n",
        "Vars = []\n",
        "Outs = []\n",
        "\n",
        "temp1 = []\n",
        "\n",
        "for i in tqdm(range(30)):\n",
        "  temp1.append(model.predict(unlab_data))\n",
        "\n",
        "for j in tqdm(range(unlab_data.shape[0])):\n",
        "\n",
        "  temp2 = np.array([0,0,0,0,0,0,0,0,0,0], 'float32')\n",
        "  \n",
        "  for i in range(30):\n",
        "    temp2 += temp1[i][j]\n",
        "  Outs.append(temp2/30)\n",
        "  \n",
        "  outputs=[]\n",
        "\n",
        "  for i in range(30):\n",
        "    outputs.append(temp1[i][j][np.argmax(temp2)])\n",
        "  Vars.append(np.var(outputs))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-NnAVIXTXlAa"
      },
      "outputs": [],
      "source": [
        "Outs = np.array(Outs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XxIFHtGqAF9B"
      },
      "source": [
        "class마다 균등하게 선택"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IGGGKCzvAiZb"
      },
      "outputs": [],
      "source": [
        "Counter(np.argmax(unlab_labels, axis=1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qXY6ufSkE_rP"
      },
      "source": [
        "### 불확정성 컷 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cEPgF4EWEdGx"
      },
      "outputs": [],
      "source": [
        "# upper bound of variance?\n",
        "\n",
        "UB25 = []\n",
        "UB50 = []\n",
        "UB75 = []\n",
        "\n",
        "\n",
        "for h in range(10):\n",
        "  classvars = []\n",
        "  for i in tqdm(range(50000)):\n",
        "    if np.argmax(unlab_labels, axis=1).tolist()[i]==h:\n",
        "      classvars.append(Vars[i])\n",
        "  UB25.append(np.percentile(classvars, 25))\n",
        "  UB50.append(np.percentile(classvars, 50))\n",
        "  UB75.append(np.percentile(classvars, 75))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F2m-BBSNFRO6"
      },
      "outputs": [],
      "source": [
        "# UB25 < UB50 < UB75"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xOq_mV-uFGKX"
      },
      "outputs": [],
      "source": [
        "vars25 = []\n",
        "vars50 = []\n",
        "vars75 = []\n",
        "vars100 = []\n",
        "\n",
        "ind = 0 \n",
        "\n",
        "\n",
        "for i in Vars:\n",
        "  if i <= UB25[np.argmax(unlab_labels, axis=1)[ind]]:\n",
        "    vars25.append(ind)\n",
        "  elif i <= UB50[np.argmax(unlab_labels, axis=1)[ind]]:\n",
        "    vars50.append(ind)\n",
        "  elif i <= UB75[np.argmax(unlab_labels, axis=1)[ind]]:\n",
        "    vars75.append(ind)\n",
        "  else:\n",
        "    vars100.append(ind)\n",
        "  ind += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5kx2MFUxKh6d"
      },
      "outputs": [],
      "source": [
        "k1 = random.sample(range(len(vars25)), len(vars25))\n",
        "k2 = random.sample(range(len(vars50)), len(vars50))\n",
        "k3 = random.sample(range(len(vars75)), len(vars75))\n",
        "k4 = random.sample(range(len(vars100)), len(vars100))\n",
        "\n",
        "lowvars = k1[0:len(k1)]+k2[0:len(k2)]\n",
        "highvars = k3[0:len(k3)]+k4[0:len(k4)]\n",
        "\n",
        "clstvars1 = k1[0:np.int(len(k1)/2)] + k2[0:np.int(len(k2)/2)] + k3[0:np.int(len(k3)/2)] + k4[0:np.int(len(k4)/2)]\n",
        "clstvars2 = k1[np.int(len(k1)/2):len(k1)] + k2[np.int(len(k2)/2):len(k2)] + k3[np.int(len(k3)/2):len(k3)] + k4[np.int(len(k4)/2):len(k4)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cHARP-fyFGKX"
      },
      "outputs": [],
      "source": [
        "# 같은 길이의 랜덤하게 고른 data들에 모델로 label 부여 후 정확도 측정\n",
        "randomindx = random.sample(range(50000), 50000)\n",
        "randomindx2 = randomindx[0:25000]\n",
        "randomindx = randomindx[25000:50000]\n",
        "accuracy_score(np.argmax(np.array(Outs)[randomindx], axis=1), np.argmax(unlab_labels[randomindx], axis=1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DU2TXlLaFGKY"
      },
      "outputs": [],
      "source": [
        "# 분산추출\n",
        "accuracy_score(np.argmax(np.array(Outs)[lowvars], axis=1), np.argmax(unlab_labels[lowvars], axis=1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g3-DbwVdiAlB"
      },
      "outputs": [],
      "source": [
        "# 층화추출\n",
        "accuracy_score(np.argmax(np.array(Outs)[clstvars1], axis=1), np.argmax(unlab_labels[clstvars1], axis=1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ka9xFulFGKY"
      },
      "outputs": [],
      "source": [
        "train_data_1 = unlab_data[lowvars]\n",
        "train_labels_1 = Outs[lowvars]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uLqnYj4ZFGKZ"
      },
      "outputs": [],
      "source": [
        "shufindx = random.sample(range(train_data_1.shape[0]),train_data_1.shape[0])\n",
        "train_data_1 = train_data_1[shufindx]\n",
        "train_labels_1 = train_labels_1[shufindx]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TDsyN3o-iAlB"
      },
      "outputs": [],
      "source": [
        "train_data_2 = unlab_data[clstvars1]\n",
        "train_labels_2 = Outs[clstvars1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ak-neqT_iAlC"
      },
      "outputs": [],
      "source": [
        "shufindx = random.sample(range(train_data_2.shape[0]),train_data_2.shape[0])\n",
        "train_data_2 = train_data_2[shufindx]\n",
        "train_labels_2 = train_labels_2[shufindx]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nvb7FhRaFGKZ"
      },
      "outputs": [],
      "source": [
        "train_data_3 = unlab_data[randomindx]\n",
        "train_labels_3 = Outs[randomindx]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PsSWcAFHFGKZ"
      },
      "outputs": [],
      "source": [
        "shufindx = random.sample(range(train_data_3.shape[0]),train_data_3.shape[0])\n",
        "train_data_3 = train_data_3[shufindx]\n",
        "train_labels_3 = train_labels_3[shufindx]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F39Oc7V8FGKZ"
      },
      "outputs": [],
      "source": [
        "unlab_data_1 = unlab_data[highvars]\n",
        "unlab_labels_1 = unlab_labels[highvars]\n",
        "unlab_data_2 = unlab_data[clstvars2]\n",
        "unlab_labels_2 = unlab_labels[clstvars2]\n",
        "unlab_data_3 = unlab_data[randomindx2]\n",
        "unlab_labels_3 = unlab_labels[randomindx2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MMw4VfmaFGKZ"
      },
      "outputs": [],
      "source": [
        "Counter(np.argmax(train_labels_1, axis=1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o5ZZKXxBFGKZ"
      },
      "outputs": [],
      "source": [
        "Counter(np.argmax(train_labels_2, axis=1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pKgNGwopiAlC"
      },
      "outputs": [],
      "source": [
        "Counter(np.argmax(train_labels_3, axis=1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y05Wb3HZFGKa"
      },
      "outputs": [],
      "source": [
        "Counter(np.argmax(unlab_labels_1, axis=1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qHWvlgD4FGKa"
      },
      "outputs": [],
      "source": [
        "Counter(np.argmax(unlab_labels_2, axis=1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a9UpZVhSiAlD"
      },
      "outputs": [],
      "source": [
        "Counter(np.argmax(unlab_labels_3, axis=1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bOtFA9fr5oDF"
      },
      "source": [
        "## 모델링\n",
        "\n",
        "간단한 모델에서 받은 지식를 복잡한 모델에서 학습 \n",
        "\n",
        "uncertainty aware data vs random sampling data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9u3DDkIzmpzz"
      },
      "source": [
        "#### Resnet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RXGIcInoiAlD"
      },
      "outputs": [],
      "source": [
        "def relu_bn(inputs: Tensor) -> Tensor:\n",
        "    relu = ReLU()(inputs)\n",
        "    bn = BatchNormalization()(relu)\n",
        "    return bn\n",
        "\n",
        "def create_simple_net():\n",
        "    \n",
        "    inputs = Input(shape=(28, 28, 1))\n",
        "    num_filters = 64\n",
        "    \n",
        "    t = BatchNormalization()(inputs)\n",
        "    t = Conv2D(kernel_size=3,\n",
        "               strides=1,\n",
        "               filters=num_filters,\n",
        "               padding=\"same\")(t)\n",
        "    t = relu_bn(t)\n",
        "    t = Conv2D(kernel_size=3,\n",
        "               strides=1,\n",
        "               filters=num_filters,\n",
        "               padding=\"same\")(t)\n",
        "    t = relu_bn(t)\n",
        "    t = Dropout(0.5)(t)\n",
        "    t = Flatten()(t)\n",
        "    outputs = Dense(10, activation='softmax')(t)\n",
        "    \n",
        "    model = Model(inputs, outputs)\n",
        "\n",
        "    model.compile(\n",
        "        optimizer='adam',\n",
        "        loss='categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oK46BFIUiAlD"
      },
      "outputs": [],
      "source": [
        "lr_reducer = ReduceLROnPlateau(monitor='val_loss', factor=0.9, patience=3)\n",
        "early_stopper = EarlyStopping(monitor='val_accuracy', min_delta=0, patience=30, mode='auto')\n",
        "model = create_simple_net()\n",
        "\n",
        "model.fit(\n",
        "    x=train_data_1,\n",
        "    y=train_labels_1,\n",
        "    epochs=500,\n",
        "    verbose=1,\n",
        "    validation_split=0.3,\n",
        "    batch_size=64,\n",
        "    callbacks=[lr_reducer, early_stopper]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ax7V5lVTiAlD"
      },
      "outputs": [],
      "source": [
        "for i in range(len(model.layers)-1):\n",
        "    model.layers[i].trainable = False\n",
        "    \n",
        "model.compile(\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=0.00001),\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "lr_reducer = ReduceLROnPlateau(monitor='val_loss', factor=0.9, patience=3)\n",
        "early_stopper = EarlyStopping(monitor='val_accuracy', min_delta=0, patience=30, mode='auto')\n",
        "\n",
        "model.fit(\n",
        "    x=train_data,\n",
        "    y=train_labels,\n",
        "    epochs=500,\n",
        "    verbose=1,\n",
        "    validation_split=0.3,\n",
        "    batch_size=64,\n",
        "    callbacks=[lr_reducer, early_stopper]\n",
        ")\n",
        "\n",
        "model.save('labeling_resnet_a1.h5')\n",
        "model_eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FSHwjApBiAlE"
      },
      "outputs": [],
      "source": [
        "lr_reducer = ReduceLROnPlateau(monitor='val_loss', factor=0.9, patience=3)\n",
        "early_stopper = EarlyStopping(monitor='val_accuracy', min_delta=0, patience=30, mode='auto')\n",
        "model = create_simple_net()\n",
        "\n",
        "model.fit(\n",
        "    x=train_data_2,\n",
        "    y=train_labels_2,\n",
        "    epochs=500,\n",
        "    verbose=1,\n",
        "    validation_split=0.3,\n",
        "    batch_size=64,\n",
        "    callbacks=[lr_reducer, early_stopper]\n",
        ")\n",
        "\n",
        "for i in range(len(model.layers)-1):\n",
        "    model.layers[i].trainable = False\n",
        "    \n",
        "model.compile(\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=0.00001),\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "lr_reducer = ReduceLROnPlateau(monitor='val_loss', factor=0.9, patience=3)\n",
        "early_stopper = EarlyStopping(monitor='val_accuracy', min_delta=0, patience=30, mode='auto')\n",
        "\n",
        "model.fit(\n",
        "    x=train_data,\n",
        "    y=train_labels,\n",
        "    epochs=500,\n",
        "    verbose=1,\n",
        "    validation_split=0.3,\n",
        "    batch_size=64,\n",
        "    callbacks=[lr_reducer, early_stopper]\n",
        ")\n",
        "\n",
        "model.save('labeling_resnet_b1.h5')\n",
        "model_eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u9q1S-pRiAlE"
      },
      "outputs": [],
      "source": [
        "lr_reducer = ReduceLROnPlateau(monitor='val_loss', factor=0.9, patience=3)\n",
        "early_stopper = EarlyStopping(monitor='val_accuracy', min_delta=0, patience=30, mode='auto')\n",
        "model = create_simple_net()\n",
        "\n",
        "model.fit(\n",
        "    x=train_data_3,\n",
        "    y=train_labels_3,\n",
        "    epochs=500,\n",
        "    verbose=1,\n",
        "    validation_split=0.3,\n",
        "    batch_size=64,\n",
        "    callbacks=[lr_reducer, early_stopper]\n",
        ")\n",
        "\n",
        "for i in range(len(model.layers)-1):\n",
        "    model.layers[i].trainable = False\n",
        "    \n",
        "model.compile(\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=0.00001),\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "lr_reducer = ReduceLROnPlateau(monitor='val_loss', factor=0.9, patience=3)\n",
        "early_stopper = EarlyStopping(monitor='val_accuracy', min_delta=0, patience=30, mode='auto')\n",
        "\n",
        "model.fit(\n",
        "    x=train_data,\n",
        "    y=train_labels,\n",
        "    epochs=500,\n",
        "    verbose=1,\n",
        "    validation_split=0.3,\n",
        "    batch_size=64,\n",
        "    callbacks=[lr_reducer, early_stopper]\n",
        ")\n",
        "\n",
        "model.save('labeling_resnet_c1.h5')\n",
        "model_eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YWPMeUZFiAlE"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cL2EW1wliAlE"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Iof5086XiAlE"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P8VsignDiAlE"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T59xJJepiAlE"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TWZxEIMXiAlE"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "BUrklzVkE66r",
        "IQb_xC_smn88",
        "YEpEOf-k3eET"
      ],
      "name": "uncertainty_기반_labeling_resnet.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}