{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YianKim/2022_uncertainty_aware_semisupervise/blob/main/uncertainty_%EA%B8%B0%EB%B0%98_labeling_resnet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UQy7KUb6NBs-"
      },
      "source": [
        "## 라이브러리 불러오기\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XRPQRtXGmm2W"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import PIL\n",
        "import pickle\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "from collections import Counter\n",
        "\n",
        "from keras.layers.core import Lambda\n",
        "from keras import backend as K\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.regularizers import l2\n",
        "from keras.layers import Activation\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Reshape\n",
        "from keras.layers import LSTM\n",
        "from keras import optimizers\n",
        "from keras.callbacks import ReduceLROnPlateau, EarlyStopping, TensorBoard, ModelCheckpoint\n",
        "from sklearn.metrics import *\n",
        "from keras.models import load_model\n",
        "\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xpAjYytuPDaU"
      },
      "source": [
        "## 데이터 불러오기\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e6b1qO5dSAyP"
      },
      "outputs": [],
      "source": [
        "fashion_mnist = keras.datasets.fashion_mnist\n",
        "(data, labels), (test_data, test_labels) = fashion_mnist.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B-e24WMOTQ4d"
      },
      "outputs": [],
      "source": [
        "train_data = data[range(10000)].reshape([10000,28,28,1])\n",
        "train_labels = labels[range(10000)].reshape([10000,1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EhhKskDITIEm"
      },
      "outputs": [],
      "source": [
        "unlab_data = data[range(10000,60000)].reshape([50000,28,28,1])\n",
        "unlab_labels = labels[range(10000,60000)].reshape([50000,1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W5aNLvjxVUq0"
      },
      "outputs": [],
      "source": [
        "test_data = test_data.reshape([10000,28,28,1])\n",
        "test_labels = test_labels.reshape([10000,1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2K2wXxMmUxRV"
      },
      "outputs": [],
      "source": [
        "train_labels2 = []\n",
        "unlab_labels2 = []\n",
        "test_labels2 = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8c9LL8JVThd-"
      },
      "outputs": [],
      "source": [
        "for i in range(10000):\n",
        "  white = [0,0,0,0,0,0,0,0,0,0]\n",
        "  white[train_labels[i][0]] = 1\n",
        "  train_labels2.append(white)\n",
        "\n",
        "for i in range(50000):\n",
        "  white = [0,0,0,0,0,0,0,0,0,0]\n",
        "  white[unlab_labels[i][0]] = 1\n",
        "  unlab_labels2.append(white)\n",
        "\n",
        "for i in range(10000):\n",
        "  white = [0,0,0,0,0,0,0,0,0,0]\n",
        "  white[test_labels[i][0]] = 1\n",
        "  test_labels2.append(white)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iULFrchUU5nt"
      },
      "outputs": [],
      "source": [
        "train_labels = np.array(train_labels2)\n",
        "unlab_labels = np.array(unlab_labels2)\n",
        "test_labels = np.array(test_labels2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hIAa0HMvS5CT"
      },
      "source": [
        "## resnet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P64aH7gGPPTY"
      },
      "outputs": [],
      "source": [
        "from tensorflow import Tensor\n",
        "from tensorflow.keras.layers import Input, Conv2D, ReLU, BatchNormalization,\\\n",
        "                                    Add, AveragePooling2D, Flatten, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "def PermaDropout(rate):\n",
        "    return Lambda(lambda x: K.dropout(x, level=rate))\n",
        "\n",
        "def relu_bn(inputs: Tensor) -> Tensor:\n",
        "    relu = ReLU()(inputs)\n",
        "    bn = BatchNormalization()(relu)\n",
        "    return bn\n",
        "\n",
        "def residual_block(x: Tensor, downsample: bool, filters: int, kernel_size: int = 3) -> Tensor:\n",
        "    y = Conv2D(kernel_size=kernel_size,\n",
        "               strides= (1 if not downsample else 2),\n",
        "               filters=filters,\n",
        "               padding=\"same\")(x)\n",
        "    y = relu_bn(y)\n",
        "    y = Conv2D(kernel_size=kernel_size,\n",
        "               strides=1,\n",
        "               filters=filters,\n",
        "               padding=\"same\")(y)\n",
        "\n",
        "    if downsample:\n",
        "        x = Conv2D(kernel_size=1,\n",
        "                   strides=2,\n",
        "                   filters=filters,\n",
        "                   padding=\"same\")(x)\n",
        "    out = Add()([x, y])\n",
        "    out = relu_bn(out)\n",
        "    return out\n",
        "\n",
        "def create_res_net():\n",
        "    \n",
        "    inputs = Input(shape=(28, 28, 1))\n",
        "    num_filters = 64\n",
        "    \n",
        "    t = BatchNormalization()(inputs)\n",
        "    t = Conv2D(kernel_size=3,\n",
        "               strides=1,\n",
        "               filters=num_filters,\n",
        "               padding=\"same\")(t)\n",
        "    t = relu_bn(t)\n",
        "    t = PermaDropout(0.5)(t)\n",
        "    \n",
        "    num_blocks_list = [2, 5, 5, 2]\n",
        "    for i in range(len(num_blocks_list)):\n",
        "        num_blocks = num_blocks_list[i]\n",
        "        for j in range(num_blocks):\n",
        "            t = residual_block(t, downsample=(j==0 and i!=0), filters=num_filters)\n",
        "        num_filters *= 2\n",
        "        t = PermaDropout(0.5)(t)\n",
        "    \n",
        "    t = AveragePooling2D(4)(t)\n",
        "    t = Flatten()(t)\n",
        "    outputs = Dense(10, activation='softmax')(t)\n",
        "    \n",
        "    model = Model(inputs, outputs)\n",
        "\n",
        "    model.compile(\n",
        "        optimizer='adam',\n",
        "        loss='categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_NNvVlDJSCt5",
        "outputId": "32c074f5-dd43-4f22-a8ae-8872e126b4a3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_7\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_8 (InputLayer)            [(None, 28, 28, 1)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_210 (BatchN (None, 28, 28, 1)    4           input_8[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_224 (Conv2D)             (None, 28, 28, 64)   640         batch_normalization_210[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_203 (ReLU)                (None, 28, 28, 64)   0           conv2d_224[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_211 (BatchN (None, 28, 28, 64)   256         re_lu_203[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "lambda_35 (Lambda)              (None, 28, 28, 64)   0           batch_normalization_211[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_225 (Conv2D)             (None, 28, 28, 64)   36928       lambda_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_204 (ReLU)                (None, 28, 28, 64)   0           conv2d_225[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_212 (BatchN (None, 28, 28, 64)   256         re_lu_204[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_226 (Conv2D)             (None, 28, 28, 64)   36928       batch_normalization_212[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "add_98 (Add)                    (None, 28, 28, 64)   0           lambda_35[0][0]                  \n",
            "                                                                 conv2d_226[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_205 (ReLU)                (None, 28, 28, 64)   0           add_98[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_213 (BatchN (None, 28, 28, 64)   256         re_lu_205[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_227 (Conv2D)             (None, 28, 28, 64)   36928       batch_normalization_213[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_206 (ReLU)                (None, 28, 28, 64)   0           conv2d_227[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_214 (BatchN (None, 28, 28, 64)   256         re_lu_206[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_228 (Conv2D)             (None, 28, 28, 64)   36928       batch_normalization_214[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "add_99 (Add)                    (None, 28, 28, 64)   0           batch_normalization_213[0][0]    \n",
            "                                                                 conv2d_228[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_207 (ReLU)                (None, 28, 28, 64)   0           add_99[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_215 (BatchN (None, 28, 28, 64)   256         re_lu_207[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "lambda_36 (Lambda)              (None, 28, 28, 64)   0           batch_normalization_215[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_229 (Conv2D)             (None, 14, 14, 128)  73856       lambda_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_208 (ReLU)                (None, 14, 14, 128)  0           conv2d_229[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_216 (BatchN (None, 14, 14, 128)  512         re_lu_208[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_231 (Conv2D)             (None, 14, 14, 128)  8320        lambda_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_230 (Conv2D)             (None, 14, 14, 128)  147584      batch_normalization_216[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "add_100 (Add)                   (None, 14, 14, 128)  0           conv2d_231[0][0]                 \n",
            "                                                                 conv2d_230[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_209 (ReLU)                (None, 14, 14, 128)  0           add_100[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_217 (BatchN (None, 14, 14, 128)  512         re_lu_209[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_232 (Conv2D)             (None, 14, 14, 128)  147584      batch_normalization_217[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_210 (ReLU)                (None, 14, 14, 128)  0           conv2d_232[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_218 (BatchN (None, 14, 14, 128)  512         re_lu_210[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_233 (Conv2D)             (None, 14, 14, 128)  147584      batch_normalization_218[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "add_101 (Add)                   (None, 14, 14, 128)  0           batch_normalization_217[0][0]    \n",
            "                                                                 conv2d_233[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_211 (ReLU)                (None, 14, 14, 128)  0           add_101[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_219 (BatchN (None, 14, 14, 128)  512         re_lu_211[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_234 (Conv2D)             (None, 14, 14, 128)  147584      batch_normalization_219[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_212 (ReLU)                (None, 14, 14, 128)  0           conv2d_234[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_220 (BatchN (None, 14, 14, 128)  512         re_lu_212[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_235 (Conv2D)             (None, 14, 14, 128)  147584      batch_normalization_220[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "add_102 (Add)                   (None, 14, 14, 128)  0           batch_normalization_219[0][0]    \n",
            "                                                                 conv2d_235[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_213 (ReLU)                (None, 14, 14, 128)  0           add_102[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_221 (BatchN (None, 14, 14, 128)  512         re_lu_213[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_236 (Conv2D)             (None, 14, 14, 128)  147584      batch_normalization_221[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_214 (ReLU)                (None, 14, 14, 128)  0           conv2d_236[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_222 (BatchN (None, 14, 14, 128)  512         re_lu_214[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_237 (Conv2D)             (None, 14, 14, 128)  147584      batch_normalization_222[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "add_103 (Add)                   (None, 14, 14, 128)  0           batch_normalization_221[0][0]    \n",
            "                                                                 conv2d_237[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_215 (ReLU)                (None, 14, 14, 128)  0           add_103[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_223 (BatchN (None, 14, 14, 128)  512         re_lu_215[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_238 (Conv2D)             (None, 14, 14, 128)  147584      batch_normalization_223[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_216 (ReLU)                (None, 14, 14, 128)  0           conv2d_238[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_224 (BatchN (None, 14, 14, 128)  512         re_lu_216[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_239 (Conv2D)             (None, 14, 14, 128)  147584      batch_normalization_224[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "add_104 (Add)                   (None, 14, 14, 128)  0           batch_normalization_223[0][0]    \n",
            "                                                                 conv2d_239[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_217 (ReLU)                (None, 14, 14, 128)  0           add_104[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_225 (BatchN (None, 14, 14, 128)  512         re_lu_217[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "lambda_37 (Lambda)              (None, 14, 14, 128)  0           batch_normalization_225[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_240 (Conv2D)             (None, 7, 7, 256)    295168      lambda_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_218 (ReLU)                (None, 7, 7, 256)    0           conv2d_240[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_226 (BatchN (None, 7, 7, 256)    1024        re_lu_218[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_242 (Conv2D)             (None, 7, 7, 256)    33024       lambda_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_241 (Conv2D)             (None, 7, 7, 256)    590080      batch_normalization_226[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "add_105 (Add)                   (None, 7, 7, 256)    0           conv2d_242[0][0]                 \n",
            "                                                                 conv2d_241[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_219 (ReLU)                (None, 7, 7, 256)    0           add_105[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_227 (BatchN (None, 7, 7, 256)    1024        re_lu_219[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_243 (Conv2D)             (None, 7, 7, 256)    590080      batch_normalization_227[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_220 (ReLU)                (None, 7, 7, 256)    0           conv2d_243[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_228 (BatchN (None, 7, 7, 256)    1024        re_lu_220[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_244 (Conv2D)             (None, 7, 7, 256)    590080      batch_normalization_228[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "add_106 (Add)                   (None, 7, 7, 256)    0           batch_normalization_227[0][0]    \n",
            "                                                                 conv2d_244[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_221 (ReLU)                (None, 7, 7, 256)    0           add_106[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_229 (BatchN (None, 7, 7, 256)    1024        re_lu_221[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_245 (Conv2D)             (None, 7, 7, 256)    590080      batch_normalization_229[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_222 (ReLU)                (None, 7, 7, 256)    0           conv2d_245[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_230 (BatchN (None, 7, 7, 256)    1024        re_lu_222[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_246 (Conv2D)             (None, 7, 7, 256)    590080      batch_normalization_230[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "add_107 (Add)                   (None, 7, 7, 256)    0           batch_normalization_229[0][0]    \n",
            "                                                                 conv2d_246[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_223 (ReLU)                (None, 7, 7, 256)    0           add_107[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_231 (BatchN (None, 7, 7, 256)    1024        re_lu_223[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_247 (Conv2D)             (None, 7, 7, 256)    590080      batch_normalization_231[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_224 (ReLU)                (None, 7, 7, 256)    0           conv2d_247[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_232 (BatchN (None, 7, 7, 256)    1024        re_lu_224[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_248 (Conv2D)             (None, 7, 7, 256)    590080      batch_normalization_232[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "add_108 (Add)                   (None, 7, 7, 256)    0           batch_normalization_231[0][0]    \n",
            "                                                                 conv2d_248[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_225 (ReLU)                (None, 7, 7, 256)    0           add_108[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_233 (BatchN (None, 7, 7, 256)    1024        re_lu_225[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_249 (Conv2D)             (None, 7, 7, 256)    590080      batch_normalization_233[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_226 (ReLU)                (None, 7, 7, 256)    0           conv2d_249[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_234 (BatchN (None, 7, 7, 256)    1024        re_lu_226[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_250 (Conv2D)             (None, 7, 7, 256)    590080      batch_normalization_234[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "add_109 (Add)                   (None, 7, 7, 256)    0           batch_normalization_233[0][0]    \n",
            "                                                                 conv2d_250[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_227 (ReLU)                (None, 7, 7, 256)    0           add_109[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_235 (BatchN (None, 7, 7, 256)    1024        re_lu_227[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "lambda_38 (Lambda)              (None, 7, 7, 256)    0           batch_normalization_235[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_251 (Conv2D)             (None, 4, 4, 512)    1180160     lambda_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_228 (ReLU)                (None, 4, 4, 512)    0           conv2d_251[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_236 (BatchN (None, 4, 4, 512)    2048        re_lu_228[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_253 (Conv2D)             (None, 4, 4, 512)    131584      lambda_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_252 (Conv2D)             (None, 4, 4, 512)    2359808     batch_normalization_236[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "add_110 (Add)                   (None, 4, 4, 512)    0           conv2d_253[0][0]                 \n",
            "                                                                 conv2d_252[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_229 (ReLU)                (None, 4, 4, 512)    0           add_110[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_237 (BatchN (None, 4, 4, 512)    2048        re_lu_229[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_254 (Conv2D)             (None, 4, 4, 512)    2359808     batch_normalization_237[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_230 (ReLU)                (None, 4, 4, 512)    0           conv2d_254[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_238 (BatchN (None, 4, 4, 512)    2048        re_lu_230[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_255 (Conv2D)             (None, 4, 4, 512)    2359808     batch_normalization_238[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "add_111 (Add)                   (None, 4, 4, 512)    0           batch_normalization_237[0][0]    \n",
            "                                                                 conv2d_255[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_231 (ReLU)                (None, 4, 4, 512)    0           add_111[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_239 (BatchN (None, 4, 4, 512)    2048        re_lu_231[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "lambda_39 (Lambda)              (None, 4, 4, 512)    0           batch_normalization_239[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_7 (AveragePoo (None, 1, 1, 512)    0           lambda_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "flatten_7 (Flatten)             (None, 512)          0           average_pooling2d_7[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "dense_7 (Dense)                 (None, 10)           5130        flatten_7[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 15,618,830\n",
            "Trainable params: 15,606,412\n",
            "Non-trainable params: 12,418\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model = create_res_net() # or create_plain_net()\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KwkScUQtSJfJ",
        "outputId": "56ee06a0-7ecb-414e-d73f-bfb16bdf562a",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "110/110 [==============================] - 10s 63ms/step - loss: 1.0659 - accuracy: 0.6051 - val_loss: 4.5772 - val_accuracy: 0.1730\n",
            "Epoch 2/500\n",
            "110/110 [==============================] - 6s 58ms/step - loss: 0.6121 - accuracy: 0.7764 - val_loss: 4.8579 - val_accuracy: 0.1890\n",
            "Epoch 3/500\n",
            "110/110 [==============================] - 7s 59ms/step - loss: 0.5323 - accuracy: 0.8071 - val_loss: 1.1230 - val_accuracy: 0.6147\n",
            "Epoch 4/500\n",
            "110/110 [==============================] - 6s 56ms/step - loss: 0.4783 - accuracy: 0.8260 - val_loss: 1.1310 - val_accuracy: 0.6680\n",
            "Epoch 5/500\n",
            "110/110 [==============================] - 6s 56ms/step - loss: 0.4235 - accuracy: 0.8410 - val_loss: 0.7391 - val_accuracy: 0.7443\n",
            "Epoch 6/500\n",
            "110/110 [==============================] - 6s 56ms/step - loss: 0.4130 - accuracy: 0.8490 - val_loss: 0.6321 - val_accuracy: 0.7960\n",
            "Epoch 7/500\n",
            "110/110 [==============================] - 6s 55ms/step - loss: 0.3789 - accuracy: 0.8620 - val_loss: 0.5360 - val_accuracy: 0.8190\n",
            "Epoch 8/500\n",
            "110/110 [==============================] - 6s 59ms/step - loss: 0.3484 - accuracy: 0.8731 - val_loss: 0.5191 - val_accuracy: 0.8317\n",
            "Epoch 9/500\n",
            "110/110 [==============================] - 7s 59ms/step - loss: 0.3464 - accuracy: 0.8756 - val_loss: 0.7229 - val_accuracy: 0.7760\n",
            "Epoch 10/500\n",
            "110/110 [==============================] - 6s 57ms/step - loss: 0.3210 - accuracy: 0.8801 - val_loss: 0.6498 - val_accuracy: 0.8143\n",
            "Epoch 11/500\n",
            "110/110 [==============================] - 6s 57ms/step - loss: 0.3058 - accuracy: 0.8890 - val_loss: 0.5429 - val_accuracy: 0.8263\n",
            "Epoch 12/500\n",
            "110/110 [==============================] - 6s 58ms/step - loss: 0.2807 - accuracy: 0.8956 - val_loss: 0.4289 - val_accuracy: 0.8523\n",
            "Epoch 13/500\n",
            "110/110 [==============================] - 6s 57ms/step - loss: 0.2716 - accuracy: 0.8980 - val_loss: 0.4886 - val_accuracy: 0.8520\n",
            "Epoch 14/500\n",
            "110/110 [==============================] - 6s 57ms/step - loss: 0.2601 - accuracy: 0.9026 - val_loss: 0.4309 - val_accuracy: 0.8620\n",
            "Epoch 15/500\n",
            "110/110 [==============================] - 6s 58ms/step - loss: 0.2482 - accuracy: 0.9119 - val_loss: 0.4243 - val_accuracy: 0.8593\n",
            "Epoch 16/500\n",
            "110/110 [==============================] - 6s 58ms/step - loss: 0.2353 - accuracy: 0.9117 - val_loss: 0.4382 - val_accuracy: 0.8550\n",
            "Epoch 17/500\n",
            "110/110 [==============================] - 6s 55ms/step - loss: 0.2256 - accuracy: 0.9209 - val_loss: 0.4813 - val_accuracy: 0.8477\n",
            "Epoch 18/500\n",
            "110/110 [==============================] - 6s 56ms/step - loss: 0.2277 - accuracy: 0.9151 - val_loss: 0.4252 - val_accuracy: 0.8707\n",
            "Epoch 19/500\n",
            "110/110 [==============================] - 6s 57ms/step - loss: 0.1996 - accuracy: 0.9273 - val_loss: 0.4524 - val_accuracy: 0.8650\n",
            "Epoch 20/500\n",
            "110/110 [==============================] - 6s 57ms/step - loss: 0.2013 - accuracy: 0.9304 - val_loss: 0.4479 - val_accuracy: 0.8633\n",
            "Epoch 21/500\n",
            "110/110 [==============================] - 6s 58ms/step - loss: 0.1944 - accuracy: 0.9280 - val_loss: 0.3891 - val_accuracy: 0.8757\n",
            "Epoch 22/500\n",
            "110/110 [==============================] - 6s 58ms/step - loss: 0.1814 - accuracy: 0.9336 - val_loss: 0.4713 - val_accuracy: 0.8617\n",
            "Epoch 23/500\n",
            "110/110 [==============================] - 6s 57ms/step - loss: 0.1839 - accuracy: 0.9341 - val_loss: 0.4928 - val_accuracy: 0.8553\n",
            "Epoch 24/500\n",
            "110/110 [==============================] - 6s 57ms/step - loss: 0.1745 - accuracy: 0.9344 - val_loss: 0.4314 - val_accuracy: 0.8723\n",
            "Epoch 25/500\n",
            "110/110 [==============================] - 6s 58ms/step - loss: 0.1403 - accuracy: 0.9506 - val_loss: 0.4834 - val_accuracy: 0.8717\n",
            "Epoch 26/500\n",
            "110/110 [==============================] - 6s 57ms/step - loss: 0.1549 - accuracy: 0.9449 - val_loss: 0.4425 - val_accuracy: 0.8730\n",
            "Epoch 27/500\n",
            "110/110 [==============================] - 6s 57ms/step - loss: 0.1363 - accuracy: 0.9529 - val_loss: 0.4352 - val_accuracy: 0.8800\n",
            "Epoch 28/500\n",
            "110/110 [==============================] - 6s 56ms/step - loss: 0.1101 - accuracy: 0.9603 - val_loss: 0.4288 - val_accuracy: 0.8783\n",
            "Epoch 29/500\n",
            "110/110 [==============================] - 6s 56ms/step - loss: 0.0975 - accuracy: 0.9663 - val_loss: 0.4572 - val_accuracy: 0.8763\n",
            "Epoch 30/500\n",
            "110/110 [==============================] - 6s 57ms/step - loss: 0.1137 - accuracy: 0.9571 - val_loss: 0.4394 - val_accuracy: 0.8843\n",
            "Epoch 31/500\n",
            "110/110 [==============================] - 6s 56ms/step - loss: 0.0800 - accuracy: 0.9709 - val_loss: 0.5333 - val_accuracy: 0.8653\n",
            "Epoch 32/500\n",
            "110/110 [==============================] - 6s 54ms/step - loss: 0.0926 - accuracy: 0.9654 - val_loss: 0.4731 - val_accuracy: 0.8843\n",
            "Epoch 33/500\n",
            "110/110 [==============================] - 6s 55ms/step - loss: 0.0876 - accuracy: 0.9694 - val_loss: 0.4792 - val_accuracy: 0.8823\n",
            "Epoch 34/500\n",
            "110/110 [==============================] - 6s 57ms/step - loss: 0.0754 - accuracy: 0.9713 - val_loss: 0.5365 - val_accuracy: 0.8760\n",
            "Epoch 35/500\n",
            "110/110 [==============================] - 6s 59ms/step - loss: 0.0630 - accuracy: 0.9783 - val_loss: 0.5056 - val_accuracy: 0.8817\n",
            "Epoch 36/500\n",
            "110/110 [==============================] - 6s 57ms/step - loss: 0.0595 - accuracy: 0.9773 - val_loss: 0.5419 - val_accuracy: 0.8757\n",
            "Epoch 37/500\n",
            "110/110 [==============================] - 6s 57ms/step - loss: 0.0602 - accuracy: 0.9790 - val_loss: 0.5416 - val_accuracy: 0.8873\n",
            "Epoch 38/500\n",
            "110/110 [==============================] - 6s 56ms/step - loss: 0.0578 - accuracy: 0.9816 - val_loss: 0.5145 - val_accuracy: 0.8817\n",
            "Epoch 39/500\n",
            "110/110 [==============================] - 6s 57ms/step - loss: 0.0391 - accuracy: 0.9859 - val_loss: 0.5968 - val_accuracy: 0.8810\n",
            "Epoch 40/500\n",
            "110/110 [==============================] - 6s 57ms/step - loss: 0.0412 - accuracy: 0.9856 - val_loss: 0.6050 - val_accuracy: 0.8717\n",
            "Epoch 41/500\n",
            "110/110 [==============================] - 6s 58ms/step - loss: 0.0439 - accuracy: 0.9839 - val_loss: 0.5879 - val_accuracy: 0.8860\n",
            "Epoch 42/500\n",
            "110/110 [==============================] - 6s 58ms/step - loss: 0.0482 - accuracy: 0.9830 - val_loss: 0.6298 - val_accuracy: 0.8727\n",
            "Epoch 43/500\n",
            "110/110 [==============================] - 6s 56ms/step - loss: 0.0482 - accuracy: 0.9844 - val_loss: 0.5818 - val_accuracy: 0.8870\n",
            "Epoch 44/500\n",
            "110/110 [==============================] - 6s 56ms/step - loss: 0.0285 - accuracy: 0.9889 - val_loss: 0.5747 - val_accuracy: 0.8880\n",
            "Epoch 45/500\n",
            "110/110 [==============================] - 6s 56ms/step - loss: 0.0370 - accuracy: 0.9880 - val_loss: 0.5841 - val_accuracy: 0.8767\n",
            "Epoch 46/500\n",
            "110/110 [==============================] - 6s 57ms/step - loss: 0.0235 - accuracy: 0.9919 - val_loss: 0.5731 - val_accuracy: 0.8863\n",
            "Epoch 47/500\n",
            "110/110 [==============================] - 6s 57ms/step - loss: 0.0280 - accuracy: 0.9910 - val_loss: 0.6041 - val_accuracy: 0.8850\n",
            "Epoch 48/500\n",
            "110/110 [==============================] - 6s 57ms/step - loss: 0.0249 - accuracy: 0.9921 - val_loss: 0.6971 - val_accuracy: 0.8790\n",
            "Epoch 49/500\n",
            "110/110 [==============================] - 6s 57ms/step - loss: 0.0397 - accuracy: 0.9877 - val_loss: 0.5730 - val_accuracy: 0.8930\n",
            "Epoch 50/500\n",
            " 73/110 [==================>...........] - ETA: 1s - loss: 0.0168 - accuracy: 0.9940"
          ]
        }
      ],
      "source": [
        "lr_reducer = ReduceLROnPlateau(monitor='val_loss', factor=0.9, patience=3)\n",
        "early_stopper = EarlyStopping(monitor='val_accuracy', min_delta=0, patience=30, mode='auto')\n",
        "\n",
        "model.fit(\n",
        "    x=train_data,\n",
        "    y=train_labels,\n",
        "    epochs=500,\n",
        "    verbose=1,\n",
        "    validation_split=0.3,\n",
        "    batch_size=64,\n",
        "    callbacks=[lr_reducer, early_stopper]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uY9o0L1zlu7j"
      },
      "outputs": [],
      "source": [
        "model.save('labeling_resnet.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TD8ppILhFUrz"
      },
      "source": [
        "## 모델 결과"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Ljx2EWA2v2n"
      },
      "outputs": [],
      "source": [
        "def model_eval():\n",
        "  pred_mu = model.predict(test_data)\n",
        "  for i in range(1, 30):\n",
        "    pred_mu += model.predict(test_data)\n",
        "  pred_mu = pred_mu/30\n",
        "  predicted_test_labels = np.argmax(pred_mu, axis=1)\n",
        "  return(accuracy_score(np.argmax(test_labels, axis=1), predicted_test_labels))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OzhQw9NOWjl3"
      },
      "outputs": [],
      "source": [
        "model = keras.models.load_model('labeling_resnet.h5')\n",
        "model_eval()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rcbs04885lTu"
      },
      "source": [
        "# 라벨링"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mAtfoQKLZDJC"
      },
      "source": [
        "## 라벨링; 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GKJgmFGWhlfl"
      },
      "outputs": [],
      "source": [
        "model = keras.models.load_model('labeling_resnet.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J_Jb5VX9ZC3y"
      },
      "outputs": [],
      "source": [
        "# Vars : 분산들\n",
        "# Outs : 결과 값들\n",
        "\n",
        "Vars = []\n",
        "Outs = []\n",
        "\n",
        "temp1 = []\n",
        "\n",
        "for i in tqdm(range(30)):\n",
        "  temp1.append(model.predict(unlab_data))\n",
        "\n",
        "for j in tqdm(range(unlab_data.shape[0])):\n",
        "\n",
        "  temp2 = np.array([0,0,0,0,0,0,0,0,0,0], 'float32')\n",
        "  \n",
        "  for i in range(30):\n",
        "    temp2 += temp1[i][j]\n",
        "  Outs.append(temp2/30)\n",
        "  \n",
        "  outputs=[]\n",
        "\n",
        "  for i in range(30):\n",
        "    outputs.append(temp1[i][j][np.argmax(temp2)])\n",
        "  Vars.append(np.var(outputs))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-NnAVIXTXlAa"
      },
      "outputs": [],
      "source": [
        "Outs = np.array(Outs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XxIFHtGqAF9B"
      },
      "source": [
        "class마다 균등하게 선택"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IGGGKCzvAiZb"
      },
      "outputs": [],
      "source": [
        "Counter(np.argmax(unlab_labels, axis=1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qXY6ufSkE_rP"
      },
      "source": [
        "### 불확정성 컷 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cEPgF4EWEdGx"
      },
      "outputs": [],
      "source": [
        "# upper bound of variance?\n",
        "\n",
        "UB25 = []\n",
        "UB50 = []\n",
        "UB75 = []\n",
        "\n",
        "\n",
        "for h in range(10):\n",
        "  classvars = []\n",
        "  for i in tqdm(range(50000)):\n",
        "    if np.argmax(unlab_labels, axis=1).tolist()[i]==h:\n",
        "      classvars.append(Vars[i])\n",
        "  UB25.append(np.percentile(classvars, 25))\n",
        "  UB50.append(np.percentile(classvars, 50))\n",
        "  UB75.append(np.percentile(classvars, 75))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F2m-BBSNFRO6"
      },
      "outputs": [],
      "source": [
        "# UB25 < UB50 < UB75"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xOq_mV-uFGKX"
      },
      "outputs": [],
      "source": [
        "vars25 = []\n",
        "vars50 = []\n",
        "vars75 = []\n",
        "vars100 = []\n",
        "\n",
        "ind = 0 \n",
        "\n",
        "\n",
        "for i in Vars:\n",
        "  if i <= UB25[np.argmax(unlab_labels, axis=1)[ind]]:\n",
        "    vars25.append(ind)\n",
        "  elif i <= UB50[np.argmax(unlab_labels, axis=1)[ind]]:\n",
        "    vars50.append(ind)\n",
        "  elif i <= UB75[np.argmax(unlab_labels, axis=1)[ind]]:\n",
        "    vars75.append(ind)\n",
        "  else:\n",
        "    vars100.append(ind)\n",
        "  ind += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5kx2MFUxKh6d"
      },
      "outputs": [],
      "source": [
        "k1 = random.sample(range(len(vars25)), len(vars25))\n",
        "k2 = random.sample(range(len(vars50)), len(vars50))\n",
        "k3 = random.sample(range(len(vars75)), len(vars75))\n",
        "k4 = random.sample(range(len(vars100)), len(vars100))\n",
        "\n",
        "lowvars = k1[0:np.int(len(k1)/2)] + k2[0:np.int(len(k2)/2)] + k3[0:np.int(len(k3)/2)] + k4[0:np.int(len(k4)/2)]\n",
        "highvars = k1[np.int(len(k1)/2):len(k1)] + k2[np.int(len(k2)/2):len(k2)] + k3[np.int(len(k3)/2):len(k3)] + k4[np.int(len(k4)/2):len(k4)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cHARP-fyFGKX"
      },
      "outputs": [],
      "source": [
        "# 같은 길이의 랜덤하게 고른 data들에 모델로 label 부여 후 정확도 측정\n",
        "randomindx = random.sample(range(50000), 50000)\n",
        "randomindx2 = randomindx[0:25000]\n",
        "randomindx = randomindx[25000:50000]\n",
        "accuracy_score(np.argmax(np.array(Outs)[randomindx], axis=1), np.argmax(unlab_labels[randomindx], axis=1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DU2TXlLaFGKY"
      },
      "outputs": [],
      "source": [
        "# 층화추출\n",
        "accuracy_score(np.argmax(np.array(Outs)[lowvars], axis=1), np.argmax(unlab_labels[lowvars], axis=1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ka9xFulFGKY"
      },
      "outputs": [],
      "source": [
        "train_data_1 = np.concatenate([train_data, unlab_data[lowvars]], axis=0)\n",
        "train_labels_1 = np.concatenate([train_labels, Outs[lowvars]], axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uLqnYj4ZFGKZ"
      },
      "outputs": [],
      "source": [
        "shufindx = random.sample(range(train_data_1.shape[0]),train_data_1.shape[0])\n",
        "train_data_1 = train_data_1[shufindx]\n",
        "train_labels_1 = train_labels_1[shufindx]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nvb7FhRaFGKZ"
      },
      "outputs": [],
      "source": [
        "train_data_2 = np.concatenate([train_data, unlab_data[randomindx]], axis=0)\n",
        "train_labels_2 = np.concatenate([train_labels, Outs[randomindx]], axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PsSWcAFHFGKZ"
      },
      "outputs": [],
      "source": [
        "shufindx = random.sample(range(train_data_2.shape[0]),train_data_2.shape[0])\n",
        "train_data_2 = train_data_2[shufindx]\n",
        "train_labels_2 = train_labels_2[shufindx]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F39Oc7V8FGKZ"
      },
      "outputs": [],
      "source": [
        "unlab_data_1 = unlab_data[highvars]\n",
        "unlab_labels_1 = unlab_labels[highvars]\n",
        "unlab_data_2 = unlab_data[randomindx2]\n",
        "unlab_labels_2 = unlab_labels[randomindx2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MMw4VfmaFGKZ"
      },
      "outputs": [],
      "source": [
        "Counter(np.argmax(train_labels_1, axis=1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o5ZZKXxBFGKZ"
      },
      "outputs": [],
      "source": [
        "Counter(np.argmax(train_labels_2, axis=1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y05Wb3HZFGKa"
      },
      "outputs": [],
      "source": [
        "Counter(np.argmax(unlab_labels_1, axis=1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qHWvlgD4FGKa"
      },
      "outputs": [],
      "source": [
        "Counter(np.argmax(unlab_labels_2, axis=1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bOtFA9fr5oDF"
      },
      "source": [
        "## 모델링\n",
        "\n",
        "간단한 모델에서 받은 지식를 복잡한 모델에서 학습 \n",
        "\n",
        "uncertainty aware data vs random sampling data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9u3DDkIzmpzz"
      },
      "source": [
        "#### Resnet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BrPuKrurotJ6"
      },
      "outputs": [],
      "source": [
        "from tensorflow import Tensor\n",
        "from tensorflow.keras.layers import Input, Conv2D, ReLU, BatchNormalization,\\\n",
        "                                    Add, AveragePooling2D, Flatten, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "def PermaDropout(rate):\n",
        "    return Lambda(lambda x: K.dropout(x, level=rate))\n",
        "\n",
        "def relu_bn(inputs: Tensor) -> Tensor:\n",
        "    relu = ReLU()(inputs)\n",
        "    bn = BatchNormalization()(relu)\n",
        "    return bn\n",
        "\n",
        "def residual_block(x: Tensor, downsample: bool, filters: int, kernel_size: int = 3) -> Tensor:\n",
        "    y = Conv2D(kernel_size=kernel_size,\n",
        "               strides= (1 if not downsample else 2),\n",
        "               filters=filters,\n",
        "               padding=\"same\")(x)\n",
        "    y = relu_bn(y)\n",
        "    y = Conv2D(kernel_size=kernel_size,\n",
        "               strides=1,\n",
        "               filters=filters,\n",
        "               padding=\"same\")(y)\n",
        "\n",
        "    if downsample:\n",
        "        x = Conv2D(kernel_size=1,\n",
        "                   strides=2,\n",
        "                   filters=filters,\n",
        "                   padding=\"same\")(x)\n",
        "    out = Add()([x, y])\n",
        "    out = relu_bn(out)\n",
        "    return out\n",
        "\n",
        "def create_res_net():\n",
        "    \n",
        "    inputs = Input(shape=(28, 28, 1))\n",
        "    num_filters = 64\n",
        "    \n",
        "    t = BatchNormalization()(inputs)\n",
        "    t = Conv2D(kernel_size=3,\n",
        "               strides=1,\n",
        "               filters=num_filters,\n",
        "               padding=\"same\")(t)\n",
        "    t = relu_bn(t)\n",
        "    t = PermaDropout(0.5)(t)\n",
        "    \n",
        "    num_blocks_list = [2, 5, 5, 5, 2]\n",
        "    for i in range(len(num_blocks_list)):\n",
        "        num_blocks = num_blocks_list[i]\n",
        "        for j in range(num_blocks):\n",
        "            t = residual_block(t, downsample=(j==0 and i!=0), filters=num_filters)\n",
        "        num_filters *= 2\n",
        "        t = PermaDropout(0.5)(t)\n",
        "    \n",
        "    t = AveragePooling2D(4)(t)\n",
        "    t = Flatten()(t)\n",
        "    outputs = Dense(10, activation='softmax')(t)\n",
        "    \n",
        "    model = Model(inputs, outputs)\n",
        "\n",
        "    model.compile(\n",
        "        optimizer='adam',\n",
        "        loss='categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mQJhYaz-otKF",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "model = create_res_net()\n",
        "lr_reducer = ReduceLROnPlateau(monitor='val_loss', factor=0.9, patience=3)\n",
        "early_stopper = EarlyStopping(monitor='val_accuracy', min_delta=0, patience=30, mode='auto')\n",
        "\n",
        "model.fit(\n",
        "    x=train_data_1,\n",
        "    y=train_labels_1,\n",
        "    epochs=500,\n",
        "    verbose=1,\n",
        "    validation_split=0.3,\n",
        "    batch_size=64,\n",
        "    callbacks=[lr_reducer, early_stopper]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rq55UzIFotKG"
      },
      "outputs": [],
      "source": [
        "model.save('labeling_resnet_a1.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IkejtLJno4Pl"
      },
      "outputs": [],
      "source": [
        "model_eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tpfArulIo1ml"
      },
      "outputs": [],
      "source": [
        "model = create_res_net()\n",
        "lr_reducer = ReduceLROnPlateau(monitor='val_loss', factor=0.9, patience=3)\n",
        "early_stopper = EarlyStopping(monitor='val_accuracy', min_delta=0, patience=30, mode='auto')\n",
        "\n",
        "model.fit(\n",
        "    x=train_data_2,\n",
        "    y=train_labels_2,\n",
        "    epochs=500,\n",
        "    verbose=1,\n",
        "    validation_split=0.3,\n",
        "    batch_size=64,\n",
        "    callbacks=[lr_reducer, early_stopper]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3az2Tj6vo1ml"
      },
      "outputs": [],
      "source": [
        "model.save('labeling_resnet_b1.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pSFsarpfo7px"
      },
      "outputs": [],
      "source": [
        "model_eval()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L5kdx4FDw7ED"
      },
      "source": [
        "# 남은 데이터 라벨링하기\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s8F_ifi6w9Uq"
      },
      "outputs": [],
      "source": [
        "model1 = keras.models.load_model('labeling_resnet_a1.h5')\n",
        "model2 = keras.models.load_model('labeling_resnet_b1.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "74E6i_eCxCNG"
      },
      "outputs": [],
      "source": [
        "unlab_label_1 = model1.predict(unlab_data_1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_tz_MEzhxXos"
      },
      "outputs": [],
      "source": [
        "unlab_label_2 = model2.predict(unlab_data_2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tiz6rZkT5ORw"
      },
      "outputs": [],
      "source": [
        "train_data_1 = np.concatenate([train_data_1, unlab_data_1], axis=0)\n",
        "train_labels_1 = np.concatenate([train_labels_1, unlab_label_1], axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vIe8iZLkD8pJ"
      },
      "outputs": [],
      "source": [
        "train_data_2 = np.concatenate([train_data_2, unlab_data_2], axis=0)\n",
        "train_labels_2 = np.concatenate([train_labels_2, unlab_label_2], axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oiL7N4BM3zxQ"
      },
      "outputs": [],
      "source": [
        "train_data_1.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Iyw46HeL31p3"
      },
      "outputs": [],
      "source": [
        "train_data_2.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "alBqvm5E3bd_"
      },
      "source": [
        "#### resnet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6EmZ6sdC3ioe"
      },
      "outputs": [],
      "source": [
        "from tensorflow import Tensor\n",
        "from tensorflow.keras.layers import Input, Conv2D, ReLU, BatchNormalization,\\\n",
        "                                    Add, AveragePooling2D, Flatten, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "def PermaDropout(rate):\n",
        "    return Lambda(lambda x: K.dropout(x, level=rate))\n",
        "\n",
        "def relu_bn(inputs: Tensor) -> Tensor:\n",
        "    relu = ReLU()(inputs)\n",
        "    bn = BatchNormalization()(relu)\n",
        "    return bn\n",
        "\n",
        "def residual_block(x: Tensor, downsample: bool, filters: int, kernel_size: int = 3) -> Tensor:\n",
        "    y = Conv2D(kernel_size=kernel_size,\n",
        "               strides= (1 if not downsample else 2),\n",
        "               filters=filters,\n",
        "               padding=\"same\")(x)\n",
        "    y = relu_bn(y)\n",
        "    y = Conv2D(kernel_size=kernel_size,\n",
        "               strides=1,\n",
        "               filters=filters,\n",
        "               padding=\"same\")(y)\n",
        "\n",
        "    if downsample:\n",
        "        x = Conv2D(kernel_size=1,\n",
        "                   strides=2,\n",
        "                   filters=filters,\n",
        "                   padding=\"same\")(x)\n",
        "    out = Add()([x, y])\n",
        "    out = relu_bn(out)\n",
        "    return out\n",
        "\n",
        "def create_res_net():\n",
        "    \n",
        "    inputs = Input(shape=(28, 28, 1))\n",
        "    num_filters = 64\n",
        "    \n",
        "    t = BatchNormalization()(inputs)\n",
        "    t = Conv2D(kernel_size=3,\n",
        "               strides=1,\n",
        "               filters=num_filters,\n",
        "               padding=\"same\")(t)\n",
        "    t = relu_bn(t)\n",
        "    t = PermaDropout(0.5)(t)\n",
        "    \n",
        "    num_blocks_list = [2, 5, 5, 5, 5, 2]\n",
        "    for i in range(len(num_blocks_list)):\n",
        "        num_blocks = num_blocks_list[i]\n",
        "        for j in range(num_blocks):\n",
        "            t = residual_block(t, downsample=(j==0 and i!=0), filters=num_filters)\n",
        "        num_filters *= 2\n",
        "        t = PermaDropout(0.5)(t)\n",
        "    \n",
        "    t = AveragePooling2D(4)(t)\n",
        "    t = Flatten()(t)\n",
        "    outputs = Dense(10, activation='softmax')(t)\n",
        "    \n",
        "    model = Model(inputs, outputs)\n",
        "\n",
        "    model.compile(\n",
        "        optimizer='adam',\n",
        "        loss='categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZGTGicAJ3iof"
      },
      "outputs": [],
      "source": [
        "model = create_res_net()\n",
        "lr_reducer = ReduceLROnPlateau(monitor='val_loss', factor=0.9, patience=3)\n",
        "early_stopper = EarlyStopping(monitor='val_accuracy', min_delta=0, patience=30, mode='auto')\n",
        "\n",
        "model.fit(\n",
        "    x=train_data_1,\n",
        "    y=train_labels_1,\n",
        "    epochs=500,\n",
        "    verbose=1,\n",
        "    validation_split=0.3,\n",
        "    batch_size=64,\n",
        "    callbacks=[lr_reducer, early_stopper]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bIqztqCd3iog"
      },
      "outputs": [],
      "source": [
        "model.save('labeling_resnet_a2.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gRVgsApR3iog"
      },
      "outputs": [],
      "source": [
        "model_eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ko6EgtS13iog"
      },
      "outputs": [],
      "source": [
        "model = create_res_net()\n",
        "lr_reducer = ReduceLROnPlateau(monitor='val_loss', factor=0.9, patience=3)\n",
        "early_stopper = EarlyStopping(monitor='val_accuracy', min_delta=0, patience=30, mode='auto')\n",
        "\n",
        "model.fit(\n",
        "    x=train_data_2,\n",
        "    y=train_labels_2,\n",
        "    epochs=500,\n",
        "    verbose=1,\n",
        "    validation_split=0.3,\n",
        "    batch_size=64,\n",
        "    callbacks=[lr_reducer, early_stopper]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "brNeFnIz3ioh"
      },
      "outputs": [],
      "source": [
        "model.save('labeling_resnet_b2.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C5mCztBs3ioh"
      },
      "outputs": [],
      "source": [
        "model_eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZvLar-vR36Rn"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "BUrklzVkE66r",
        "IQb_xC_smn88",
        "YEpEOf-k3eET"
      ],
      "name": "uncertainty_기반_labeling_resnet.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}