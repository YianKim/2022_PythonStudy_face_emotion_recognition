{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YianKim/2022_uncertainty_aware_semisupervise/blob/main/uncertaintylabeling_fer2013%2Bresnet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZhyYeRj0SI3d",
        "outputId": "c18b0131-be66-4aa2-da09-9c06682472ff"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UQy7KUb6NBs-"
      },
      "source": [
        "## 라이브러리 불러오기\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "XRPQRtXGmm2W"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import PIL\n",
        "import pickle\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "from collections import Counter\n",
        "\n",
        "from keras.layers.core import Lambda\n",
        "from keras import backend as K\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.regularizers import l2\n",
        "from keras.layers import Activation\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Reshape\n",
        "from keras.layers import LSTM\n",
        "from keras import optimizers\n",
        "from keras.callbacks import ReduceLROnPlateau, EarlyStopping, TensorBoard, ModelCheckpoint\n",
        "from sklearn.metrics import *\n",
        "from keras.models import load_model\n",
        "\n",
        "from tensorflow import Tensor\n",
        "from tensorflow.keras.layers import Input, Conv2D, ReLU, BatchNormalization,\\\n",
        "                                    Add, AveragePooling2D, Flatten, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xpAjYytuPDaU"
      },
      "source": [
        "## 데이터 불러오기\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data(dataset_path):\n",
        "  \n",
        "  #classes = ['Angry', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprsie', 'Neutral']\n",
        "\n",
        "  data = []\n",
        "  test_data = []\n",
        "  test_labels = []\n",
        "  labels =[]\n",
        "\n",
        "  with open(dataset_path, 'r') as file:\n",
        "      for line_no, line in enumerate(file.readlines()):\n",
        "          if 0 < line_no <= 35887:\n",
        "            curr_class, line, set_type = line.split(',')\n",
        "            image_data = np.asarray([int(x) for x in line.split()]).reshape(48, 48)\n",
        "            image_data =image_data.astype(np.uint8)/255.0\n",
        "\n",
        "            if (set_type.strip() == 'PrivateTest'):\n",
        "              \n",
        "              test_data.append(image_data)\n",
        "              test_labels.append(curr_class)\n",
        "            else:\n",
        "              data.append(image_data)\n",
        "              labels.append(curr_class)\n",
        "      \n",
        "      test_data = np.expand_dims(test_data, -1)\n",
        "      test_labels = to_categorical(test_labels, num_classes = 7)\n",
        "      data = np.expand_dims(data, -1)   \n",
        "      labels = to_categorical(labels, num_classes = 7)\n",
        "    \n",
        "      return np.array(data), np.array(labels), np.array(test_data), np.array(test_labels)\n",
        "\n",
        "dataset_path = \"/content/drive/MyDrive/파이썬스터디 프로젝트/fer2013.csv/fer2013.csv\"\n",
        "train_data, train_labels, test_data, test_labels = load_data(dataset_path)\n",
        "#train_data, test_data, train_labels, test_labels = train_test_split(data, labels, test_size = test_size,random_state = seed)\n",
        "\n",
        "#평가용\n",
        "test_labels2 = np.argmax(test_labels, axis=1)\n",
        "\n",
        "# print(\"Number of images in Training set:\", len(train_data))\n",
        "# print(\"Number of images in Test set:\", len(test_data))\n",
        "\n",
        "with open('/content/drive/MyDrive/파이썬스터디 프로젝트/aug_array1.pkl', 'rb') as f:\n",
        "\taug_array1 = pickle.load(f)\n",
        " \n",
        "train_data_aug = np.concatenate((train_data, aug_array1), axis=0)\n",
        "train_labels_aug = np.concatenate((train_labels, train_labels), axis=0)"
      ],
      "metadata": {
        "id": "U_ZB0uDTSGGC"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_aug.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "COMQNhDiSkGT",
        "outputId": "2dbfa114-8897-46fa-cf68-7e56acff9932"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(64596, 48, 48, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_labels_aug.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LdGqU-jSSlvF",
        "outputId": "5833eb28-e720-49d1-833e-ade209ef8eea"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(64596, 7)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = train_data_aug[range(10000)]"
      ],
      "metadata": {
        "id": "--YdRp5-S7oi"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_labels = train_labels_aug[range(10000)]"
      ],
      "metadata": {
        "id": "SGX3CSwwS7_v"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unlab_data = train_data_aug[range(10000,64596)]"
      ],
      "metadata": {
        "id": "KpGODvQVTHkd"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unlab_labels = train_labels_aug[range(10000,64596)]"
      ],
      "metadata": {
        "id": "jAngZFurTH17"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hIAa0HMvS5CT"
      },
      "source": [
        "## resnet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "P64aH7gGPPTY"
      },
      "outputs": [],
      "source": [
        "def PermaDropout(rate):\n",
        "    return Lambda(lambda x: K.dropout(x, level=rate))\n",
        "\n",
        "def relu_bn(inputs: Tensor) -> Tensor:\n",
        "    relu = ReLU()(inputs)\n",
        "    bn = BatchNormalization()(relu)\n",
        "    return bn\n",
        "\n",
        "def residual_block(x: Tensor, downsample: bool, filters: int, kernel_size: int = 3) -> Tensor:\n",
        "    y = Conv2D(kernel_size=kernel_size,\n",
        "               strides= (1 if not downsample else 2),\n",
        "               filters=filters,\n",
        "               padding=\"same\")(x)\n",
        "    y = relu_bn(y)\n",
        "    y = Conv2D(kernel_size=kernel_size,\n",
        "               strides=1,\n",
        "               filters=filters,\n",
        "               padding=\"same\")(y)\n",
        "\n",
        "    if downsample:\n",
        "        x = Conv2D(kernel_size=1,\n",
        "                   strides=2,\n",
        "                   filters=filters,\n",
        "                   padding=\"same\")(x)\n",
        "    out = Add()([x, y])\n",
        "    out = relu_bn(out)\n",
        "    return out\n",
        "\n",
        "def create_res_net():\n",
        "    \n",
        "    inputs = Input(shape=(48, 48, 1))\n",
        "    num_filters = 128\n",
        "    \n",
        "    t = BatchNormalization()(inputs)\n",
        "    t = Conv2D(kernel_size=3,\n",
        "               strides=1,\n",
        "               filters=num_filters,\n",
        "               padding=\"same\")(t)\n",
        "    t = relu_bn(t)\n",
        "    t = PermaDropout(0.5)(t)\n",
        "    \n",
        "    num_blocks_list = [2, 5, 5, 2]\n",
        "    for i in range(len(num_blocks_list)):\n",
        "        num_blocks = num_blocks_list[i]\n",
        "        for j in range(num_blocks):\n",
        "            t = residual_block(t, downsample=(j==0 and i!=0), filters=num_filters)\n",
        "        num_filters *= 2\n",
        "        t = PermaDropout(0.5)(t)\n",
        "    \n",
        "    t = AveragePooling2D(6)(t)\n",
        "    t = Flatten()(t)\n",
        "    outputs = Dense(7, activation='softmax')(t)\n",
        "    \n",
        "    model = Model(inputs, outputs)\n",
        "\n",
        "    model.compile(\n",
        "        optimizer='adam',\n",
        "        loss='categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_NNvVlDJSCt5",
        "outputId": "2c122c60-c182-4b76-d790-23b2a52e6b91"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_4\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_5 (InputLayer)           [(None, 48, 48, 1)]  0           []                               \n",
            "                                                                                                  \n",
            " batch_normalization_120 (Batch  (None, 48, 48, 1)   4           ['input_5[0][0]']                \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " conv2d_128 (Conv2D)            (None, 48, 48, 128)  1280        ['batch_normalization_120[0][0]']\n",
            "                                                                                                  \n",
            " re_lu_116 (ReLU)               (None, 48, 48, 128)  0           ['conv2d_128[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_121 (Batch  (None, 48, 48, 128)  512        ['re_lu_116[0][0]']              \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " lambda_20 (Lambda)             (None, 48, 48, 128)  0           ['batch_normalization_121[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_129 (Conv2D)            (None, 48, 48, 128)  147584      ['lambda_20[0][0]']              \n",
            "                                                                                                  \n",
            " re_lu_117 (ReLU)               (None, 48, 48, 128)  0           ['conv2d_129[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_122 (Batch  (None, 48, 48, 128)  512        ['re_lu_117[0][0]']              \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " conv2d_130 (Conv2D)            (None, 48, 48, 128)  147584      ['batch_normalization_122[0][0]']\n",
            "                                                                                                  \n",
            " add_56 (Add)                   (None, 48, 48, 128)  0           ['lambda_20[0][0]',              \n",
            "                                                                  'conv2d_130[0][0]']             \n",
            "                                                                                                  \n",
            " re_lu_118 (ReLU)               (None, 48, 48, 128)  0           ['add_56[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_123 (Batch  (None, 48, 48, 128)  512        ['re_lu_118[0][0]']              \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " conv2d_131 (Conv2D)            (None, 48, 48, 128)  147584      ['batch_normalization_123[0][0]']\n",
            "                                                                                                  \n",
            " re_lu_119 (ReLU)               (None, 48, 48, 128)  0           ['conv2d_131[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_124 (Batch  (None, 48, 48, 128)  512        ['re_lu_119[0][0]']              \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " conv2d_132 (Conv2D)            (None, 48, 48, 128)  147584      ['batch_normalization_124[0][0]']\n",
            "                                                                                                  \n",
            " add_57 (Add)                   (None, 48, 48, 128)  0           ['batch_normalization_123[0][0]',\n",
            "                                                                  'conv2d_132[0][0]']             \n",
            "                                                                                                  \n",
            " re_lu_120 (ReLU)               (None, 48, 48, 128)  0           ['add_57[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_125 (Batch  (None, 48, 48, 128)  512        ['re_lu_120[0][0]']              \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " lambda_21 (Lambda)             (None, 48, 48, 128)  0           ['batch_normalization_125[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_133 (Conv2D)            (None, 24, 24, 256)  295168      ['lambda_21[0][0]']              \n",
            "                                                                                                  \n",
            " re_lu_121 (ReLU)               (None, 24, 24, 256)  0           ['conv2d_133[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_126 (Batch  (None, 24, 24, 256)  1024       ['re_lu_121[0][0]']              \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " conv2d_135 (Conv2D)            (None, 24, 24, 256)  33024       ['lambda_21[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_134 (Conv2D)            (None, 24, 24, 256)  590080      ['batch_normalization_126[0][0]']\n",
            "                                                                                                  \n",
            " add_58 (Add)                   (None, 24, 24, 256)  0           ['conv2d_135[0][0]',             \n",
            "                                                                  'conv2d_134[0][0]']             \n",
            "                                                                                                  \n",
            " re_lu_122 (ReLU)               (None, 24, 24, 256)  0           ['add_58[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_127 (Batch  (None, 24, 24, 256)  1024       ['re_lu_122[0][0]']              \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " conv2d_136 (Conv2D)            (None, 24, 24, 256)  590080      ['batch_normalization_127[0][0]']\n",
            "                                                                                                  \n",
            " re_lu_123 (ReLU)               (None, 24, 24, 256)  0           ['conv2d_136[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_128 (Batch  (None, 24, 24, 256)  1024       ['re_lu_123[0][0]']              \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " conv2d_137 (Conv2D)            (None, 24, 24, 256)  590080      ['batch_normalization_128[0][0]']\n",
            "                                                                                                  \n",
            " add_59 (Add)                   (None, 24, 24, 256)  0           ['batch_normalization_127[0][0]',\n",
            "                                                                  'conv2d_137[0][0]']             \n",
            "                                                                                                  \n",
            " re_lu_124 (ReLU)               (None, 24, 24, 256)  0           ['add_59[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_129 (Batch  (None, 24, 24, 256)  1024       ['re_lu_124[0][0]']              \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " conv2d_138 (Conv2D)            (None, 24, 24, 256)  590080      ['batch_normalization_129[0][0]']\n",
            "                                                                                                  \n",
            " re_lu_125 (ReLU)               (None, 24, 24, 256)  0           ['conv2d_138[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_130 (Batch  (None, 24, 24, 256)  1024       ['re_lu_125[0][0]']              \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " conv2d_139 (Conv2D)            (None, 24, 24, 256)  590080      ['batch_normalization_130[0][0]']\n",
            "                                                                                                  \n",
            " add_60 (Add)                   (None, 24, 24, 256)  0           ['batch_normalization_129[0][0]',\n",
            "                                                                  'conv2d_139[0][0]']             \n",
            "                                                                                                  \n",
            " re_lu_126 (ReLU)               (None, 24, 24, 256)  0           ['add_60[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_131 (Batch  (None, 24, 24, 256)  1024       ['re_lu_126[0][0]']              \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " conv2d_140 (Conv2D)            (None, 24, 24, 256)  590080      ['batch_normalization_131[0][0]']\n",
            "                                                                                                  \n",
            " re_lu_127 (ReLU)               (None, 24, 24, 256)  0           ['conv2d_140[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_132 (Batch  (None, 24, 24, 256)  1024       ['re_lu_127[0][0]']              \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " conv2d_141 (Conv2D)            (None, 24, 24, 256)  590080      ['batch_normalization_132[0][0]']\n",
            "                                                                                                  \n",
            " add_61 (Add)                   (None, 24, 24, 256)  0           ['batch_normalization_131[0][0]',\n",
            "                                                                  'conv2d_141[0][0]']             \n",
            "                                                                                                  \n",
            " re_lu_128 (ReLU)               (None, 24, 24, 256)  0           ['add_61[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_133 (Batch  (None, 24, 24, 256)  1024       ['re_lu_128[0][0]']              \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " conv2d_142 (Conv2D)            (None, 24, 24, 256)  590080      ['batch_normalization_133[0][0]']\n",
            "                                                                                                  \n",
            " re_lu_129 (ReLU)               (None, 24, 24, 256)  0           ['conv2d_142[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_134 (Batch  (None, 24, 24, 256)  1024       ['re_lu_129[0][0]']              \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " conv2d_143 (Conv2D)            (None, 24, 24, 256)  590080      ['batch_normalization_134[0][0]']\n",
            "                                                                                                  \n",
            " add_62 (Add)                   (None, 24, 24, 256)  0           ['batch_normalization_133[0][0]',\n",
            "                                                                  'conv2d_143[0][0]']             \n",
            "                                                                                                  \n",
            " re_lu_130 (ReLU)               (None, 24, 24, 256)  0           ['add_62[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_135 (Batch  (None, 24, 24, 256)  1024       ['re_lu_130[0][0]']              \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " lambda_22 (Lambda)             (None, 24, 24, 256)  0           ['batch_normalization_135[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_144 (Conv2D)            (None, 12, 12, 512)  1180160     ['lambda_22[0][0]']              \n",
            "                                                                                                  \n",
            " re_lu_131 (ReLU)               (None, 12, 12, 512)  0           ['conv2d_144[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_136 (Batch  (None, 12, 12, 512)  2048       ['re_lu_131[0][0]']              \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " conv2d_146 (Conv2D)            (None, 12, 12, 512)  131584      ['lambda_22[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_145 (Conv2D)            (None, 12, 12, 512)  2359808     ['batch_normalization_136[0][0]']\n",
            "                                                                                                  \n",
            " add_63 (Add)                   (None, 12, 12, 512)  0           ['conv2d_146[0][0]',             \n",
            "                                                                  'conv2d_145[0][0]']             \n",
            "                                                                                                  \n",
            " re_lu_132 (ReLU)               (None, 12, 12, 512)  0           ['add_63[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_137 (Batch  (None, 12, 12, 512)  2048       ['re_lu_132[0][0]']              \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " conv2d_147 (Conv2D)            (None, 12, 12, 512)  2359808     ['batch_normalization_137[0][0]']\n",
            "                                                                                                  \n",
            " re_lu_133 (ReLU)               (None, 12, 12, 512)  0           ['conv2d_147[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_138 (Batch  (None, 12, 12, 512)  2048       ['re_lu_133[0][0]']              \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " conv2d_148 (Conv2D)            (None, 12, 12, 512)  2359808     ['batch_normalization_138[0][0]']\n",
            "                                                                                                  \n",
            " add_64 (Add)                   (None, 12, 12, 512)  0           ['batch_normalization_137[0][0]',\n",
            "                                                                  'conv2d_148[0][0]']             \n",
            "                                                                                                  \n",
            " re_lu_134 (ReLU)               (None, 12, 12, 512)  0           ['add_64[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_139 (Batch  (None, 12, 12, 512)  2048       ['re_lu_134[0][0]']              \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " conv2d_149 (Conv2D)            (None, 12, 12, 512)  2359808     ['batch_normalization_139[0][0]']\n",
            "                                                                                                  \n",
            " re_lu_135 (ReLU)               (None, 12, 12, 512)  0           ['conv2d_149[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_140 (Batch  (None, 12, 12, 512)  2048       ['re_lu_135[0][0]']              \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " conv2d_150 (Conv2D)            (None, 12, 12, 512)  2359808     ['batch_normalization_140[0][0]']\n",
            "                                                                                                  \n",
            " add_65 (Add)                   (None, 12, 12, 512)  0           ['batch_normalization_139[0][0]',\n",
            "                                                                  'conv2d_150[0][0]']             \n",
            "                                                                                                  \n",
            " re_lu_136 (ReLU)               (None, 12, 12, 512)  0           ['add_65[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_141 (Batch  (None, 12, 12, 512)  2048       ['re_lu_136[0][0]']              \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " conv2d_151 (Conv2D)            (None, 12, 12, 512)  2359808     ['batch_normalization_141[0][0]']\n",
            "                                                                                                  \n",
            " re_lu_137 (ReLU)               (None, 12, 12, 512)  0           ['conv2d_151[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_142 (Batch  (None, 12, 12, 512)  2048       ['re_lu_137[0][0]']              \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " conv2d_152 (Conv2D)            (None, 12, 12, 512)  2359808     ['batch_normalization_142[0][0]']\n",
            "                                                                                                  \n",
            " add_66 (Add)                   (None, 12, 12, 512)  0           ['batch_normalization_141[0][0]',\n",
            "                                                                  'conv2d_152[0][0]']             \n",
            "                                                                                                  \n",
            " re_lu_138 (ReLU)               (None, 12, 12, 512)  0           ['add_66[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_143 (Batch  (None, 12, 12, 512)  2048       ['re_lu_138[0][0]']              \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " conv2d_153 (Conv2D)            (None, 12, 12, 512)  2359808     ['batch_normalization_143[0][0]']\n",
            "                                                                                                  \n",
            " re_lu_139 (ReLU)               (None, 12, 12, 512)  0           ['conv2d_153[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_144 (Batch  (None, 12, 12, 512)  2048       ['re_lu_139[0][0]']              \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " conv2d_154 (Conv2D)            (None, 12, 12, 512)  2359808     ['batch_normalization_144[0][0]']\n",
            "                                                                                                  \n",
            " add_67 (Add)                   (None, 12, 12, 512)  0           ['batch_normalization_143[0][0]',\n",
            "                                                                  'conv2d_154[0][0]']             \n",
            "                                                                                                  \n",
            " re_lu_140 (ReLU)               (None, 12, 12, 512)  0           ['add_67[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_145 (Batch  (None, 12, 12, 512)  2048       ['re_lu_140[0][0]']              \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " lambda_23 (Lambda)             (None, 12, 12, 512)  0           ['batch_normalization_145[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_155 (Conv2D)            (None, 6, 6, 1024)   4719616     ['lambda_23[0][0]']              \n",
            "                                                                                                  \n",
            " re_lu_141 (ReLU)               (None, 6, 6, 1024)   0           ['conv2d_155[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_146 (Batch  (None, 6, 6, 1024)  4096        ['re_lu_141[0][0]']              \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " conv2d_157 (Conv2D)            (None, 6, 6, 1024)   525312      ['lambda_23[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_156 (Conv2D)            (None, 6, 6, 1024)   9438208     ['batch_normalization_146[0][0]']\n",
            "                                                                                                  \n",
            " add_68 (Add)                   (None, 6, 6, 1024)   0           ['conv2d_157[0][0]',             \n",
            "                                                                  'conv2d_156[0][0]']             \n",
            "                                                                                                  \n",
            " re_lu_142 (ReLU)               (None, 6, 6, 1024)   0           ['add_68[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_147 (Batch  (None, 6, 6, 1024)  4096        ['re_lu_142[0][0]']              \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " conv2d_158 (Conv2D)            (None, 6, 6, 1024)   9438208     ['batch_normalization_147[0][0]']\n",
            "                                                                                                  \n",
            " re_lu_143 (ReLU)               (None, 6, 6, 1024)   0           ['conv2d_158[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_148 (Batch  (None, 6, 6, 1024)  4096        ['re_lu_143[0][0]']              \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " conv2d_159 (Conv2D)            (None, 6, 6, 1024)   9438208     ['batch_normalization_148[0][0]']\n",
            "                                                                                                  \n",
            " add_69 (Add)                   (None, 6, 6, 1024)   0           ['batch_normalization_147[0][0]',\n",
            "                                                                  'conv2d_159[0][0]']             \n",
            "                                                                                                  \n",
            " re_lu_144 (ReLU)               (None, 6, 6, 1024)   0           ['add_69[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_149 (Batch  (None, 6, 6, 1024)  4096        ['re_lu_144[0][0]']              \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " lambda_24 (Lambda)             (None, 6, 6, 1024)   0           ['batch_normalization_149[0][0]']\n",
            "                                                                                                  \n",
            " average_pooling2d_4 (AveragePo  (None, 1, 1, 1024)  0           ['lambda_24[0][0]']              \n",
            " oling2D)                                                                                         \n",
            "                                                                                                  \n",
            " flatten_4 (Flatten)            (None, 1024)         0           ['average_pooling2d_4[0][0]']    \n",
            "                                                                                                  \n",
            " dense_4 (Dense)                (None, 7)            7175        ['flatten_4[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 62,396,939\n",
            "Trainable params: 62,372,105\n",
            "Non-trainable params: 24,834\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model = create_res_net() # or create_plain_net()\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "KwkScUQtSJfJ",
        "outputId": "f196925c-6dc7-46cb-d91c-b725d1834991"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "110/110 [==============================] - 159s 1s/step - loss: 2.1876 - accuracy: 0.2089 - val_loss: 7.6638 - val_accuracy: 0.2243 - lr: 0.0010\n",
            "Epoch 2/500\n",
            "110/110 [==============================] - 129s 1s/step - loss: 1.8900 - accuracy: 0.2207 - val_loss: 3.0755 - val_accuracy: 0.1640 - lr: 0.0010\n",
            "Epoch 3/500\n",
            " 34/110 [========>.....................] - ETA: 1:19 - loss: 1.8782 - accuracy: 0.2463"
          ]
        }
      ],
      "source": [
        "lr_reducer = ReduceLROnPlateau(monitor='val_loss', factor=0.9, patience=3)\n",
        "early_stopper = EarlyStopping(monitor='val_accuracy', min_delta=0, patience=30, mode='auto')\n",
        "\n",
        "model.fit(\n",
        "    x=train_data,\n",
        "    y=train_labels,\n",
        "    epochs=500,\n",
        "    verbose=1,\n",
        "    validation_split=0.3,\n",
        "    batch_size=64,\n",
        "    callbacks=[lr_reducer, early_stopper]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uY9o0L1zlu7j"
      },
      "outputs": [],
      "source": [
        "model.save('/content/drive/MyDrive/파이썬스터디 프로젝트/labeling_fer_resnet.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TD8ppILhFUrz"
      },
      "source": [
        "## 모델 결과"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Ljx2EWA2v2n"
      },
      "outputs": [],
      "source": [
        "def model_eval():\n",
        "  pred_mu = model.predict(test_data)\n",
        "  for i in range(1, 30):\n",
        "    pred_mu += model.predict(test_data)\n",
        "  pred_mu = pred_mu/30\n",
        "  predicted_test_labels = np.argmax(pred_mu, axis=1)\n",
        "  return(accuracy_score(np.argmax(test_labels, axis=1), predicted_test_labels))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OzhQw9NOWjl3"
      },
      "outputs": [],
      "source": [
        "model = keras.models.load_model('/content/drive/MyDrive/파이썬스터디 프로젝트/labeling_fer_resnet.h5')\n",
        "model_eval()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rcbs04885lTu"
      },
      "source": [
        "# 라벨링"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mAtfoQKLZDJC"
      },
      "source": [
        "## 라벨링; 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GKJgmFGWhlfl"
      },
      "outputs": [],
      "source": [
        "model = keras.models.load_model('/content/drive/MyDrive/파이썬스터디 프로젝트/labeling_fer_resnet.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J_Jb5VX9ZC3y"
      },
      "outputs": [],
      "source": [
        "# Vars : 분산들\n",
        "# Outs : 결과 값들\n",
        "\n",
        "Vars = []\n",
        "Outs = []\n",
        "\n",
        "temp1 = []\n",
        "\n",
        "for i in tqdm(range(20)):\n",
        "  temp1.append(model.predict(unlab_data))\n",
        "\n",
        "for j in tqdm(range(unlab_data.shape[0])):\n",
        "\n",
        "  temp2 = np.array([0,0,0,0,0,0,0], 'float32')\n",
        "  \n",
        "  for i in range(30):\n",
        "    temp2 += temp1[i][j]\n",
        "  Outs.append(temp2/30)\n",
        "  \n",
        "  outputs=[]\n",
        "\n",
        "  for i in range(30):\n",
        "    outputs.append(temp1[i][j][np.argmax(temp2)])\n",
        "  Vars.append(np.var(outputs))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-NnAVIXTXlAa"
      },
      "outputs": [],
      "source": [
        "Outs = np.array(Outs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XxIFHtGqAF9B"
      },
      "source": [
        "class마다 균등하게 선택"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IGGGKCzvAiZb"
      },
      "outputs": [],
      "source": [
        "Counter(np.argmax(unlab_labels, axis=1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qXY6ufSkE_rP"
      },
      "source": [
        "### 불확정성\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cEPgF4EWEdGx"
      },
      "outputs": [],
      "source": [
        "# upper bound of variance?\n",
        "\n",
        "UB25 = []\n",
        "UB50 = []\n",
        "UB75 = []\n",
        "\n",
        "\n",
        "for h in range(7):\n",
        "  classvars = []\n",
        "  for i in tqdm(range(54596)):\n",
        "    if np.argmax(unlab_labels, axis=1).tolist()[i]==h:\n",
        "      classvars.append(Vars[i])\n",
        "  UB25.append(np.percentile(classvars, 25))\n",
        "  UB50.append(np.percentile(classvars, 50))\n",
        "  UB75.append(np.percentile(classvars, 75))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F2m-BBSNFRO6"
      },
      "outputs": [],
      "source": [
        "# UB25 < UB50 < UB75"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xOq_mV-uFGKX"
      },
      "outputs": [],
      "source": [
        "vars25 = []\n",
        "vars50 = []\n",
        "vars75 = []\n",
        "vars100 = []\n",
        "\n",
        "ind = 0 \n",
        "\n",
        "\n",
        "for i in Vars:\n",
        "  if i <= UB25[np.argmax(unlab_labels, axis=1)[ind]]:\n",
        "    vars25.append(ind)\n",
        "  elif i <= UB50[np.argmax(unlab_labels, axis=1)[ind]]:\n",
        "    vars50.append(ind)\n",
        "  elif i <= UB75[np.argmax(unlab_labels, axis=1)[ind]]:\n",
        "    vars75.append(ind)\n",
        "  else:\n",
        "    vars100.append(ind)\n",
        "  ind += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5kx2MFUxKh6d"
      },
      "outputs": [],
      "source": [
        "k1 = random.sample(range(len(vars25)), len(vars25))\n",
        "k2 = random.sample(range(len(vars50)), len(vars50))\n",
        "k3 = random.sample(range(len(vars75)), len(vars75))\n",
        "k4 = random.sample(range(len(vars100)), len(vars100))\n",
        "\n",
        "lowvars = k1[0:len(k1)]+k2[0:len(k2)]\n",
        "highvars = k3[0:len(k3)]+k4[0:len(k4)]\n",
        "\n",
        "clstvars1 = k1[0:np.int(len(k1)/2)] + k2[0:np.int(len(k2)/2)] + k3[0:np.int(len(k3)/2)] + k4[0:np.int(len(k4)/2)]\n",
        "clstvars2 = k1[np.int(len(k1)/2):len(k1)] + k2[np.int(len(k2)/2):len(k2)] + k3[np.int(len(k3)/2):len(k3)] + k4[np.int(len(k4)/2):len(k4)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cHARP-fyFGKX"
      },
      "outputs": [],
      "source": [
        "# 같은 길이의 랜덤하게 고른 data들에 모델로 label 부여 후 정확도 측정\n",
        "randomindx = random.sample(range(54596), 54596)\n",
        "randomindx2 = randomindx[0:27298]\n",
        "randomindx = randomindx[27298:50000]\n",
        "accuracy_score(np.argmax(np.array(Outs)[randomindx], axis=1), np.argmax(unlab_labels[randomindx], axis=1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DU2TXlLaFGKY"
      },
      "outputs": [],
      "source": [
        "# 분산추출\n",
        "accuracy_score(np.argmax(np.array(Outs)[lowvars], axis=1), np.argmax(unlab_labels[lowvars], axis=1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qG3XGnVCQ-VV"
      },
      "outputs": [],
      "source": [
        "# 층화추출\n",
        "accuracy_score(np.argmax(np.array(Outs)[clstvars1], axis=1), np.argmax(unlab_labels[clstvars1], axis=1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ka9xFulFGKY"
      },
      "outputs": [],
      "source": [
        "train_data_1 = unlab_data[lowvars]\n",
        "train_labels_1 = Outs[lowvars]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uLqnYj4ZFGKZ"
      },
      "outputs": [],
      "source": [
        "shufindx = random.sample(range(train_data_1.shape[0]),train_data_1.shape[0])\n",
        "train_data_1 = train_data_1[shufindx]\n",
        "train_labels_1 = train_labels_1[shufindx]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AUv8cAJwQ-VX"
      },
      "outputs": [],
      "source": [
        "train_data_2 = unlab_data[clstvars1]\n",
        "train_labels_2 = Outs[clstvars1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aUodIRYhQ-VX"
      },
      "outputs": [],
      "source": [
        "shufindx = random.sample(range(train_data_2.shape[0]),train_data_2.shape[0])\n",
        "train_data_2 = train_data_2[shufindx]\n",
        "train_labels_2 = train_labels_2[shufindx]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nvb7FhRaFGKZ"
      },
      "outputs": [],
      "source": [
        "train_data_3 = unlab_data[randomindx]\n",
        "train_labels_3 = Outs[randomindx]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PsSWcAFHFGKZ"
      },
      "outputs": [],
      "source": [
        "shufindx = random.sample(range(train_data_3.shape[0]),train_data_3.shape[0])\n",
        "train_data_3 = train_data_3[shufindx]\n",
        "train_labels_3 = train_labels_3[shufindx]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F39Oc7V8FGKZ"
      },
      "outputs": [],
      "source": [
        "unlab_data_1 = unlab_data[highvars]\n",
        "unlab_labels_1 = unlab_labels[highvars]\n",
        "unlab_data_2 = unlab_data[clstvars2]\n",
        "unlab_labels_2 = unlab_labels[clstvars2]\n",
        "unlab_data_3 = unlab_data[randomindx2]\n",
        "unlab_labels_3 = unlab_labels[randomindx2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MMw4VfmaFGKZ"
      },
      "outputs": [],
      "source": [
        "Counter(np.argmax(train_labels_1, axis=1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o5ZZKXxBFGKZ"
      },
      "outputs": [],
      "source": [
        "Counter(np.argmax(train_labels_2, axis=1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UKgTMCL8Q-VZ"
      },
      "outputs": [],
      "source": [
        "Counter(np.argmax(train_labels_3, axis=1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y05Wb3HZFGKa"
      },
      "outputs": [],
      "source": [
        "Counter(np.argmax(unlab_labels_1, axis=1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qHWvlgD4FGKa"
      },
      "outputs": [],
      "source": [
        "Counter(np.argmax(unlab_labels_2, axis=1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X4WYCa4aQ-VZ"
      },
      "outputs": [],
      "source": [
        "Counter(np.argmax(unlab_labels_3, axis=1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bOtFA9fr5oDF"
      },
      "source": [
        "## 모델링\n",
        "\n",
        "간단한 모델에서 받은 지식를 복잡한 모델에서 학습 \n",
        "\n",
        "uncertainty aware data vs random sampling data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9u3DDkIzmpzz"
      },
      "source": [
        "#### Resnet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cBBsEBDGQ-Va"
      },
      "outputs": [],
      "source": [
        "def relu_bn(inputs: Tensor) -> Tensor:\n",
        "    relu = ReLU()(inputs)\n",
        "    bn = BatchNormalization()(relu)\n",
        "    return bn\n",
        "\n",
        "def create_simple_net():\n",
        "    \n",
        "    inputs = Input(shape=(48, 48, 1))\n",
        "    num_filters = 64\n",
        "    \n",
        "    t = BatchNormalization()(inputs)\n",
        "    t = Conv2D(kernel_size=3,\n",
        "               strides=1,\n",
        "               filters=num_filters,\n",
        "               padding=\"same\")(t)\n",
        "    t = relu_bn(t)\n",
        "    t = Conv2D(kernel_size=3,\n",
        "               strides=1,\n",
        "               filters=num_filters,\n",
        "               padding=\"same\")(t)\n",
        "    t = relu_bn(t)\n",
        "    t = Dropout(0.5)(t)\n",
        "    t = Flatten()(t)\n",
        "    outputs = Dense(7, activation='softmax')(t)\n",
        "    \n",
        "    model = Model(inputs, outputs)\n",
        "\n",
        "    model.compile(\n",
        "        optimizer='adam',\n",
        "        loss='categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_HmHMKXKQ-Va",
        "outputId": "9517546f-ec4a-436a-9650-14e00301269c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "110/110 [==============================] - 2s 13ms/step - loss: 0.2869 - accuracy: 0.9070 - val_loss: 0.3547 - val_accuracy: 0.8943\n",
            "Epoch 2/500\n",
            "110/110 [==============================] - 1s 11ms/step - loss: 0.2841 - accuracy: 0.9080 - val_loss: 0.3535 - val_accuracy: 0.8967\n",
            "Epoch 3/500\n",
            "110/110 [==============================] - 1s 11ms/step - loss: 0.2849 - accuracy: 0.9066 - val_loss: 0.3525 - val_accuracy: 0.8970\n",
            "Epoch 4/500\n",
            "110/110 [==============================] - 1s 9ms/step - loss: 0.2780 - accuracy: 0.9106 - val_loss: 0.3515 - val_accuracy: 0.8977\n",
            "Epoch 5/500\n",
            "110/110 [==============================] - 1s 8ms/step - loss: 0.2739 - accuracy: 0.9110 - val_loss: 0.3507 - val_accuracy: 0.8977\n",
            "Epoch 6/500\n",
            "110/110 [==============================] - 1s 10ms/step - loss: 0.2718 - accuracy: 0.9100 - val_loss: 0.3499 - val_accuracy: 0.8983\n",
            "Epoch 7/500\n",
            "110/110 [==============================] - 1s 11ms/step - loss: 0.2697 - accuracy: 0.9109 - val_loss: 0.3492 - val_accuracy: 0.8987\n",
            "Epoch 8/500\n",
            "110/110 [==============================] - 1s 11ms/step - loss: 0.2756 - accuracy: 0.9103 - val_loss: 0.3485 - val_accuracy: 0.8987\n",
            "Epoch 9/500\n",
            "110/110 [==============================] - 1s 11ms/step - loss: 0.2692 - accuracy: 0.9090 - val_loss: 0.3478 - val_accuracy: 0.8993\n",
            "Epoch 10/500\n",
            "110/110 [==============================] - 1s 11ms/step - loss: 0.2659 - accuracy: 0.9136 - val_loss: 0.3470 - val_accuracy: 0.8983\n",
            "Epoch 11/500\n",
            "110/110 [==============================] - 1s 11ms/step - loss: 0.2699 - accuracy: 0.9100 - val_loss: 0.3464 - val_accuracy: 0.8990\n",
            "Epoch 12/500\n",
            "110/110 [==============================] - 1s 11ms/step - loss: 0.2652 - accuracy: 0.9106 - val_loss: 0.3457 - val_accuracy: 0.8987\n",
            "Epoch 13/500\n",
            "110/110 [==============================] - 1s 11ms/step - loss: 0.2620 - accuracy: 0.9107 - val_loss: 0.3451 - val_accuracy: 0.8990\n",
            "Epoch 14/500\n",
            "110/110 [==============================] - 1s 11ms/step - loss: 0.2622 - accuracy: 0.9120 - val_loss: 0.3445 - val_accuracy: 0.8987\n",
            "Epoch 15/500\n",
            "110/110 [==============================] - 1s 11ms/step - loss: 0.2646 - accuracy: 0.9101 - val_loss: 0.3439 - val_accuracy: 0.8993\n",
            "Epoch 16/500\n",
            "110/110 [==============================] - 1s 11ms/step - loss: 0.2548 - accuracy: 0.9146 - val_loss: 0.3434 - val_accuracy: 0.8990\n",
            "Epoch 17/500\n",
            "110/110 [==============================] - 1s 11ms/step - loss: 0.2553 - accuracy: 0.9130 - val_loss: 0.3428 - val_accuracy: 0.8993\n",
            "Epoch 18/500\n",
            "110/110 [==============================] - 1s 9ms/step - loss: 0.2561 - accuracy: 0.9139 - val_loss: 0.3423 - val_accuracy: 0.9000\n",
            "Epoch 19/500\n",
            "110/110 [==============================] - 1s 9ms/step - loss: 0.2555 - accuracy: 0.9171 - val_loss: 0.3417 - val_accuracy: 0.9000\n",
            "Epoch 20/500\n",
            "110/110 [==============================] - 1s 10ms/step - loss: 0.2583 - accuracy: 0.9113 - val_loss: 0.3411 - val_accuracy: 0.9003\n",
            "Epoch 21/500\n",
            "110/110 [==============================] - 1s 10ms/step - loss: 0.2531 - accuracy: 0.9139 - val_loss: 0.3406 - val_accuracy: 0.9007\n",
            "Epoch 22/500\n",
            "110/110 [==============================] - 1s 11ms/step - loss: 0.2528 - accuracy: 0.9176 - val_loss: 0.3400 - val_accuracy: 0.9007\n",
            "Epoch 23/500\n",
            "110/110 [==============================] - 1s 11ms/step - loss: 0.2480 - accuracy: 0.9171 - val_loss: 0.3395 - val_accuracy: 0.9003\n",
            "Epoch 24/500\n",
            "110/110 [==============================] - 1s 11ms/step - loss: 0.2500 - accuracy: 0.9176 - val_loss: 0.3390 - val_accuracy: 0.9003\n",
            "Epoch 25/500\n",
            "110/110 [==============================] - 1s 11ms/step - loss: 0.2527 - accuracy: 0.9156 - val_loss: 0.3383 - val_accuracy: 0.9003\n",
            "Epoch 26/500\n",
            "110/110 [==============================] - 1s 11ms/step - loss: 0.2469 - accuracy: 0.9173 - val_loss: 0.3378 - val_accuracy: 0.9003\n",
            "Epoch 27/500\n",
            "110/110 [==============================] - 1s 12ms/step - loss: 0.2461 - accuracy: 0.9153 - val_loss: 0.3374 - val_accuracy: 0.9003\n",
            "Epoch 28/500\n",
            "110/110 [==============================] - 1s 11ms/step - loss: 0.2477 - accuracy: 0.9153 - val_loss: 0.3368 - val_accuracy: 0.9007\n",
            "Epoch 29/500\n",
            "110/110 [==============================] - 1s 12ms/step - loss: 0.2461 - accuracy: 0.9171 - val_loss: 0.3362 - val_accuracy: 0.9007\n",
            "Epoch 30/500\n",
            "110/110 [==============================] - 1s 11ms/step - loss: 0.2424 - accuracy: 0.9193 - val_loss: 0.3358 - val_accuracy: 0.9003\n",
            "Epoch 31/500\n",
            "110/110 [==============================] - 1s 11ms/step - loss: 0.2405 - accuracy: 0.9187 - val_loss: 0.3352 - val_accuracy: 0.9007\n",
            "Epoch 32/500\n",
            "110/110 [==============================] - 1s 9ms/step - loss: 0.2385 - accuracy: 0.9179 - val_loss: 0.3348 - val_accuracy: 0.9010\n",
            "Epoch 33/500\n",
            "110/110 [==============================] - 1s 11ms/step - loss: 0.2354 - accuracy: 0.9167 - val_loss: 0.3345 - val_accuracy: 0.9017\n",
            "Epoch 34/500\n",
            "110/110 [==============================] - 1s 12ms/step - loss: 0.2376 - accuracy: 0.9200 - val_loss: 0.3340 - val_accuracy: 0.9017\n",
            "Epoch 35/500\n",
            "110/110 [==============================] - 1s 11ms/step - loss: 0.2337 - accuracy: 0.9207 - val_loss: 0.3335 - val_accuracy: 0.9020\n",
            "Epoch 36/500\n",
            "110/110 [==============================] - 1s 11ms/step - loss: 0.2338 - accuracy: 0.9191 - val_loss: 0.3331 - val_accuracy: 0.9020\n",
            "Epoch 37/500\n",
            "110/110 [==============================] - 1s 11ms/step - loss: 0.2351 - accuracy: 0.9199 - val_loss: 0.3326 - val_accuracy: 0.9020\n",
            "Epoch 38/500\n",
            "110/110 [==============================] - 1s 10ms/step - loss: 0.2309 - accuracy: 0.9197 - val_loss: 0.3322 - val_accuracy: 0.9020\n",
            "Epoch 39/500\n",
            "110/110 [==============================] - 1s 11ms/step - loss: 0.2300 - accuracy: 0.9201 - val_loss: 0.3317 - val_accuracy: 0.9020\n",
            "Epoch 40/500\n",
            "110/110 [==============================] - 1s 11ms/step - loss: 0.2324 - accuracy: 0.9199 - val_loss: 0.3314 - val_accuracy: 0.9020\n",
            "Epoch 41/500\n",
            "110/110 [==============================] - 1s 12ms/step - loss: 0.2283 - accuracy: 0.9220 - val_loss: 0.3309 - val_accuracy: 0.9020\n",
            "Epoch 42/500\n",
            "110/110 [==============================] - 1s 11ms/step - loss: 0.2278 - accuracy: 0.9219 - val_loss: 0.3305 - val_accuracy: 0.9020\n",
            "Epoch 43/500\n",
            "110/110 [==============================] - 1s 11ms/step - loss: 0.2243 - accuracy: 0.9226 - val_loss: 0.3300 - val_accuracy: 0.9023\n",
            "Epoch 44/500\n",
            "110/110 [==============================] - 1s 11ms/step - loss: 0.2243 - accuracy: 0.9207 - val_loss: 0.3297 - val_accuracy: 0.9027\n",
            "Epoch 45/500\n",
            "110/110 [==============================] - 1s 9ms/step - loss: 0.2283 - accuracy: 0.9199 - val_loss: 0.3292 - val_accuracy: 0.9027\n",
            "Epoch 46/500\n",
            "110/110 [==============================] - 1s 10ms/step - loss: 0.2245 - accuracy: 0.9203 - val_loss: 0.3288 - val_accuracy: 0.9037\n",
            "Epoch 47/500\n",
            "110/110 [==============================] - 1s 11ms/step - loss: 0.2181 - accuracy: 0.9244 - val_loss: 0.3284 - val_accuracy: 0.9040\n",
            "Epoch 48/500\n",
            "110/110 [==============================] - 1s 12ms/step - loss: 0.2229 - accuracy: 0.9219 - val_loss: 0.3279 - val_accuracy: 0.9040\n",
            "Epoch 49/500\n",
            "110/110 [==============================] - 1s 12ms/step - loss: 0.2188 - accuracy: 0.9226 - val_loss: 0.3275 - val_accuracy: 0.9040\n",
            "Epoch 50/500\n",
            "110/110 [==============================] - 1s 12ms/step - loss: 0.2185 - accuracy: 0.9233 - val_loss: 0.3273 - val_accuracy: 0.9033\n",
            "Epoch 51/500\n",
            "110/110 [==============================] - 1s 11ms/step - loss: 0.2208 - accuracy: 0.9213 - val_loss: 0.3268 - val_accuracy: 0.9033\n",
            "Epoch 52/500\n",
            "110/110 [==============================] - 1s 12ms/step - loss: 0.2167 - accuracy: 0.9244 - val_loss: 0.3265 - val_accuracy: 0.9033\n",
            "Epoch 53/500\n",
            "110/110 [==============================] - 1s 12ms/step - loss: 0.2162 - accuracy: 0.9229 - val_loss: 0.3261 - val_accuracy: 0.9037\n",
            "Epoch 54/500\n",
            "110/110 [==============================] - 1s 12ms/step - loss: 0.2131 - accuracy: 0.9233 - val_loss: 0.3258 - val_accuracy: 0.9033\n",
            "Epoch 55/500\n",
            "110/110 [==============================] - 1s 12ms/step - loss: 0.2154 - accuracy: 0.9250 - val_loss: 0.3254 - val_accuracy: 0.9033\n",
            "Epoch 56/500\n",
            "110/110 [==============================] - 1s 12ms/step - loss: 0.2134 - accuracy: 0.9239 - val_loss: 0.3250 - val_accuracy: 0.9030\n",
            "Epoch 57/500\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "110/110 [==============================] - 1s 12ms/step - loss: 0.2154 - accuracy: 0.9257 - val_loss: 0.3248 - val_accuracy: 0.9033\n",
            "Epoch 58/500\n",
            "110/110 [==============================] - 1s 9ms/step - loss: 0.2112 - accuracy: 0.9253 - val_loss: 0.3243 - val_accuracy: 0.9033\n",
            "Epoch 59/500\n",
            "110/110 [==============================] - 1s 11ms/step - loss: 0.2110 - accuracy: 0.9266 - val_loss: 0.3240 - val_accuracy: 0.9033\n",
            "Epoch 60/500\n",
            "110/110 [==============================] - 1s 12ms/step - loss: 0.2091 - accuracy: 0.9279 - val_loss: 0.3237 - val_accuracy: 0.9033\n",
            "Epoch 61/500\n",
            "110/110 [==============================] - 1s 12ms/step - loss: 0.2074 - accuracy: 0.9274 - val_loss: 0.3234 - val_accuracy: 0.9030\n",
            "Epoch 62/500\n",
            "110/110 [==============================] - 1s 12ms/step - loss: 0.2124 - accuracy: 0.9227 - val_loss: 0.3231 - val_accuracy: 0.9030\n",
            "Epoch 63/500\n",
            "110/110 [==============================] - 1s 11ms/step - loss: 0.2082 - accuracy: 0.9260 - val_loss: 0.3227 - val_accuracy: 0.9027\n",
            "Epoch 64/500\n",
            "110/110 [==============================] - 1s 11ms/step - loss: 0.2063 - accuracy: 0.9284 - val_loss: 0.3224 - val_accuracy: 0.9027\n",
            "Epoch 65/500\n",
            "110/110 [==============================] - 1s 11ms/step - loss: 0.2044 - accuracy: 0.9289 - val_loss: 0.3220 - val_accuracy: 0.9023\n",
            "Epoch 66/500\n",
            "110/110 [==============================] - 1s 11ms/step - loss: 0.2060 - accuracy: 0.9267 - val_loss: 0.3217 - val_accuracy: 0.9030\n",
            "Epoch 67/500\n",
            "110/110 [==============================] - 1s 11ms/step - loss: 0.2037 - accuracy: 0.9280 - val_loss: 0.3213 - val_accuracy: 0.9030\n",
            "Epoch 68/500\n",
            "110/110 [==============================] - 1s 11ms/step - loss: 0.2031 - accuracy: 0.9297 - val_loss: 0.3211 - val_accuracy: 0.9033\n",
            "Epoch 69/500\n",
            "110/110 [==============================] - 1s 11ms/step - loss: 0.2015 - accuracy: 0.9307 - val_loss: 0.3207 - val_accuracy: 0.9033\n",
            "Epoch 70/500\n",
            "110/110 [==============================] - 1s 11ms/step - loss: 0.2012 - accuracy: 0.9280 - val_loss: 0.3203 - val_accuracy: 0.9030\n",
            "Epoch 71/500\n",
            "110/110 [==============================] - 1s 9ms/step - loss: 0.2003 - accuracy: 0.9283 - val_loss: 0.3201 - val_accuracy: 0.9030\n",
            "Epoch 72/500\n",
            "110/110 [==============================] - 1s 10ms/step - loss: 0.1941 - accuracy: 0.9317 - val_loss: 0.3198 - val_accuracy: 0.9033\n",
            "Epoch 73/500\n",
            "110/110 [==============================] - 1s 11ms/step - loss: 0.1954 - accuracy: 0.9339 - val_loss: 0.3195 - val_accuracy: 0.9027\n",
            "Epoch 74/500\n",
            "110/110 [==============================] - 1s 11ms/step - loss: 0.1974 - accuracy: 0.9304 - val_loss: 0.3192 - val_accuracy: 0.9030\n",
            "Epoch 75/500\n",
            "110/110 [==============================] - 1s 10ms/step - loss: 0.1915 - accuracy: 0.9319 - val_loss: 0.3189 - val_accuracy: 0.9027\n",
            "Epoch 76/500\n",
            "110/110 [==============================] - 1s 11ms/step - loss: 0.1956 - accuracy: 0.9290 - val_loss: 0.3186 - val_accuracy: 0.9027\n",
            "Epoch 77/500\n",
            "110/110 [==============================] - 1s 11ms/step - loss: 0.1904 - accuracy: 0.9349 - val_loss: 0.3184 - val_accuracy: 0.9030\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0.8991"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "lr_reducer = ReduceLROnPlateau(monitor='val_loss', factor=0.9, patience=3)\n",
        "early_stopper = EarlyStopping(monitor='val_accuracy', min_delta=0, patience=30, mode='auto')\n",
        "model = create_simple_net()\n",
        "\n",
        "model.fit(\n",
        "    x=train_data_1,\n",
        "    y=train_labels_1,\n",
        "    epochs=500,\n",
        "    verbose=1,\n",
        "    validation_split=0.3,\n",
        "    batch_size=64,\n",
        "    callbacks=[lr_reducer, early_stopper]\n",
        ")\n",
        "\n",
        "for i in range(len(model.layers)-1):\n",
        "    model.layers[i].trainable = False\n",
        "    \n",
        "model.compile(\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=0.00001),\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "lr_reducer = ReduceLROnPlateau(monitor='val_loss', factor=0.9, patience=3)\n",
        "early_stopper = EarlyStopping(monitor='val_accuracy', min_delta=0, patience=30, mode='auto')\n",
        "\n",
        "model.fit(\n",
        "    x=train_data,\n",
        "    y=train_labels,\n",
        "    epochs=500,\n",
        "    verbose=1,\n",
        "    validation_split=0.3,\n",
        "    batch_size=64,\n",
        "    callbacks=[lr_reducer, early_stopper]\n",
        ")\n",
        "\n",
        "model.save('/content/drive/MyDrive/파이썬스터디 프로젝트/labeling_fer_resnet_a1.h5')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_eval()"
      ],
      "metadata": {
        "id": "RdSjd0GuVS8k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7R1x771YQ-Vb",
        "outputId": "7177c4a4-a757-47d6-e1c1-d45342c5b745"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "274/274 [==============================] - 4s 14ms/step - loss: 1.6017 - accuracy: 0.8135 - val_loss: 1.6366 - val_accuracy: 0.5920\n",
            "Epoch 2/500\n",
            "274/274 [==============================] - 3s 13ms/step - loss: 1.0112 - accuracy: 0.8792 - val_loss: 0.7154 - val_accuracy: 0.8664\n",
            "Epoch 3/500\n",
            "274/274 [==============================] - 3s 12ms/step - loss: 0.7849 - accuracy: 0.8987 - val_loss: 0.7207 - val_accuracy: 0.8985\n",
            "Epoch 4/500\n",
            "274/274 [==============================] - 3s 12ms/step - loss: 0.6292 - accuracy: 0.9117 - val_loss: 0.5370 - val_accuracy: 0.9220\n",
            "Epoch 5/500\n",
            "274/274 [==============================] - 4s 13ms/step - loss: 0.4803 - accuracy: 0.9243 - val_loss: 0.5016 - val_accuracy: 0.9205\n",
            "Epoch 6/500\n",
            "274/274 [==============================] - 4s 13ms/step - loss: 0.3818 - accuracy: 0.9381 - val_loss: 0.3587 - val_accuracy: 0.9393\n",
            "Epoch 7/500\n",
            "274/274 [==============================] - 3s 13ms/step - loss: 0.3136 - accuracy: 0.9417 - val_loss: 0.3540 - val_accuracy: 0.9373\n",
            "Epoch 8/500\n",
            "274/274 [==============================] - 3s 11ms/step - loss: 0.2654 - accuracy: 0.9487 - val_loss: 0.2717 - val_accuracy: 0.9529\n",
            "Epoch 9/500\n",
            "274/274 [==============================] - 3s 12ms/step - loss: 0.2241 - accuracy: 0.9554 - val_loss: 0.2328 - val_accuracy: 0.9543\n",
            "Epoch 10/500\n",
            "274/274 [==============================] - 3s 12ms/step - loss: 0.1901 - accuracy: 0.9605 - val_loss: 0.2097 - val_accuracy: 0.9539\n",
            "Epoch 11/500\n",
            "274/274 [==============================] - 3s 12ms/step - loss: 0.1674 - accuracy: 0.9653 - val_loss: 0.2011 - val_accuracy: 0.9575\n",
            "Epoch 12/500\n",
            "274/274 [==============================] - 3s 12ms/step - loss: 0.1519 - accuracy: 0.9683 - val_loss: 0.1832 - val_accuracy: 0.9585\n",
            "Epoch 13/500\n",
            "274/274 [==============================] - 3s 12ms/step - loss: 0.1443 - accuracy: 0.9698 - val_loss: 0.1764 - val_accuracy: 0.9611\n",
            "Epoch 14/500\n",
            "274/274 [==============================] - 3s 12ms/step - loss: 0.1394 - accuracy: 0.9719 - val_loss: 0.1777 - val_accuracy: 0.9589\n",
            "Epoch 15/500\n",
            "274/274 [==============================] - 3s 12ms/step - loss: 0.1345 - accuracy: 0.9721 - val_loss: 0.1686 - val_accuracy: 0.9623\n",
            "Epoch 16/500\n",
            "274/274 [==============================] - 3s 12ms/step - loss: 0.1313 - accuracy: 0.9731 - val_loss: 0.1688 - val_accuracy: 0.9628\n",
            "Epoch 17/500\n",
            "274/274 [==============================] - 4s 13ms/step - loss: 0.1317 - accuracy: 0.9741 - val_loss: 0.1675 - val_accuracy: 0.9636\n",
            "Epoch 18/500\n",
            "274/274 [==============================] - 3s 11ms/step - loss: 0.1291 - accuracy: 0.9757 - val_loss: 0.1686 - val_accuracy: 0.9651\n",
            "Epoch 19/500\n",
            "274/274 [==============================] - 4s 13ms/step - loss: 0.1273 - accuracy: 0.9755 - val_loss: 0.1650 - val_accuracy: 0.9624\n",
            "Epoch 20/500\n",
            "274/274 [==============================] - 4s 13ms/step - loss: 0.1268 - accuracy: 0.9759 - val_loss: 0.1657 - val_accuracy: 0.9611\n",
            "Epoch 21/500\n",
            "274/274 [==============================] - 4s 13ms/step - loss: 0.1277 - accuracy: 0.9748 - val_loss: 0.1695 - val_accuracy: 0.9604\n",
            "Epoch 22/500\n",
            "274/274 [==============================] - 3s 12ms/step - loss: 0.1270 - accuracy: 0.9763 - val_loss: 0.1666 - val_accuracy: 0.9617\n",
            "Epoch 23/500\n",
            "274/274 [==============================] - 3s 12ms/step - loss: 0.1231 - accuracy: 0.9768 - val_loss: 0.1630 - val_accuracy: 0.9659\n",
            "Epoch 24/500\n",
            "274/274 [==============================] - 4s 13ms/step - loss: 0.1243 - accuracy: 0.9759 - val_loss: 0.1613 - val_accuracy: 0.9644\n",
            "Epoch 25/500\n",
            "274/274 [==============================] - 4s 13ms/step - loss: 0.1213 - accuracy: 0.9779 - val_loss: 0.1594 - val_accuracy: 0.9663\n",
            "Epoch 26/500\n",
            "274/274 [==============================] - 4s 13ms/step - loss: 0.1226 - accuracy: 0.9762 - val_loss: 0.1665 - val_accuracy: 0.9613\n",
            "Epoch 27/500\n",
            "274/274 [==============================] - 3s 12ms/step - loss: 0.1219 - accuracy: 0.9778 - val_loss: 0.1587 - val_accuracy: 0.9655\n",
            "Epoch 28/500\n",
            "274/274 [==============================] - 4s 13ms/step - loss: 0.1219 - accuracy: 0.9766 - val_loss: 0.1603 - val_accuracy: 0.9632\n",
            "Epoch 29/500\n",
            "274/274 [==============================] - 4s 13ms/step - loss: 0.1213 - accuracy: 0.9779 - val_loss: 0.1621 - val_accuracy: 0.9609\n",
            "Epoch 30/500\n",
            "274/274 [==============================] - 4s 13ms/step - loss: 0.1196 - accuracy: 0.9778 - val_loss: 0.1581 - val_accuracy: 0.9648\n",
            "Epoch 31/500\n",
            "274/274 [==============================] - 3s 13ms/step - loss: 0.1206 - accuracy: 0.9771 - val_loss: 0.1628 - val_accuracy: 0.9635\n",
            "Epoch 32/500\n",
            "274/274 [==============================] - 3s 11ms/step - loss: 0.1186 - accuracy: 0.9791 - val_loss: 0.1598 - val_accuracy: 0.9644\n",
            "Epoch 33/500\n",
            "274/274 [==============================] - 3s 12ms/step - loss: 0.1187 - accuracy: 0.9772 - val_loss: 0.1569 - val_accuracy: 0.9657\n",
            "Epoch 34/500\n",
            "274/274 [==============================] - 3s 12ms/step - loss: 0.1171 - accuracy: 0.9791 - val_loss: 0.1540 - val_accuracy: 0.9664\n",
            "Epoch 35/500\n",
            "274/274 [==============================] - 3s 12ms/step - loss: 0.1177 - accuracy: 0.9787 - val_loss: 0.1541 - val_accuracy: 0.9669\n",
            "Epoch 36/500\n",
            "274/274 [==============================] - 3s 11ms/step - loss: 0.1173 - accuracy: 0.9773 - val_loss: 0.1629 - val_accuracy: 0.9655\n",
            "Epoch 37/500\n",
            "274/274 [==============================] - 3s 11ms/step - loss: 0.1167 - accuracy: 0.9790 - val_loss: 0.1540 - val_accuracy: 0.9656\n",
            "Epoch 38/500\n",
            "274/274 [==============================] - 3s 12ms/step - loss: 0.1133 - accuracy: 0.9798 - val_loss: 0.1558 - val_accuracy: 0.9641\n",
            "Epoch 39/500\n",
            "274/274 [==============================] - 4s 13ms/step - loss: 0.1127 - accuracy: 0.9792 - val_loss: 0.1551 - val_accuracy: 0.9641\n",
            "Epoch 40/500\n",
            "274/274 [==============================] - 4s 13ms/step - loss: 0.1119 - accuracy: 0.9790 - val_loss: 0.1503 - val_accuracy: 0.9661\n",
            "Epoch 41/500\n",
            "274/274 [==============================] - 3s 12ms/step - loss: 0.1107 - accuracy: 0.9795 - val_loss: 0.1549 - val_accuracy: 0.9680\n",
            "Epoch 42/500\n",
            "274/274 [==============================] - 3s 12ms/step - loss: 0.1134 - accuracy: 0.9788 - val_loss: 0.1512 - val_accuracy: 0.9655\n",
            "Epoch 43/500\n",
            "274/274 [==============================] - 4s 13ms/step - loss: 0.1109 - accuracy: 0.9798 - val_loss: 0.1498 - val_accuracy: 0.9667\n",
            "Epoch 44/500\n",
            "274/274 [==============================] - 4s 13ms/step - loss: 0.1110 - accuracy: 0.9790 - val_loss: 0.1479 - val_accuracy: 0.9677\n",
            "Epoch 45/500\n",
            "274/274 [==============================] - 4s 13ms/step - loss: 0.1086 - accuracy: 0.9798 - val_loss: 0.1525 - val_accuracy: 0.9641\n",
            "Epoch 46/500\n",
            "274/274 [==============================] - 3s 11ms/step - loss: 0.1104 - accuracy: 0.9801 - val_loss: 0.1493 - val_accuracy: 0.9661\n",
            "Epoch 47/500\n",
            "274/274 [==============================] - 3s 12ms/step - loss: 0.1095 - accuracy: 0.9799 - val_loss: 0.1546 - val_accuracy: 0.9644\n",
            "Epoch 48/500\n",
            "274/274 [==============================] - 3s 13ms/step - loss: 0.1080 - accuracy: 0.9798 - val_loss: 0.1465 - val_accuracy: 0.9687\n",
            "Epoch 49/500\n",
            "274/274 [==============================] - 4s 13ms/step - loss: 0.1065 - accuracy: 0.9813 - val_loss: 0.1457 - val_accuracy: 0.9691\n",
            "Epoch 50/500\n",
            "274/274 [==============================] - 4s 13ms/step - loss: 0.1069 - accuracy: 0.9799 - val_loss: 0.1501 - val_accuracy: 0.9680\n",
            "Epoch 51/500\n",
            "274/274 [==============================] - 3s 12ms/step - loss: 0.1075 - accuracy: 0.9803 - val_loss: 0.1494 - val_accuracy: 0.9695\n",
            "Epoch 52/500\n",
            "274/274 [==============================] - 3s 12ms/step - loss: 0.1060 - accuracy: 0.9815 - val_loss: 0.1488 - val_accuracy: 0.9679\n",
            "Epoch 53/500\n",
            "274/274 [==============================] - 4s 13ms/step - loss: 0.1057 - accuracy: 0.9807 - val_loss: 0.1456 - val_accuracy: 0.9700\n",
            "Epoch 54/500\n",
            "274/274 [==============================] - 4s 13ms/step - loss: 0.1042 - accuracy: 0.9816 - val_loss: 0.1481 - val_accuracy: 0.9685\n",
            "Epoch 55/500\n",
            "274/274 [==============================] - 3s 12ms/step - loss: 0.1054 - accuracy: 0.9805 - val_loss: 0.1464 - val_accuracy: 0.9669\n",
            "Epoch 56/500\n",
            "274/274 [==============================] - 3s 12ms/step - loss: 0.1044 - accuracy: 0.9821 - val_loss: 0.1474 - val_accuracy: 0.9689\n",
            "Epoch 57/500\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "274/274 [==============================] - 3s 12ms/step - loss: 0.1023 - accuracy: 0.9834 - val_loss: 0.1466 - val_accuracy: 0.9649\n",
            "Epoch 58/500\n",
            "274/274 [==============================] - 3s 12ms/step - loss: 0.1027 - accuracy: 0.9817 - val_loss: 0.1444 - val_accuracy: 0.9692\n",
            "Epoch 59/500\n",
            "274/274 [==============================] - 3s 12ms/step - loss: 0.1022 - accuracy: 0.9826 - val_loss: 0.1456 - val_accuracy: 0.9687\n",
            "Epoch 60/500\n",
            "274/274 [==============================] - 3s 11ms/step - loss: 0.1027 - accuracy: 0.9821 - val_loss: 0.1449 - val_accuracy: 0.9699\n",
            "Epoch 61/500\n",
            "274/274 [==============================] - 3s 12ms/step - loss: 0.1023 - accuracy: 0.9823 - val_loss: 0.1430 - val_accuracy: 0.9691\n",
            "Epoch 62/500\n",
            "274/274 [==============================] - 3s 13ms/step - loss: 0.1017 - accuracy: 0.9813 - val_loss: 0.1428 - val_accuracy: 0.9705\n",
            "Epoch 63/500\n",
            "274/274 [==============================] - 3s 13ms/step - loss: 0.1019 - accuracy: 0.9827 - val_loss: 0.1446 - val_accuracy: 0.9695\n",
            "Epoch 64/500\n",
            "274/274 [==============================] - 3s 13ms/step - loss: 0.1018 - accuracy: 0.9825 - val_loss: 0.1430 - val_accuracy: 0.9699\n",
            "Epoch 65/500\n",
            "274/274 [==============================] - 3s 12ms/step - loss: 0.1013 - accuracy: 0.9830 - val_loss: 0.1419 - val_accuracy: 0.9717\n",
            "Epoch 66/500\n",
            "274/274 [==============================] - 3s 13ms/step - loss: 0.1012 - accuracy: 0.9826 - val_loss: 0.1427 - val_accuracy: 0.9701\n",
            "Epoch 67/500\n",
            "274/274 [==============================] - 4s 13ms/step - loss: 0.1015 - accuracy: 0.9816 - val_loss: 0.1431 - val_accuracy: 0.9673\n",
            "Epoch 68/500\n",
            "274/274 [==============================] - 4s 13ms/step - loss: 0.1002 - accuracy: 0.9820 - val_loss: 0.1454 - val_accuracy: 0.9691\n",
            "Epoch 69/500\n",
            "274/274 [==============================] - 3s 13ms/step - loss: 0.1003 - accuracy: 0.9837 - val_loss: 0.1432 - val_accuracy: 0.9684\n",
            "Epoch 70/500\n",
            "274/274 [==============================] - 3s 11ms/step - loss: 0.1003 - accuracy: 0.9821 - val_loss: 0.1446 - val_accuracy: 0.9692\n",
            "Epoch 71/500\n",
            "274/274 [==============================] - 3s 12ms/step - loss: 0.0994 - accuracy: 0.9831 - val_loss: 0.1414 - val_accuracy: 0.9695\n",
            "Epoch 72/500\n",
            "274/274 [==============================] - 3s 13ms/step - loss: 0.0997 - accuracy: 0.9825 - val_loss: 0.1451 - val_accuracy: 0.9696\n",
            "Epoch 73/500\n",
            "274/274 [==============================] - 3s 12ms/step - loss: 0.0989 - accuracy: 0.9828 - val_loss: 0.1433 - val_accuracy: 0.9693\n",
            "Epoch 74/500\n",
            "274/274 [==============================] - 3s 12ms/step - loss: 0.0989 - accuracy: 0.9826 - val_loss: 0.1429 - val_accuracy: 0.9689\n",
            "Epoch 75/500\n",
            "274/274 [==============================] - 3s 11ms/step - loss: 0.0990 - accuracy: 0.9832 - val_loss: 0.1425 - val_accuracy: 0.9712\n",
            "Epoch 76/500\n",
            "274/274 [==============================] - 4s 13ms/step - loss: 0.0979 - accuracy: 0.9843 - val_loss: 0.1449 - val_accuracy: 0.9676\n",
            "Epoch 77/500\n",
            "274/274 [==============================] - 4s 13ms/step - loss: 0.0981 - accuracy: 0.9826 - val_loss: 0.1403 - val_accuracy: 0.9724\n",
            "Epoch 78/500\n",
            "274/274 [==============================] - 4s 13ms/step - loss: 0.0979 - accuracy: 0.9829 - val_loss: 0.1427 - val_accuracy: 0.9689\n",
            "Epoch 79/500\n",
            "274/274 [==============================] - 3s 12ms/step - loss: 0.0979 - accuracy: 0.9855 - val_loss: 0.1441 - val_accuracy: 0.9697\n",
            "Epoch 80/500\n",
            "274/274 [==============================] - 3s 13ms/step - loss: 0.0981 - accuracy: 0.9826 - val_loss: 0.1439 - val_accuracy: 0.9708\n",
            "Epoch 81/500\n",
            "274/274 [==============================] - 3s 13ms/step - loss: 0.0977 - accuracy: 0.9843 - val_loss: 0.1391 - val_accuracy: 0.9717\n",
            "Epoch 82/500\n",
            "274/274 [==============================] - 3s 12ms/step - loss: 0.0972 - accuracy: 0.9837 - val_loss: 0.1427 - val_accuracy: 0.9695\n",
            "Epoch 83/500\n",
            "274/274 [==============================] - 3s 13ms/step - loss: 0.0973 - accuracy: 0.9835 - val_loss: 0.1405 - val_accuracy: 0.9725\n",
            "Epoch 84/500\n",
            "274/274 [==============================] - 3s 11ms/step - loss: 0.0968 - accuracy: 0.9840 - val_loss: 0.1404 - val_accuracy: 0.9699\n",
            "Epoch 85/500\n",
            "274/274 [==============================] - 3s 12ms/step - loss: 0.0958 - accuracy: 0.9837 - val_loss: 0.1407 - val_accuracy: 0.9704\n",
            "Epoch 86/500\n",
            "274/274 [==============================] - 3s 13ms/step - loss: 0.0963 - accuracy: 0.9844 - val_loss: 0.1400 - val_accuracy: 0.9708\n",
            "Epoch 87/500\n",
            "274/274 [==============================] - 3s 12ms/step - loss: 0.0965 - accuracy: 0.9841 - val_loss: 0.1400 - val_accuracy: 0.9719\n",
            "Epoch 88/500\n",
            "274/274 [==============================] - 4s 13ms/step - loss: 0.0962 - accuracy: 0.9850 - val_loss: 0.1409 - val_accuracy: 0.9689\n",
            "Epoch 89/500\n",
            "274/274 [==============================] - 3s 12ms/step - loss: 0.0957 - accuracy: 0.9846 - val_loss: 0.1406 - val_accuracy: 0.9709\n",
            "Epoch 90/500\n",
            "274/274 [==============================] - 4s 13ms/step - loss: 0.0957 - accuracy: 0.9851 - val_loss: 0.1408 - val_accuracy: 0.9703\n",
            "Epoch 91/500\n",
            "274/274 [==============================] - 4s 13ms/step - loss: 0.0956 - accuracy: 0.9839 - val_loss: 0.1389 - val_accuracy: 0.9715\n",
            "Epoch 92/500\n",
            "274/274 [==============================] - 4s 13ms/step - loss: 0.0957 - accuracy: 0.9842 - val_loss: 0.1408 - val_accuracy: 0.9711\n",
            "Epoch 93/500\n",
            "274/274 [==============================] - 3s 12ms/step - loss: 0.0949 - accuracy: 0.9847 - val_loss: 0.1397 - val_accuracy: 0.9711\n",
            "Epoch 94/500\n",
            "274/274 [==============================] - 3s 13ms/step - loss: 0.0951 - accuracy: 0.9842 - val_loss: 0.1404 - val_accuracy: 0.9724\n",
            "Epoch 95/500\n",
            "274/274 [==============================] - 4s 13ms/step - loss: 0.0946 - accuracy: 0.9855 - val_loss: 0.1396 - val_accuracy: 0.9711\n",
            "Epoch 96/500\n",
            "274/274 [==============================] - 4s 14ms/step - loss: 0.0944 - accuracy: 0.9846 - val_loss: 0.1398 - val_accuracy: 0.9725\n",
            "Epoch 97/500\n",
            "274/274 [==============================] - 4s 13ms/step - loss: 0.0945 - accuracy: 0.9855 - val_loss: 0.1397 - val_accuracy: 0.9721\n",
            "Epoch 98/500\n",
            "274/274 [==============================] - 3s 11ms/step - loss: 0.0939 - accuracy: 0.9859 - val_loss: 0.1389 - val_accuracy: 0.9700\n",
            "Epoch 99/500\n",
            "274/274 [==============================] - 4s 13ms/step - loss: 0.0943 - accuracy: 0.9838 - val_loss: 0.1395 - val_accuracy: 0.9727\n",
            "Epoch 100/500\n",
            "274/274 [==============================] - 3s 12ms/step - loss: 0.0943 - accuracy: 0.9847 - val_loss: 0.1387 - val_accuracy: 0.9724\n",
            "Epoch 101/500\n",
            "274/274 [==============================] - 3s 12ms/step - loss: 0.0941 - accuracy: 0.9858 - val_loss: 0.1376 - val_accuracy: 0.9724\n",
            "Epoch 102/500\n",
            "274/274 [==============================] - 3s 12ms/step - loss: 0.0940 - accuracy: 0.9847 - val_loss: 0.1383 - val_accuracy: 0.9724\n",
            "Epoch 103/500\n",
            "274/274 [==============================] - 3s 12ms/step - loss: 0.0940 - accuracy: 0.9861 - val_loss: 0.1388 - val_accuracy: 0.9716\n",
            "Epoch 104/500\n",
            "274/274 [==============================] - 3s 12ms/step - loss: 0.0941 - accuracy: 0.9846 - val_loss: 0.1394 - val_accuracy: 0.9717\n",
            "Epoch 105/500\n",
            "274/274 [==============================] - 3s 12ms/step - loss: 0.0937 - accuracy: 0.9850 - val_loss: 0.1384 - val_accuracy: 0.9716\n",
            "Epoch 106/500\n",
            "274/274 [==============================] - 3s 12ms/step - loss: 0.0936 - accuracy: 0.9853 - val_loss: 0.1384 - val_accuracy: 0.9717\n",
            "Epoch 107/500\n",
            "274/274 [==============================] - 3s 12ms/step - loss: 0.0935 - accuracy: 0.9854 - val_loss: 0.1375 - val_accuracy: 0.9724\n",
            "Epoch 108/500\n",
            "274/274 [==============================] - 3s 12ms/step - loss: 0.0940 - accuracy: 0.9852 - val_loss: 0.1375 - val_accuracy: 0.9731\n",
            "Epoch 109/500\n",
            "274/274 [==============================] - 4s 13ms/step - loss: 0.0933 - accuracy: 0.9857 - val_loss: 0.1385 - val_accuracy: 0.9752\n",
            "Epoch 110/500\n",
            "274/274 [==============================] - 4s 13ms/step - loss: 0.0936 - accuracy: 0.9855 - val_loss: 0.1380 - val_accuracy: 0.9725\n",
            "Epoch 111/500\n",
            "274/274 [==============================] - 4s 13ms/step - loss: 0.0928 - accuracy: 0.9858 - val_loss: 0.1388 - val_accuracy: 0.9731\n",
            "Epoch 112/500\n",
            "274/274 [==============================] - 3s 12ms/step - loss: 0.0929 - accuracy: 0.9862 - val_loss: 0.1389 - val_accuracy: 0.9691\n",
            "Epoch 113/500\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "274/274 [==============================] - 3s 13ms/step - loss: 0.0936 - accuracy: 0.9842 - val_loss: 0.1379 - val_accuracy: 0.9731\n",
            "Epoch 114/500\n",
            "274/274 [==============================] - 4s 13ms/step - loss: 0.0930 - accuracy: 0.9854 - val_loss: 0.1398 - val_accuracy: 0.9719\n",
            "Epoch 115/500\n",
            "274/274 [==============================] - 4s 13ms/step - loss: 0.0929 - accuracy: 0.9864 - val_loss: 0.1382 - val_accuracy: 0.9736\n",
            "Epoch 116/500\n",
            "274/274 [==============================] - 3s 13ms/step - loss: 0.0926 - accuracy: 0.9862 - val_loss: 0.1396 - val_accuracy: 0.9728\n",
            "Epoch 117/500\n",
            "274/274 [==============================] - 3s 13ms/step - loss: 0.0928 - accuracy: 0.9853 - val_loss: 0.1380 - val_accuracy: 0.9740\n",
            "Epoch 118/500\n",
            "274/274 [==============================] - 4s 13ms/step - loss: 0.0923 - accuracy: 0.9867 - val_loss: 0.1377 - val_accuracy: 0.9737\n",
            "Epoch 119/500\n",
            "274/274 [==============================] - 4s 13ms/step - loss: 0.0925 - accuracy: 0.9859 - val_loss: 0.1375 - val_accuracy: 0.9740\n",
            "Epoch 120/500\n",
            "274/274 [==============================] - 3s 12ms/step - loss: 0.0920 - accuracy: 0.9869 - val_loss: 0.1373 - val_accuracy: 0.9737\n",
            "Epoch 121/500\n",
            "274/274 [==============================] - 3s 10ms/step - loss: 0.0918 - accuracy: 0.9857 - val_loss: 0.1378 - val_accuracy: 0.9727\n",
            "Epoch 122/500\n",
            "274/274 [==============================] - 3s 12ms/step - loss: 0.0923 - accuracy: 0.9861 - val_loss: 0.1376 - val_accuracy: 0.9743\n",
            "Epoch 123/500\n",
            "274/274 [==============================] - 3s 12ms/step - loss: 0.0928 - accuracy: 0.9851 - val_loss: 0.1378 - val_accuracy: 0.9733\n",
            "Epoch 124/500\n",
            "274/274 [==============================] - 3s 12ms/step - loss: 0.0923 - accuracy: 0.9864 - val_loss: 0.1380 - val_accuracy: 0.9720\n",
            "Epoch 125/500\n",
            "274/274 [==============================] - 3s 12ms/step - loss: 0.0918 - accuracy: 0.9866 - val_loss: 0.1374 - val_accuracy: 0.9715\n",
            "Epoch 126/500\n",
            "274/274 [==============================] - 3s 12ms/step - loss: 0.0921 - accuracy: 0.9860 - val_loss: 0.1379 - val_accuracy: 0.9724\n",
            "Epoch 127/500\n",
            "274/274 [==============================] - 3s 13ms/step - loss: 0.0921 - accuracy: 0.9858 - val_loss: 0.1375 - val_accuracy: 0.9736\n",
            "Epoch 128/500\n",
            "274/274 [==============================] - 3s 12ms/step - loss: 0.0918 - accuracy: 0.9859 - val_loss: 0.1376 - val_accuracy: 0.9736\n",
            "Epoch 129/500\n",
            "274/274 [==============================] - 3s 13ms/step - loss: 0.0920 - accuracy: 0.9867 - val_loss: 0.1372 - val_accuracy: 0.9755\n",
            "Epoch 130/500\n",
            "274/274 [==============================] - 4s 13ms/step - loss: 0.0922 - accuracy: 0.9858 - val_loss: 0.1377 - val_accuracy: 0.9740\n",
            "Epoch 131/500\n",
            "274/274 [==============================] - 3s 13ms/step - loss: 0.0918 - accuracy: 0.9867 - val_loss: 0.1369 - val_accuracy: 0.9744\n",
            "Epoch 132/500\n",
            "274/274 [==============================] - 4s 13ms/step - loss: 0.0921 - accuracy: 0.9857 - val_loss: 0.1365 - val_accuracy: 0.9745\n",
            "Epoch 133/500\n",
            "274/274 [==============================] - 4s 13ms/step - loss: 0.0917 - accuracy: 0.9867 - val_loss: 0.1369 - val_accuracy: 0.9739\n",
            "Epoch 134/500\n",
            "274/274 [==============================] - 4s 13ms/step - loss: 0.0920 - accuracy: 0.9858 - val_loss: 0.1366 - val_accuracy: 0.9732\n",
            "Epoch 135/500\n",
            "274/274 [==============================] - 3s 12ms/step - loss: 0.0914 - accuracy: 0.9866 - val_loss: 0.1379 - val_accuracy: 0.9732\n",
            "Epoch 136/500\n",
            "274/274 [==============================] - 3s 13ms/step - loss: 0.0918 - accuracy: 0.9856 - val_loss: 0.1375 - val_accuracy: 0.9735\n",
            "Epoch 137/500\n",
            "274/274 [==============================] - 4s 13ms/step - loss: 0.0914 - accuracy: 0.9859 - val_loss: 0.1370 - val_accuracy: 0.9747\n",
            "Epoch 138/500\n",
            "274/274 [==============================] - 3s 12ms/step - loss: 0.0914 - accuracy: 0.9883 - val_loss: 0.1370 - val_accuracy: 0.9736\n",
            "Epoch 139/500\n",
            "274/274 [==============================] - 3s 13ms/step - loss: 0.0912 - accuracy: 0.9869 - val_loss: 0.1372 - val_accuracy: 0.9733\n",
            "Epoch 140/500\n",
            "274/274 [==============================] - 3s 12ms/step - loss: 0.0913 - accuracy: 0.9862 - val_loss: 0.1372 - val_accuracy: 0.9751\n",
            "Epoch 141/500\n",
            "274/274 [==============================] - 3s 13ms/step - loss: 0.0915 - accuracy: 0.9864 - val_loss: 0.1372 - val_accuracy: 0.9749\n",
            "Epoch 142/500\n",
            "274/274 [==============================] - 3s 13ms/step - loss: 0.0911 - accuracy: 0.9858 - val_loss: 0.1372 - val_accuracy: 0.9757\n",
            "Epoch 143/500\n",
            "274/274 [==============================] - 4s 13ms/step - loss: 0.0915 - accuracy: 0.9875 - val_loss: 0.1364 - val_accuracy: 0.9748\n",
            "Epoch 144/500\n",
            "274/274 [==============================] - 3s 12ms/step - loss: 0.0915 - accuracy: 0.9859 - val_loss: 0.1372 - val_accuracy: 0.9737\n",
            "Epoch 145/500\n",
            "274/274 [==============================] - 3s 11ms/step - loss: 0.0911 - accuracy: 0.9882 - val_loss: 0.1364 - val_accuracy: 0.9755\n",
            "Epoch 146/500\n",
            "274/274 [==============================] - 3s 12ms/step - loss: 0.0917 - accuracy: 0.9855 - val_loss: 0.1366 - val_accuracy: 0.9752\n",
            "Epoch 147/500\n",
            "274/274 [==============================] - 3s 12ms/step - loss: 0.0910 - accuracy: 0.9860 - val_loss: 0.1366 - val_accuracy: 0.9752\n",
            "Epoch 148/500\n",
            "274/274 [==============================] - 3s 13ms/step - loss: 0.0912 - accuracy: 0.9859 - val_loss: 0.1365 - val_accuracy: 0.9756\n",
            "Epoch 149/500\n",
            "274/274 [==============================] - 3s 12ms/step - loss: 0.0909 - accuracy: 0.9870 - val_loss: 0.1365 - val_accuracy: 0.9751\n",
            "Epoch 150/500\n",
            "274/274 [==============================] - 3s 11ms/step - loss: 0.0914 - accuracy: 0.9851 - val_loss: 0.1369 - val_accuracy: 0.9757\n",
            "Epoch 151/500\n",
            "274/274 [==============================] - 3s 12ms/step - loss: 0.0909 - accuracy: 0.9865 - val_loss: 0.1363 - val_accuracy: 0.9765\n",
            "Epoch 152/500\n",
            "274/274 [==============================] - 3s 13ms/step - loss: 0.0908 - accuracy: 0.9873 - val_loss: 0.1369 - val_accuracy: 0.9756\n",
            "Epoch 153/500\n",
            "274/274 [==============================] - 4s 13ms/step - loss: 0.0909 - accuracy: 0.9865 - val_loss: 0.1362 - val_accuracy: 0.9752\n",
            "Epoch 154/500\n",
            "274/274 [==============================] - 3s 11ms/step - loss: 0.0912 - accuracy: 0.9865 - val_loss: 0.1366 - val_accuracy: 0.9760\n",
            "Epoch 155/500\n",
            "274/274 [==============================] - 4s 13ms/step - loss: 0.0909 - accuracy: 0.9870 - val_loss: 0.1368 - val_accuracy: 0.9748\n",
            "Epoch 156/500\n",
            "274/274 [==============================] - 4s 13ms/step - loss: 0.0908 - accuracy: 0.9869 - val_loss: 0.1365 - val_accuracy: 0.9748\n",
            "Epoch 157/500\n",
            "274/274 [==============================] - 3s 11ms/step - loss: 0.0909 - accuracy: 0.9856 - val_loss: 0.1364 - val_accuracy: 0.9756\n",
            "Epoch 158/500\n",
            "274/274 [==============================] - 3s 10ms/step - loss: 0.0911 - accuracy: 0.9871 - val_loss: 0.1361 - val_accuracy: 0.9753\n",
            "Epoch 159/500\n",
            "274/274 [==============================] - 2s 9ms/step - loss: 0.0913 - accuracy: 0.9854 - val_loss: 0.1357 - val_accuracy: 0.9764\n",
            "Epoch 160/500\n",
            "274/274 [==============================] - 3s 10ms/step - loss: 0.0908 - accuracy: 0.9877 - val_loss: 0.1360 - val_accuracy: 0.9756\n",
            "Epoch 161/500\n",
            "274/274 [==============================] - 3s 11ms/step - loss: 0.0907 - accuracy: 0.9869 - val_loss: 0.1362 - val_accuracy: 0.9755\n",
            "Epoch 162/500\n",
            "274/274 [==============================] - 3s 12ms/step - loss: 0.0906 - accuracy: 0.9873 - val_loss: 0.1365 - val_accuracy: 0.9753\n",
            "Epoch 163/500\n",
            "274/274 [==============================] - 3s 12ms/step - loss: 0.0909 - accuracy: 0.9879 - val_loss: 0.1366 - val_accuracy: 0.9760\n",
            "Epoch 164/500\n",
            "274/274 [==============================] - 3s 12ms/step - loss: 0.0908 - accuracy: 0.9862 - val_loss: 0.1366 - val_accuracy: 0.9752\n",
            "Epoch 165/500\n",
            "274/274 [==============================] - 3s 12ms/step - loss: 0.0911 - accuracy: 0.9866 - val_loss: 0.1367 - val_accuracy: 0.9763\n",
            "Epoch 166/500\n",
            "274/274 [==============================] - 3s 12ms/step - loss: 0.0905 - accuracy: 0.9869 - val_loss: 0.1363 - val_accuracy: 0.9753\n",
            "Epoch 167/500\n",
            "274/274 [==============================] - 3s 12ms/step - loss: 0.0906 - accuracy: 0.9877 - val_loss: 0.1362 - val_accuracy: 0.9760\n",
            "Epoch 168/500\n",
            "274/274 [==============================] - 3s 12ms/step - loss: 0.0903 - accuracy: 0.9873 - val_loss: 0.1362 - val_accuracy: 0.9751\n",
            "Epoch 169/500\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "274/274 [==============================] - 3s 12ms/step - loss: 0.0904 - accuracy: 0.9889 - val_loss: 0.1362 - val_accuracy: 0.9763\n",
            "Epoch 170/500\n",
            "274/274 [==============================] - 3s 11ms/step - loss: 0.0904 - accuracy: 0.9872 - val_loss: 0.1361 - val_accuracy: 0.9760\n",
            "Epoch 171/500\n",
            "274/274 [==============================] - 3s 12ms/step - loss: 0.0907 - accuracy: 0.9869 - val_loss: 0.1359 - val_accuracy: 0.9753\n",
            "Epoch 172/500\n",
            "274/274 [==============================] - 3s 12ms/step - loss: 0.0907 - accuracy: 0.9867 - val_loss: 0.1366 - val_accuracy: 0.9755\n",
            "Epoch 173/500\n",
            "274/274 [==============================] - 3s 12ms/step - loss: 0.0903 - accuracy: 0.9869 - val_loss: 0.1363 - val_accuracy: 0.9761\n",
            "Epoch 174/500\n",
            "274/274 [==============================] - 3s 11ms/step - loss: 0.0905 - accuracy: 0.9869 - val_loss: 0.1364 - val_accuracy: 0.9764\n",
            "Epoch 175/500\n",
            "274/274 [==============================] - 3s 12ms/step - loss: 0.0909 - accuracy: 0.9859 - val_loss: 0.1361 - val_accuracy: 0.9764\n",
            "Epoch 176/500\n",
            "274/274 [==============================] - 3s 12ms/step - loss: 0.0905 - accuracy: 0.9878 - val_loss: 0.1363 - val_accuracy: 0.9767\n",
            "Epoch 177/500\n",
            "274/274 [==============================] - 3s 11ms/step - loss: 0.0907 - accuracy: 0.9872 - val_loss: 0.1363 - val_accuracy: 0.9763\n",
            "Epoch 178/500\n",
            "274/274 [==============================] - 3s 12ms/step - loss: 0.0905 - accuracy: 0.9860 - val_loss: 0.1363 - val_accuracy: 0.9761\n",
            "Epoch 179/500\n",
            "274/274 [==============================] - 3s 12ms/step - loss: 0.0903 - accuracy: 0.9882 - val_loss: 0.1361 - val_accuracy: 0.9753\n",
            "Epoch 180/500\n",
            "274/274 [==============================] - 3s 12ms/step - loss: 0.0904 - accuracy: 0.9875 - val_loss: 0.1361 - val_accuracy: 0.9759\n",
            "Epoch 181/500\n",
            "274/274 [==============================] - 4s 13ms/step - loss: 0.0903 - accuracy: 0.9870 - val_loss: 0.1357 - val_accuracy: 0.9768\n",
            "Epoch 182/500\n",
            "274/274 [==============================] - 4s 13ms/step - loss: 0.0902 - accuracy: 0.9870 - val_loss: 0.1365 - val_accuracy: 0.9756\n",
            "Epoch 183/500\n",
            "274/274 [==============================] - 4s 13ms/step - loss: 0.0906 - accuracy: 0.9867 - val_loss: 0.1361 - val_accuracy: 0.9755\n",
            "Epoch 184/500\n",
            "274/274 [==============================] - 3s 11ms/step - loss: 0.0904 - accuracy: 0.9868 - val_loss: 0.1363 - val_accuracy: 0.9764\n",
            "Epoch 185/500\n",
            "274/274 [==============================] - 3s 12ms/step - loss: 0.0907 - accuracy: 0.9873 - val_loss: 0.1362 - val_accuracy: 0.9756\n",
            "Epoch 186/500\n",
            "274/274 [==============================] - 4s 13ms/step - loss: 0.0906 - accuracy: 0.9866 - val_loss: 0.1361 - val_accuracy: 0.9759\n",
            "Epoch 187/500\n",
            "274/274 [==============================] - 4s 13ms/step - loss: 0.0905 - accuracy: 0.9877 - val_loss: 0.1361 - val_accuracy: 0.9764\n",
            "Epoch 188/500\n",
            "274/274 [==============================] - 4s 14ms/step - loss: 0.0902 - accuracy: 0.9874 - val_loss: 0.1361 - val_accuracy: 0.9759\n",
            "Epoch 189/500\n",
            "274/274 [==============================] - 3s 12ms/step - loss: 0.0905 - accuracy: 0.9880 - val_loss: 0.1362 - val_accuracy: 0.9757\n",
            "Epoch 190/500\n",
            "274/274 [==============================] - 4s 13ms/step - loss: 0.0904 - accuracy: 0.9869 - val_loss: 0.1359 - val_accuracy: 0.9761\n",
            "Epoch 191/500\n",
            "274/274 [==============================] - 3s 12ms/step - loss: 0.0900 - accuracy: 0.9883 - val_loss: 0.1359 - val_accuracy: 0.9765\n",
            "Epoch 192/500\n",
            "274/274 [==============================] - 3s 13ms/step - loss: 0.0904 - accuracy: 0.9866 - val_loss: 0.1362 - val_accuracy: 0.9763\n",
            "Epoch 193/500\n",
            "274/274 [==============================] - 3s 12ms/step - loss: 0.0904 - accuracy: 0.9875 - val_loss: 0.1362 - val_accuracy: 0.9763\n",
            "Epoch 194/500\n",
            "274/274 [==============================] - 3s 12ms/step - loss: 0.0905 - accuracy: 0.9867 - val_loss: 0.1361 - val_accuracy: 0.9759\n",
            "Epoch 195/500\n",
            "274/274 [==============================] - 3s 12ms/step - loss: 0.0901 - accuracy: 0.9884 - val_loss: 0.1362 - val_accuracy: 0.9763\n",
            "Epoch 196/500\n",
            "274/274 [==============================] - 3s 12ms/step - loss: 0.0906 - accuracy: 0.9877 - val_loss: 0.1360 - val_accuracy: 0.9764\n",
            "Epoch 197/500\n",
            "274/274 [==============================] - 3s 12ms/step - loss: 0.0903 - accuracy: 0.9871 - val_loss: 0.1362 - val_accuracy: 0.9768\n",
            "Epoch 198/500\n",
            "274/274 [==============================] - 3s 10ms/step - loss: 0.0905 - accuracy: 0.9871 - val_loss: 0.1364 - val_accuracy: 0.9763\n",
            "Epoch 199/500\n",
            "274/274 [==============================] - 3s 11ms/step - loss: 0.0903 - accuracy: 0.9871 - val_loss: 0.1361 - val_accuracy: 0.9765\n",
            "Epoch 200/500\n",
            "274/274 [==============================] - 3s 12ms/step - loss: 0.0902 - accuracy: 0.9870 - val_loss: 0.1360 - val_accuracy: 0.9767\n",
            "Epoch 201/500\n",
            "274/274 [==============================] - 3s 12ms/step - loss: 0.0901 - accuracy: 0.9879 - val_loss: 0.1360 - val_accuracy: 0.9768\n",
            "Epoch 202/500\n",
            "274/274 [==============================] - 3s 12ms/step - loss: 0.0903 - accuracy: 0.9877 - val_loss: 0.1362 - val_accuracy: 0.9763\n",
            "Epoch 203/500\n",
            "274/274 [==============================] - 3s 11ms/step - loss: 0.0902 - accuracy: 0.9877 - val_loss: 0.1361 - val_accuracy: 0.9763\n",
            "Epoch 204/500\n",
            "274/274 [==============================] - 3s 12ms/step - loss: 0.0905 - accuracy: 0.9867 - val_loss: 0.1360 - val_accuracy: 0.9765\n",
            "Epoch 205/500\n",
            "274/274 [==============================] - 3s 13ms/step - loss: 0.0902 - accuracy: 0.9880 - val_loss: 0.1361 - val_accuracy: 0.9768\n",
            "Epoch 206/500\n",
            "274/274 [==============================] - 3s 12ms/step - loss: 0.0903 - accuracy: 0.9877 - val_loss: 0.1362 - val_accuracy: 0.9767\n",
            "Epoch 207/500\n",
            "274/274 [==============================] - 3s 12ms/step - loss: 0.0905 - accuracy: 0.9863 - val_loss: 0.1363 - val_accuracy: 0.9767\n",
            "Epoch 208/500\n",
            "274/274 [==============================] - 3s 11ms/step - loss: 0.0905 - accuracy: 0.9861 - val_loss: 0.1364 - val_accuracy: 0.9764\n",
            "Epoch 209/500\n",
            "274/274 [==============================] - 3s 12ms/step - loss: 0.0903 - accuracy: 0.9877 - val_loss: 0.1361 - val_accuracy: 0.9763\n",
            "Epoch 210/500\n",
            "274/274 [==============================] - 3s 12ms/step - loss: 0.0900 - accuracy: 0.9865 - val_loss: 0.1362 - val_accuracy: 0.9764\n",
            "Epoch 211/500\n",
            "274/274 [==============================] - 3s 12ms/step - loss: 0.0903 - accuracy: 0.9866 - val_loss: 0.1361 - val_accuracy: 0.9769\n",
            "Epoch 212/500\n",
            "274/274 [==============================] - 3s 12ms/step - loss: 0.0902 - accuracy: 0.9875 - val_loss: 0.1361 - val_accuracy: 0.9765\n",
            "Epoch 213/500\n",
            "274/274 [==============================] - 3s 10ms/step - loss: 0.0904 - accuracy: 0.9873 - val_loss: 0.1361 - val_accuracy: 0.9768\n",
            "Epoch 214/500\n",
            "274/274 [==============================] - 3s 12ms/step - loss: 0.0899 - accuracy: 0.9866 - val_loss: 0.1363 - val_accuracy: 0.9767\n",
            "Epoch 215/500\n",
            "274/274 [==============================] - 3s 12ms/step - loss: 0.0902 - accuracy: 0.9873 - val_loss: 0.1362 - val_accuracy: 0.9765\n",
            "Epoch 216/500\n",
            "274/274 [==============================] - 3s 11ms/step - loss: 0.0903 - accuracy: 0.9870 - val_loss: 0.1363 - val_accuracy: 0.9767\n",
            "Epoch 217/500\n",
            "274/274 [==============================] - 3s 11ms/step - loss: 0.0904 - accuracy: 0.9850 - val_loss: 0.1363 - val_accuracy: 0.9768\n",
            "Epoch 218/500\n",
            "274/274 [==============================] - 3s 12ms/step - loss: 0.0903 - accuracy: 0.9885 - val_loss: 0.1362 - val_accuracy: 0.9767\n",
            "Epoch 219/500\n",
            "274/274 [==============================] - 3s 12ms/step - loss: 0.0904 - accuracy: 0.9873 - val_loss: 0.1361 - val_accuracy: 0.9764\n",
            "Epoch 220/500\n",
            "274/274 [==============================] - 3s 12ms/step - loss: 0.0907 - accuracy: 0.9862 - val_loss: 0.1362 - val_accuracy: 0.9763\n",
            "Epoch 221/500\n",
            "274/274 [==============================] - 3s 12ms/step - loss: 0.0901 - accuracy: 0.9873 - val_loss: 0.1362 - val_accuracy: 0.9765\n",
            "Epoch 222/500\n",
            "274/274 [==============================] - 3s 12ms/step - loss: 0.0902 - accuracy: 0.9862 - val_loss: 0.1361 - val_accuracy: 0.9767\n",
            "Epoch 223/500\n",
            "274/274 [==============================] - 3s 11ms/step - loss: 0.0902 - accuracy: 0.9882 - val_loss: 0.1361 - val_accuracy: 0.9771\n",
            "Epoch 224/500\n",
            "274/274 [==============================] - 3s 12ms/step - loss: 0.0900 - accuracy: 0.9874 - val_loss: 0.1361 - val_accuracy: 0.9767\n",
            "Epoch 225/500\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "274/274 [==============================] - 4s 13ms/step - loss: 0.0903 - accuracy: 0.9868 - val_loss: 0.1361 - val_accuracy: 0.9769\n",
            "Epoch 226/500\n",
            "274/274 [==============================] - 4s 13ms/step - loss: 0.0906 - accuracy: 0.9869 - val_loss: 0.1360 - val_accuracy: 0.9764\n",
            "Epoch 227/500\n",
            "274/274 [==============================] - 4s 14ms/step - loss: 0.0901 - accuracy: 0.9875 - val_loss: 0.1361 - val_accuracy: 0.9767\n",
            "Epoch 228/500\n",
            "274/274 [==============================] - 3s 12ms/step - loss: 0.0900 - accuracy: 0.9882 - val_loss: 0.1361 - val_accuracy: 0.9765\n",
            "Epoch 229/500\n",
            "274/274 [==============================] - 4s 13ms/step - loss: 0.0902 - accuracy: 0.9867 - val_loss: 0.1362 - val_accuracy: 0.9768\n",
            "Epoch 230/500\n",
            "274/274 [==============================] - 4s 13ms/step - loss: 0.0900 - accuracy: 0.9869 - val_loss: 0.1363 - val_accuracy: 0.9765\n",
            "Epoch 231/500\n",
            "274/274 [==============================] - 4s 13ms/step - loss: 0.0898 - accuracy: 0.9877 - val_loss: 0.1363 - val_accuracy: 0.9767\n",
            "Epoch 232/500\n",
            "274/274 [==============================] - 3s 12ms/step - loss: 0.0901 - accuracy: 0.9871 - val_loss: 0.1361 - val_accuracy: 0.9767\n",
            "Epoch 233/500\n",
            "274/274 [==============================] - 3s 12ms/step - loss: 0.0901 - accuracy: 0.9873 - val_loss: 0.1361 - val_accuracy: 0.9769\n",
            "Epoch 234/500\n",
            "274/274 [==============================] - 4s 13ms/step - loss: 0.0902 - accuracy: 0.9870 - val_loss: 0.1361 - val_accuracy: 0.9767\n",
            "Epoch 235/500\n",
            "274/274 [==============================] - 4s 13ms/step - loss: 0.0901 - accuracy: 0.9873 - val_loss: 0.1361 - val_accuracy: 0.9765\n",
            "Epoch 236/500\n",
            "274/274 [==============================] - 3s 13ms/step - loss: 0.0901 - accuracy: 0.9865 - val_loss: 0.1361 - val_accuracy: 0.9765\n",
            "Epoch 237/500\n",
            "274/274 [==============================] - 3s 10ms/step - loss: 0.0902 - accuracy: 0.9875 - val_loss: 0.1361 - val_accuracy: 0.9763\n",
            "Epoch 238/500\n",
            "274/274 [==============================] - 3s 11ms/step - loss: 0.0904 - accuracy: 0.9872 - val_loss: 0.1361 - val_accuracy: 0.9763\n",
            "Epoch 239/500\n",
            "274/274 [==============================] - 3s 12ms/step - loss: 0.0905 - accuracy: 0.9873 - val_loss: 0.1361 - val_accuracy: 0.9765\n",
            "Epoch 240/500\n",
            "274/274 [==============================] - 3s 12ms/step - loss: 0.0902 - accuracy: 0.9869 - val_loss: 0.1361 - val_accuracy: 0.9767\n",
            "Epoch 241/500\n",
            "274/274 [==============================] - 3s 12ms/step - loss: 0.0899 - accuracy: 0.9878 - val_loss: 0.1361 - val_accuracy: 0.9763\n",
            "Epoch 242/500\n",
            "274/274 [==============================] - 3s 10ms/step - loss: 0.0903 - accuracy: 0.9882 - val_loss: 0.1361 - val_accuracy: 0.9767\n",
            "Epoch 243/500\n",
            "274/274 [==============================] - 3s 12ms/step - loss: 0.0900 - accuracy: 0.9868 - val_loss: 0.1360 - val_accuracy: 0.9769\n",
            "Epoch 244/500\n",
            "274/274 [==============================] - 3s 12ms/step - loss: 0.0900 - accuracy: 0.9879 - val_loss: 0.1361 - val_accuracy: 0.9769\n",
            "Epoch 245/500\n",
            "274/274 [==============================] - 3s 12ms/step - loss: 0.0905 - accuracy: 0.9877 - val_loss: 0.1361 - val_accuracy: 0.9768\n",
            "Epoch 246/500\n",
            "274/274 [==============================] - 3s 12ms/step - loss: 0.0900 - accuracy: 0.9866 - val_loss: 0.1361 - val_accuracy: 0.9768\n",
            "Epoch 247/500\n",
            "274/274 [==============================] - 3s 12ms/step - loss: 0.0903 - accuracy: 0.9878 - val_loss: 0.1361 - val_accuracy: 0.9767\n",
            "Epoch 248/500\n",
            "274/274 [==============================] - 3s 12ms/step - loss: 0.0902 - accuracy: 0.9869 - val_loss: 0.1360 - val_accuracy: 0.9767\n",
            "Epoch 249/500\n",
            "274/274 [==============================] - 3s 12ms/step - loss: 0.0902 - accuracy: 0.9865 - val_loss: 0.1361 - val_accuracy: 0.9769\n",
            "Epoch 250/500\n",
            "274/274 [==============================] - 4s 13ms/step - loss: 0.0902 - accuracy: 0.9874 - val_loss: 0.1361 - val_accuracy: 0.9768\n",
            "Epoch 251/500\n",
            "274/274 [==============================] - 4s 13ms/step - loss: 0.0903 - accuracy: 0.9885 - val_loss: 0.1360 - val_accuracy: 0.9767\n",
            "Epoch 252/500\n",
            "274/274 [==============================] - 3s 12ms/step - loss: 0.0902 - accuracy: 0.9867 - val_loss: 0.1360 - val_accuracy: 0.9767\n",
            "Epoch 253/500\n",
            "274/274 [==============================] - 4s 13ms/step - loss: 0.0903 - accuracy: 0.9872 - val_loss: 0.1360 - val_accuracy: 0.9772\n",
            "Epoch 254/500\n",
            "274/274 [==============================] - 4s 13ms/step - loss: 0.0900 - accuracy: 0.9880 - val_loss: 0.1360 - val_accuracy: 0.9769\n",
            "Epoch 255/500\n",
            "274/274 [==============================] - 3s 12ms/step - loss: 0.0901 - accuracy: 0.9870 - val_loss: 0.1361 - val_accuracy: 0.9768\n",
            "Epoch 256/500\n",
            "274/274 [==============================] - 3s 13ms/step - loss: 0.0903 - accuracy: 0.9865 - val_loss: 0.1361 - val_accuracy: 0.9769\n",
            "Epoch 257/500\n",
            "274/274 [==============================] - 3s 12ms/step - loss: 0.0904 - accuracy: 0.9865 - val_loss: 0.1360 - val_accuracy: 0.9769\n",
            "Epoch 258/500\n",
            "274/274 [==============================] - 3s 13ms/step - loss: 0.0903 - accuracy: 0.9863 - val_loss: 0.1361 - val_accuracy: 0.9767\n",
            "Epoch 259/500\n",
            "274/274 [==============================] - 4s 13ms/step - loss: 0.0900 - accuracy: 0.9865 - val_loss: 0.1361 - val_accuracy: 0.9769\n",
            "Epoch 260/500\n",
            "274/274 [==============================] - 4s 13ms/step - loss: 0.0904 - accuracy: 0.9875 - val_loss: 0.1361 - val_accuracy: 0.9768\n",
            "Epoch 261/500\n",
            "274/274 [==============================] - 3s 12ms/step - loss: 0.0901 - accuracy: 0.9872 - val_loss: 0.1360 - val_accuracy: 0.9769\n",
            "Epoch 262/500\n",
            "274/274 [==============================] - 3s 12ms/step - loss: 0.0900 - accuracy: 0.9885 - val_loss: 0.1360 - val_accuracy: 0.9771\n",
            "Epoch 263/500\n",
            "274/274 [==============================] - 3s 12ms/step - loss: 0.0901 - accuracy: 0.9859 - val_loss: 0.1360 - val_accuracy: 0.9771\n",
            "Epoch 264/500\n",
            "274/274 [==============================] - 3s 12ms/step - loss: 0.0899 - accuracy: 0.9866 - val_loss: 0.1360 - val_accuracy: 0.9771\n",
            "Epoch 265/500\n",
            "274/274 [==============================] - 3s 12ms/step - loss: 0.0902 - accuracy: 0.9874 - val_loss: 0.1361 - val_accuracy: 0.9771\n",
            "Epoch 266/500\n",
            "274/274 [==============================] - 3s 11ms/step - loss: 0.0901 - accuracy: 0.9876 - val_loss: 0.1361 - val_accuracy: 0.9772\n",
            "Epoch 267/500\n",
            "274/274 [==============================] - 3s 12ms/step - loss: 0.0904 - accuracy: 0.9872 - val_loss: 0.1361 - val_accuracy: 0.9771\n",
            "Epoch 268/500\n",
            "274/274 [==============================] - 3s 12ms/step - loss: 0.0904 - accuracy: 0.9874 - val_loss: 0.1361 - val_accuracy: 0.9769\n",
            "Epoch 269/500\n",
            "274/274 [==============================] - 3s 12ms/step - loss: 0.0901 - accuracy: 0.9875 - val_loss: 0.1361 - val_accuracy: 0.9769\n",
            "Epoch 270/500\n",
            "274/274 [==============================] - 3s 13ms/step - loss: 0.0900 - accuracy: 0.9879 - val_loss: 0.1361 - val_accuracy: 0.9767\n",
            "Epoch 271/500\n",
            "274/274 [==============================] - 3s 12ms/step - loss: 0.0899 - accuracy: 0.9877 - val_loss: 0.1361 - val_accuracy: 0.9767\n",
            "Epoch 272/500\n",
            "274/274 [==============================] - 3s 13ms/step - loss: 0.0900 - accuracy: 0.9870 - val_loss: 0.1361 - val_accuracy: 0.9768\n",
            "Epoch 273/500\n",
            "274/274 [==============================] - 4s 13ms/step - loss: 0.0902 - accuracy: 0.9878 - val_loss: 0.1361 - val_accuracy: 0.9767\n",
            "Epoch 274/500\n",
            "274/274 [==============================] - 4s 13ms/step - loss: 0.0901 - accuracy: 0.9887 - val_loss: 0.1361 - val_accuracy: 0.9767\n",
            "Epoch 275/500\n",
            "274/274 [==============================] - 3s 11ms/step - loss: 0.0901 - accuracy: 0.9875 - val_loss: 0.1361 - val_accuracy: 0.9768\n",
            "Epoch 276/500\n",
            "274/274 [==============================] - 3s 11ms/step - loss: 0.0900 - accuracy: 0.9879 - val_loss: 0.1361 - val_accuracy: 0.9767\n",
            "Epoch 277/500\n",
            "274/274 [==============================] - 3s 13ms/step - loss: 0.0903 - accuracy: 0.9877 - val_loss: 0.1360 - val_accuracy: 0.9769\n",
            "Epoch 278/500\n",
            "274/274 [==============================] - 4s 13ms/step - loss: 0.0901 - accuracy: 0.9885 - val_loss: 0.1361 - val_accuracy: 0.9771\n",
            "Epoch 279/500\n",
            "274/274 [==============================] - 3s 12ms/step - loss: 0.0901 - accuracy: 0.9867 - val_loss: 0.1361 - val_accuracy: 0.9768\n",
            "Epoch 280/500\n",
            "274/274 [==============================] - 3s 10ms/step - loss: 0.0904 - accuracy: 0.9867 - val_loss: 0.1361 - val_accuracy: 0.9768\n",
            "Epoch 281/500\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "274/274 [==============================] - 3s 12ms/step - loss: 0.0902 - accuracy: 0.9871 - val_loss: 0.1361 - val_accuracy: 0.9767\n",
            "Epoch 282/500\n",
            "274/274 [==============================] - 4s 13ms/step - loss: 0.0900 - accuracy: 0.9877 - val_loss: 0.1361 - val_accuracy: 0.9769\n",
            "Epoch 283/500\n",
            "274/274 [==============================] - 4s 13ms/step - loss: 0.0901 - accuracy: 0.9873 - val_loss: 0.1361 - val_accuracy: 0.9767\n",
            "Epoch 1/500\n",
            "110/110 [==============================] - 2s 12ms/step - loss: 0.2936 - accuracy: 0.9081 - val_loss: 0.3574 - val_accuracy: 0.8957\n",
            "Epoch 2/500\n",
            "110/110 [==============================] - 1s 10ms/step - loss: 0.2939 - accuracy: 0.9069 - val_loss: 0.3565 - val_accuracy: 0.8957\n",
            "Epoch 3/500\n",
            "110/110 [==============================] - 1s 11ms/step - loss: 0.2955 - accuracy: 0.9064 - val_loss: 0.3556 - val_accuracy: 0.8967\n",
            "Epoch 4/500\n",
            "110/110 [==============================] - 1s 10ms/step - loss: 0.2882 - accuracy: 0.9084 - val_loss: 0.3548 - val_accuracy: 0.8973\n",
            "Epoch 5/500\n",
            "110/110 [==============================] - 1s 9ms/step - loss: 0.2887 - accuracy: 0.9104 - val_loss: 0.3540 - val_accuracy: 0.8973\n",
            "Epoch 6/500\n",
            "110/110 [==============================] - 1s 11ms/step - loss: 0.2776 - accuracy: 0.9116 - val_loss: 0.3533 - val_accuracy: 0.8970\n",
            "Epoch 7/500\n",
            "110/110 [==============================] - 1s 11ms/step - loss: 0.2833 - accuracy: 0.9099 - val_loss: 0.3526 - val_accuracy: 0.8970\n",
            "Epoch 8/500\n",
            "110/110 [==============================] - 1s 12ms/step - loss: 0.2857 - accuracy: 0.9099 - val_loss: 0.3520 - val_accuracy: 0.8967\n",
            "Epoch 9/500\n",
            "110/110 [==============================] - 1s 11ms/step - loss: 0.2789 - accuracy: 0.9134 - val_loss: 0.3514 - val_accuracy: 0.8967\n",
            "Epoch 10/500\n",
            "110/110 [==============================] - 1s 11ms/step - loss: 0.2804 - accuracy: 0.9101 - val_loss: 0.3507 - val_accuracy: 0.8970\n",
            "Epoch 11/500\n",
            "110/110 [==============================] - 1s 10ms/step - loss: 0.2771 - accuracy: 0.9124 - val_loss: 0.3501 - val_accuracy: 0.8973\n",
            "Epoch 12/500\n",
            "110/110 [==============================] - 1s 11ms/step - loss: 0.2723 - accuracy: 0.9117 - val_loss: 0.3494 - val_accuracy: 0.8970\n",
            "Epoch 13/500\n",
            "110/110 [==============================] - 1s 11ms/step - loss: 0.2761 - accuracy: 0.9090 - val_loss: 0.3488 - val_accuracy: 0.8970\n",
            "Epoch 14/500\n",
            "110/110 [==============================] - 1s 11ms/step - loss: 0.2744 - accuracy: 0.9103 - val_loss: 0.3482 - val_accuracy: 0.8963\n",
            "Epoch 15/500\n",
            "110/110 [==============================] - 1s 9ms/step - loss: 0.2689 - accuracy: 0.9123 - val_loss: 0.3477 - val_accuracy: 0.8960\n",
            "Epoch 16/500\n",
            "110/110 [==============================] - 1s 10ms/step - loss: 0.2643 - accuracy: 0.9121 - val_loss: 0.3471 - val_accuracy: 0.8957\n",
            "Epoch 17/500\n",
            "110/110 [==============================] - 1s 9ms/step - loss: 0.2713 - accuracy: 0.9134 - val_loss: 0.3466 - val_accuracy: 0.8963\n",
            "Epoch 18/500\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.2674 - accuracy: 0.9119 - val_loss: 0.3460 - val_accuracy: 0.8960\n",
            "Epoch 19/500\n",
            "110/110 [==============================] - 1s 8ms/step - loss: 0.2692 - accuracy: 0.9083 - val_loss: 0.3455 - val_accuracy: 0.8960\n",
            "Epoch 20/500\n",
            "110/110 [==============================] - 1s 9ms/step - loss: 0.2612 - accuracy: 0.9139 - val_loss: 0.3450 - val_accuracy: 0.8960\n",
            "Epoch 21/500\n",
            "110/110 [==============================] - 1s 10ms/step - loss: 0.2666 - accuracy: 0.9120 - val_loss: 0.3445 - val_accuracy: 0.8957\n",
            "Epoch 22/500\n",
            "110/110 [==============================] - 1s 11ms/step - loss: 0.2652 - accuracy: 0.9140 - val_loss: 0.3440 - val_accuracy: 0.8960\n",
            "Epoch 23/500\n",
            "110/110 [==============================] - 1s 11ms/step - loss: 0.2635 - accuracy: 0.9143 - val_loss: 0.3434 - val_accuracy: 0.8963\n",
            "Epoch 24/500\n",
            "110/110 [==============================] - 1s 10ms/step - loss: 0.2594 - accuracy: 0.9154 - val_loss: 0.3430 - val_accuracy: 0.8967\n",
            "Epoch 25/500\n",
            "110/110 [==============================] - 1s 11ms/step - loss: 0.2571 - accuracy: 0.9123 - val_loss: 0.3425 - val_accuracy: 0.8970\n",
            "Epoch 26/500\n",
            "110/110 [==============================] - 1s 11ms/step - loss: 0.2560 - accuracy: 0.9149 - val_loss: 0.3419 - val_accuracy: 0.8970\n",
            "Epoch 27/500\n",
            "110/110 [==============================] - 1s 10ms/step - loss: 0.2578 - accuracy: 0.9150 - val_loss: 0.3415 - val_accuracy: 0.8963\n",
            "Epoch 28/500\n",
            "110/110 [==============================] - 1s 11ms/step - loss: 0.2603 - accuracy: 0.9156 - val_loss: 0.3409 - val_accuracy: 0.8967\n",
            "Epoch 29/500\n",
            "110/110 [==============================] - 1s 11ms/step - loss: 0.2551 - accuracy: 0.9137 - val_loss: 0.3404 - val_accuracy: 0.8970\n",
            "Epoch 30/500\n",
            "110/110 [==============================] - 1s 11ms/step - loss: 0.2525 - accuracy: 0.9157 - val_loss: 0.3400 - val_accuracy: 0.8973\n",
            "Epoch 31/500\n",
            "110/110 [==============================] - 1s 12ms/step - loss: 0.2559 - accuracy: 0.9141 - val_loss: 0.3396 - val_accuracy: 0.8973\n",
            "Epoch 32/500\n",
            "110/110 [==============================] - 1s 10ms/step - loss: 0.2497 - accuracy: 0.9156 - val_loss: 0.3391 - val_accuracy: 0.8973\n",
            "Epoch 33/500\n",
            "110/110 [==============================] - 1s 10ms/step - loss: 0.2501 - accuracy: 0.9186 - val_loss: 0.3387 - val_accuracy: 0.8977\n",
            "Epoch 34/500\n",
            "110/110 [==============================] - 1s 11ms/step - loss: 0.2485 - accuracy: 0.9171 - val_loss: 0.3382 - val_accuracy: 0.8980\n",
            "Epoch 35/500\n",
            "110/110 [==============================] - 1s 11ms/step - loss: 0.2470 - accuracy: 0.9180 - val_loss: 0.3377 - val_accuracy: 0.8980\n",
            "Epoch 36/500\n",
            "110/110 [==============================] - 1s 12ms/step - loss: 0.2496 - accuracy: 0.9167 - val_loss: 0.3373 - val_accuracy: 0.8980\n",
            "Epoch 37/500\n",
            "110/110 [==============================] - 1s 12ms/step - loss: 0.2486 - accuracy: 0.9171 - val_loss: 0.3368 - val_accuracy: 0.8980\n",
            "Epoch 38/500\n",
            "110/110 [==============================] - 1s 13ms/step - loss: 0.2393 - accuracy: 0.9196 - val_loss: 0.3364 - val_accuracy: 0.8980\n",
            "Epoch 39/500\n",
            "110/110 [==============================] - 1s 12ms/step - loss: 0.2412 - accuracy: 0.9184 - val_loss: 0.3360 - val_accuracy: 0.8980\n",
            "Epoch 40/500\n",
            "110/110 [==============================] - 1s 11ms/step - loss: 0.2428 - accuracy: 0.9201 - val_loss: 0.3356 - val_accuracy: 0.8983\n",
            "Epoch 41/500\n",
            "110/110 [==============================] - 1s 12ms/step - loss: 0.2420 - accuracy: 0.9144 - val_loss: 0.3351 - val_accuracy: 0.8983\n",
            "Epoch 42/500\n",
            "110/110 [==============================] - 1s 12ms/step - loss: 0.2418 - accuracy: 0.9173 - val_loss: 0.3347 - val_accuracy: 0.8987\n",
            "Epoch 43/500\n",
            "110/110 [==============================] - 1s 12ms/step - loss: 0.2394 - accuracy: 0.9167 - val_loss: 0.3344 - val_accuracy: 0.8987\n",
            "Epoch 44/500\n",
            "110/110 [==============================] - 1s 13ms/step - loss: 0.2373 - accuracy: 0.9191 - val_loss: 0.3340 - val_accuracy: 0.8990\n",
            "Epoch 45/500\n",
            "110/110 [==============================] - 1s 8ms/step - loss: 0.2354 - accuracy: 0.9217 - val_loss: 0.3335 - val_accuracy: 0.8990\n",
            "Epoch 46/500\n",
            "110/110 [==============================] - 1s 10ms/step - loss: 0.2364 - accuracy: 0.9184 - val_loss: 0.3332 - val_accuracy: 0.8990\n",
            "Epoch 47/500\n",
            "110/110 [==============================] - 1s 11ms/step - loss: 0.2343 - accuracy: 0.9203 - val_loss: 0.3328 - val_accuracy: 0.8993\n",
            "Epoch 48/500\n",
            "110/110 [==============================] - 1s 11ms/step - loss: 0.2360 - accuracy: 0.9197 - val_loss: 0.3324 - val_accuracy: 0.8993\n",
            "Epoch 49/500\n",
            "110/110 [==============================] - 1s 11ms/step - loss: 0.2302 - accuracy: 0.9231 - val_loss: 0.3320 - val_accuracy: 0.8997\n",
            "Epoch 50/500\n",
            "110/110 [==============================] - 1s 11ms/step - loss: 0.2365 - accuracy: 0.9184 - val_loss: 0.3317 - val_accuracy: 0.8997\n",
            "Epoch 51/500\n",
            "110/110 [==============================] - 1s 11ms/step - loss: 0.2318 - accuracy: 0.9200 - val_loss: 0.3314 - val_accuracy: 0.8997\n",
            "Epoch 52/500\n",
            "110/110 [==============================] - 1s 11ms/step - loss: 0.2289 - accuracy: 0.9226 - val_loss: 0.3310 - val_accuracy: 0.8997\n",
            "Epoch 53/500\n",
            "110/110 [==============================] - 1s 10ms/step - loss: 0.2267 - accuracy: 0.9206 - val_loss: 0.3306 - val_accuracy: 0.8997\n",
            "Epoch 54/500\n",
            "110/110 [==============================] - 1s 11ms/step - loss: 0.2281 - accuracy: 0.9214 - val_loss: 0.3302 - val_accuracy: 0.8997\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 55/500\n",
            "110/110 [==============================] - 1s 12ms/step - loss: 0.2279 - accuracy: 0.9224 - val_loss: 0.3298 - val_accuracy: 0.8997\n",
            "Epoch 56/500\n",
            "110/110 [==============================] - 1s 11ms/step - loss: 0.2248 - accuracy: 0.9217 - val_loss: 0.3295 - val_accuracy: 0.8997\n",
            "Epoch 57/500\n",
            "110/110 [==============================] - 1s 11ms/step - loss: 0.2242 - accuracy: 0.9243 - val_loss: 0.3291 - val_accuracy: 0.8997\n",
            "Epoch 58/500\n",
            "110/110 [==============================] - 1s 8ms/step - loss: 0.2270 - accuracy: 0.9239 - val_loss: 0.3288 - val_accuracy: 0.8997\n",
            "Epoch 59/500\n",
            "110/110 [==============================] - 1s 8ms/step - loss: 0.2213 - accuracy: 0.9229 - val_loss: 0.3284 - val_accuracy: 0.9000\n",
            "Epoch 60/500\n",
            "110/110 [==============================] - 1s 10ms/step - loss: 0.2214 - accuracy: 0.9219 - val_loss: 0.3281 - val_accuracy: 0.9003\n",
            "Epoch 61/500\n",
            "110/110 [==============================] - 1s 10ms/step - loss: 0.2208 - accuracy: 0.9214 - val_loss: 0.3278 - val_accuracy: 0.9010\n",
            "Epoch 62/500\n",
            "110/110 [==============================] - 1s 11ms/step - loss: 0.2253 - accuracy: 0.9259 - val_loss: 0.3275 - val_accuracy: 0.9007\n",
            "Epoch 63/500\n",
            "110/110 [==============================] - 1s 12ms/step - loss: 0.2186 - accuracy: 0.9226 - val_loss: 0.3272 - val_accuracy: 0.9007\n",
            "Epoch 64/500\n",
            "110/110 [==============================] - 1s 12ms/step - loss: 0.2222 - accuracy: 0.9229 - val_loss: 0.3270 - val_accuracy: 0.9007\n",
            "Epoch 65/500\n",
            "110/110 [==============================] - 1s 12ms/step - loss: 0.2195 - accuracy: 0.9244 - val_loss: 0.3266 - val_accuracy: 0.9000\n",
            "Epoch 66/500\n",
            "110/110 [==============================] - 1s 12ms/step - loss: 0.2163 - accuracy: 0.9264 - val_loss: 0.3263 - val_accuracy: 0.9000\n",
            "Epoch 67/500\n",
            "110/110 [==============================] - 1s 12ms/step - loss: 0.2118 - accuracy: 0.9293 - val_loss: 0.3260 - val_accuracy: 0.8997\n",
            "Epoch 68/500\n",
            "110/110 [==============================] - 1s 11ms/step - loss: 0.2117 - accuracy: 0.9236 - val_loss: 0.3258 - val_accuracy: 0.8997\n",
            "Epoch 69/500\n",
            "110/110 [==============================] - 1s 11ms/step - loss: 0.2108 - accuracy: 0.9261 - val_loss: 0.3255 - val_accuracy: 0.8997\n",
            "Epoch 70/500\n",
            "110/110 [==============================] - 1s 12ms/step - loss: 0.2192 - accuracy: 0.9240 - val_loss: 0.3252 - val_accuracy: 0.8993\n",
            "Epoch 71/500\n",
            "110/110 [==============================] - 1s 10ms/step - loss: 0.2102 - accuracy: 0.9269 - val_loss: 0.3248 - val_accuracy: 0.8993\n",
            "Epoch 72/500\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.2156 - accuracy: 0.9240 - val_loss: 0.3245 - val_accuracy: 0.8993\n",
            "Epoch 73/500\n",
            "110/110 [==============================] - 1s 10ms/step - loss: 0.2127 - accuracy: 0.9244 - val_loss: 0.3243 - val_accuracy: 0.8997\n",
            "Epoch 74/500\n",
            "110/110 [==============================] - 1s 11ms/step - loss: 0.2111 - accuracy: 0.9276 - val_loss: 0.3240 - val_accuracy: 0.8993\n",
            "Epoch 75/500\n",
            "110/110 [==============================] - 1s 11ms/step - loss: 0.2095 - accuracy: 0.9293 - val_loss: 0.3237 - val_accuracy: 0.8997\n",
            "Epoch 76/500\n",
            "110/110 [==============================] - 1s 10ms/step - loss: 0.2078 - accuracy: 0.9267 - val_loss: 0.3234 - val_accuracy: 0.8993\n",
            "Epoch 77/500\n",
            "110/110 [==============================] - 1s 11ms/step - loss: 0.2088 - accuracy: 0.9261 - val_loss: 0.3232 - val_accuracy: 0.8993\n",
            "Epoch 78/500\n",
            "110/110 [==============================] - 1s 11ms/step - loss: 0.2060 - accuracy: 0.9273 - val_loss: 0.3229 - val_accuracy: 0.8997\n",
            "Epoch 79/500\n",
            "110/110 [==============================] - 1s 11ms/step - loss: 0.2096 - accuracy: 0.9284 - val_loss: 0.3226 - val_accuracy: 0.9000\n",
            "Epoch 80/500\n",
            "110/110 [==============================] - 1s 11ms/step - loss: 0.2055 - accuracy: 0.9289 - val_loss: 0.3223 - val_accuracy: 0.9000\n",
            "Epoch 81/500\n",
            "110/110 [==============================] - 1s 11ms/step - loss: 0.2086 - accuracy: 0.9283 - val_loss: 0.3219 - val_accuracy: 0.9003\n",
            "Epoch 82/500\n",
            "110/110 [==============================] - 1s 11ms/step - loss: 0.2058 - accuracy: 0.9277 - val_loss: 0.3217 - val_accuracy: 0.9003\n",
            "Epoch 83/500\n",
            "110/110 [==============================] - 1s 11ms/step - loss: 0.2053 - accuracy: 0.9291 - val_loss: 0.3214 - val_accuracy: 0.9003\n",
            "Epoch 84/500\n",
            "110/110 [==============================] - 1s 11ms/step - loss: 0.2015 - accuracy: 0.9283 - val_loss: 0.3211 - val_accuracy: 0.9003\n",
            "Epoch 85/500\n",
            "110/110 [==============================] - 1s 10ms/step - loss: 0.2056 - accuracy: 0.9290 - val_loss: 0.3208 - val_accuracy: 0.9007\n",
            "Epoch 86/500\n",
            "110/110 [==============================] - 1s 9ms/step - loss: 0.2020 - accuracy: 0.9299 - val_loss: 0.3206 - val_accuracy: 0.9007\n",
            "Epoch 87/500\n",
            "110/110 [==============================] - 1s 10ms/step - loss: 0.2022 - accuracy: 0.9309 - val_loss: 0.3203 - val_accuracy: 0.9007\n",
            "Epoch 88/500\n",
            "110/110 [==============================] - 1s 11ms/step - loss: 0.2015 - accuracy: 0.9300 - val_loss: 0.3201 - val_accuracy: 0.9007\n",
            "Epoch 89/500\n",
            "110/110 [==============================] - 1s 11ms/step - loss: 0.1964 - accuracy: 0.9309 - val_loss: 0.3199 - val_accuracy: 0.9010\n",
            "Epoch 90/500\n",
            "110/110 [==============================] - 1s 12ms/step - loss: 0.1998 - accuracy: 0.9306 - val_loss: 0.3197 - val_accuracy: 0.9003\n",
            "Epoch 91/500\n",
            "110/110 [==============================] - 1s 10ms/step - loss: 0.1949 - accuracy: 0.9314 - val_loss: 0.3195 - val_accuracy: 0.9000\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0.8952"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "lr_reducer = ReduceLROnPlateau(monitor='val_loss', factor=0.9, patience=3)\n",
        "early_stopper = EarlyStopping(monitor='val_accuracy', min_delta=0, patience=30, mode='auto')\n",
        "model = create_simple_net()\n",
        "\n",
        "model.fit(\n",
        "    x=train_data_2,\n",
        "    y=train_labels_2,\n",
        "    epochs=500,\n",
        "    verbose=1,\n",
        "    validation_split=0.3,\n",
        "    batch_size=64,\n",
        "    callbacks=[lr_reducer, early_stopper]\n",
        ")\n",
        "\n",
        "for i in range(len(model.layers)-1):\n",
        "    model.layers[i].trainable = False\n",
        "    \n",
        "model.compile(\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=0.00001),\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "lr_reducer = ReduceLROnPlateau(monitor='val_loss', factor=0.9, patience=3)\n",
        "early_stopper = EarlyStopping(monitor='val_accuracy', min_delta=0, patience=30, mode='auto')\n",
        "\n",
        "model.fit(\n",
        "    x=train_data,\n",
        "    y=train_labels,\n",
        "    epochs=500,\n",
        "    verbose=1,\n",
        "    validation_split=0.3,\n",
        "    batch_size=64,\n",
        "    callbacks=[lr_reducer, early_stopper]\n",
        ")\n",
        "\n",
        "model.save('/content/drive/MyDrive/파이썬스터디 프로젝트/labeling_fer_resnet_b1.h5')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_eval()"
      ],
      "metadata": {
        "id": "wMWqorK5RE5z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XpTO55j8Q-Vb",
        "outputId": "ec3f9fe7-c936-4a9c-a464-4f1eb69bc754"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "274/274 [==============================] - 4s 14ms/step - loss: 1.6269 - accuracy: 0.8088 - val_loss: 2.1935 - val_accuracy: 0.6063\n",
            "Epoch 2/500\n",
            "274/274 [==============================] - 4s 13ms/step - loss: 1.1957 - accuracy: 0.8609 - val_loss: 0.9842 - val_accuracy: 0.8457\n",
            "Epoch 3/500\n",
            "274/274 [==============================] - 3s 11ms/step - loss: 0.9174 - accuracy: 0.8803 - val_loss: 0.8493 - val_accuracy: 0.8808\n",
            "Epoch 4/500\n",
            "274/274 [==============================] - 3s 12ms/step - loss: 0.7213 - accuracy: 0.8934 - val_loss: 0.7761 - val_accuracy: 0.8811\n",
            "Epoch 5/500\n",
            "274/274 [==============================] - 4s 13ms/step - loss: 0.5359 - accuracy: 0.9089 - val_loss: 0.6201 - val_accuracy: 0.8939\n",
            "Epoch 6/500\n",
            "274/274 [==============================] - 4s 13ms/step - loss: 0.4314 - accuracy: 0.9168 - val_loss: 0.5274 - val_accuracy: 0.8948\n",
            "Epoch 7/500\n",
            "274/274 [==============================] - 3s 12ms/step - loss: 0.3558 - accuracy: 0.9285 - val_loss: 0.4452 - val_accuracy: 0.9044\n",
            "Epoch 8/500\n",
            "274/274 [==============================] - 3s 11ms/step - loss: 0.2856 - accuracy: 0.9367 - val_loss: 0.3832 - val_accuracy: 0.9068\n",
            "Epoch 9/500\n",
            "274/274 [==============================] - 3s 12ms/step - loss: 0.2397 - accuracy: 0.9383 - val_loss: 0.3476 - val_accuracy: 0.9089\n",
            "Epoch 10/500\n",
            "274/274 [==============================] - 3s 12ms/step - loss: 0.2087 - accuracy: 0.9471 - val_loss: 0.3259 - val_accuracy: 0.9117\n",
            "Epoch 11/500\n",
            "274/274 [==============================] - 3s 12ms/step - loss: 0.1865 - accuracy: 0.9521 - val_loss: 0.2938 - val_accuracy: 0.9163\n",
            "Epoch 12/500\n",
            "274/274 [==============================] - 3s 13ms/step - loss: 0.1708 - accuracy: 0.9558 - val_loss: 0.2828 - val_accuracy: 0.9171\n",
            "Epoch 13/500\n",
            "274/274 [==============================] - 3s 12ms/step - loss: 0.1594 - accuracy: 0.9623 - val_loss: 0.2745 - val_accuracy: 0.9180\n",
            "Epoch 14/500\n",
            "274/274 [==============================] - 4s 13ms/step - loss: 0.1572 - accuracy: 0.9617 - val_loss: 0.2682 - val_accuracy: 0.9204\n",
            "Epoch 15/500\n",
            "274/274 [==============================] - 4s 14ms/step - loss: 0.1533 - accuracy: 0.9638 - val_loss: 0.2692 - val_accuracy: 0.9191\n",
            "Epoch 16/500\n",
            "274/274 [==============================] - 4s 13ms/step - loss: 0.1473 - accuracy: 0.9659 - val_loss: 0.2757 - val_accuracy: 0.9129\n",
            "Epoch 17/500\n",
            "274/274 [==============================] - 3s 12ms/step - loss: 0.1481 - accuracy: 0.9640 - val_loss: 0.2800 - val_accuracy: 0.9188\n",
            "Epoch 18/500\n",
            "274/274 [==============================] - 4s 13ms/step - loss: 0.1436 - accuracy: 0.9671 - val_loss: 0.2630 - val_accuracy: 0.9251\n",
            "Epoch 19/500\n",
            "274/274 [==============================] - 4s 13ms/step - loss: 0.1400 - accuracy: 0.9684 - val_loss: 0.2568 - val_accuracy: 0.9219\n",
            "Epoch 20/500\n",
            "274/274 [==============================] - 4s 13ms/step - loss: 0.1388 - accuracy: 0.9697 - val_loss: 0.2644 - val_accuracy: 0.9225\n",
            "Epoch 21/500\n",
            "274/274 [==============================] - 4s 13ms/step - loss: 0.1375 - accuracy: 0.9695 - val_loss: 0.2651 - val_accuracy: 0.9199\n",
            "Epoch 22/500\n",
            "274/274 [==============================] - 3s 12ms/step - loss: 0.1377 - accuracy: 0.9714 - val_loss: 0.2555 - val_accuracy: 0.9211\n",
            "Epoch 23/500\n",
            "274/274 [==============================] - 4s 13ms/step - loss: 0.1398 - accuracy: 0.9671 - val_loss: 0.2684 - val_accuracy: 0.9183\n",
            "Epoch 24/500\n",
            "274/274 [==============================] - 4s 13ms/step - loss: 0.1384 - accuracy: 0.9684 - val_loss: 0.2582 - val_accuracy: 0.9232\n",
            "Epoch 25/500\n",
            "274/274 [==============================] - 4s 13ms/step - loss: 0.1372 - accuracy: 0.9707 - val_loss: 0.2578 - val_accuracy: 0.9241\n",
            "Epoch 26/500\n",
            "274/274 [==============================] - 3s 12ms/step - loss: 0.1339 - accuracy: 0.9720 - val_loss: 0.2570 - val_accuracy: 0.9213\n",
            "Epoch 27/500\n",
            "274/274 [==============================] - 4s 13ms/step - loss: 0.1312 - accuracy: 0.9741 - val_loss: 0.2584 - val_accuracy: 0.9208\n",
            "Epoch 28/500\n",
            "274/274 [==============================] - 4s 13ms/step - loss: 0.1310 - accuracy: 0.9725 - val_loss: 0.2526 - val_accuracy: 0.9209\n",
            "Epoch 29/500\n",
            "274/274 [==============================] - 3s 12ms/step - loss: 0.1292 - accuracy: 0.9739 - val_loss: 0.2552 - val_accuracy: 0.9251\n",
            "Epoch 30/500\n",
            "274/274 [==============================] - 3s 12ms/step - loss: 0.1304 - accuracy: 0.9712 - val_loss: 0.2592 - val_accuracy: 0.9229\n",
            "Epoch 31/500\n",
            "274/274 [==============================] - 3s 12ms/step - loss: 0.1273 - accuracy: 0.9750 - val_loss: 0.2595 - val_accuracy: 0.9245\n",
            "Epoch 32/500\n",
            "274/274 [==============================] - 3s 13ms/step - loss: 0.1264 - accuracy: 0.9709 - val_loss: 0.2679 - val_accuracy: 0.9195\n",
            "Epoch 33/500\n",
            "274/274 [==============================] - 3s 13ms/step - loss: 0.1236 - accuracy: 0.9758 - val_loss: 0.2557 - val_accuracy: 0.9212\n",
            "Epoch 34/500\n",
            "274/274 [==============================] - 3s 13ms/step - loss: 0.1234 - accuracy: 0.9750 - val_loss: 0.2522 - val_accuracy: 0.9247\n",
            "Epoch 35/500\n",
            "274/274 [==============================] - 3s 12ms/step - loss: 0.1246 - accuracy: 0.9760 - val_loss: 0.2495 - val_accuracy: 0.9243\n",
            "Epoch 36/500\n",
            "274/274 [==============================] - 3s 10ms/step - loss: 0.1212 - accuracy: 0.9748 - val_loss: 0.2522 - val_accuracy: 0.9225\n",
            "Epoch 37/500\n",
            "274/274 [==============================] - 4s 13ms/step - loss: 0.1209 - accuracy: 0.9765 - val_loss: 0.2560 - val_accuracy: 0.9228\n",
            "Epoch 38/500\n",
            "274/274 [==============================] - 4s 13ms/step - loss: 0.1231 - accuracy: 0.9742 - val_loss: 0.2489 - val_accuracy: 0.9225\n",
            "Epoch 39/500\n",
            "274/274 [==============================] - 4s 13ms/step - loss: 0.1212 - accuracy: 0.9740 - val_loss: 0.2522 - val_accuracy: 0.9248\n",
            "Epoch 40/500\n",
            "274/274 [==============================] - 3s 12ms/step - loss: 0.1203 - accuracy: 0.9762 - val_loss: 0.2511 - val_accuracy: 0.9263\n",
            "Epoch 41/500\n",
            "274/274 [==============================] - 3s 13ms/step - loss: 0.1196 - accuracy: 0.9758 - val_loss: 0.2520 - val_accuracy: 0.9248\n",
            "Epoch 42/500\n",
            "274/274 [==============================] - 4s 13ms/step - loss: 0.1160 - accuracy: 0.9786 - val_loss: 0.2427 - val_accuracy: 0.9237\n",
            "Epoch 43/500\n",
            "274/274 [==============================] - 4s 13ms/step - loss: 0.1161 - accuracy: 0.9782 - val_loss: 0.2487 - val_accuracy: 0.9259\n",
            "Epoch 44/500\n",
            "274/274 [==============================] - 4s 13ms/step - loss: 0.1145 - accuracy: 0.9782 - val_loss: 0.2479 - val_accuracy: 0.9248\n",
            "Epoch 45/500\n",
            "274/274 [==============================] - 3s 12ms/step - loss: 0.1152 - accuracy: 0.9749 - val_loss: 0.2485 - val_accuracy: 0.9273\n",
            "Epoch 46/500\n",
            "274/274 [==============================] - 4s 13ms/step - loss: 0.1142 - accuracy: 0.9776 - val_loss: 0.2484 - val_accuracy: 0.9271\n",
            "Epoch 47/500\n",
            "274/274 [==============================] - 4s 13ms/step - loss: 0.1126 - accuracy: 0.9811 - val_loss: 0.2446 - val_accuracy: 0.9281\n",
            "Epoch 48/500\n",
            "274/274 [==============================] - 4s 14ms/step - loss: 0.1124 - accuracy: 0.9787 - val_loss: 0.2450 - val_accuracy: 0.9287\n",
            "Epoch 49/500\n",
            "274/274 [==============================] - 4s 13ms/step - loss: 0.1108 - accuracy: 0.9790 - val_loss: 0.2452 - val_accuracy: 0.9231\n",
            "Epoch 50/500\n",
            "274/274 [==============================] - 3s 12ms/step - loss: 0.1101 - accuracy: 0.9803 - val_loss: 0.2441 - val_accuracy: 0.9287\n",
            "Epoch 51/500\n",
            "274/274 [==============================] - 3s 13ms/step - loss: 0.1094 - accuracy: 0.9787 - val_loss: 0.2522 - val_accuracy: 0.9259\n",
            "Epoch 52/500\n",
            "274/274 [==============================] - 3s 12ms/step - loss: 0.1093 - accuracy: 0.9787 - val_loss: 0.2435 - val_accuracy: 0.9287\n",
            "Epoch 53/500\n",
            "274/274 [==============================] - 3s 12ms/step - loss: 0.1086 - accuracy: 0.9807 - val_loss: 0.2476 - val_accuracy: 0.9268\n",
            "Epoch 54/500\n",
            "274/274 [==============================] - 3s 11ms/step - loss: 0.1078 - accuracy: 0.9789 - val_loss: 0.2474 - val_accuracy: 0.9260\n",
            "Epoch 55/500\n",
            "274/274 [==============================] - 3s 12ms/step - loss: 0.1066 - accuracy: 0.9810 - val_loss: 0.2347 - val_accuracy: 0.9307\n",
            "Epoch 56/500\n",
            "274/274 [==============================] - 3s 12ms/step - loss: 0.1064 - accuracy: 0.9803 - val_loss: 0.2432 - val_accuracy: 0.9268\n",
            "Epoch 57/500\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "274/274 [==============================] - 3s 12ms/step - loss: 0.1051 - accuracy: 0.9818 - val_loss: 0.2445 - val_accuracy: 0.9269\n",
            "Epoch 58/500\n",
            "274/274 [==============================] - 4s 13ms/step - loss: 0.1061 - accuracy: 0.9802 - val_loss: 0.2431 - val_accuracy: 0.9271\n",
            "Epoch 59/500\n",
            "274/274 [==============================] - 3s 11ms/step - loss: 0.1050 - accuracy: 0.9810 - val_loss: 0.2437 - val_accuracy: 0.9307\n",
            "Epoch 60/500\n",
            "274/274 [==============================] - 3s 13ms/step - loss: 0.1045 - accuracy: 0.9812 - val_loss: 0.2405 - val_accuracy: 0.9293\n",
            "Epoch 61/500\n",
            "274/274 [==============================] - 4s 13ms/step - loss: 0.1048 - accuracy: 0.9822 - val_loss: 0.2404 - val_accuracy: 0.9280\n",
            "Epoch 62/500\n",
            "274/274 [==============================] - 4s 13ms/step - loss: 0.1028 - accuracy: 0.9833 - val_loss: 0.2438 - val_accuracy: 0.9267\n",
            "Epoch 63/500\n",
            "274/274 [==============================] - 4s 13ms/step - loss: 0.1029 - accuracy: 0.9821 - val_loss: 0.2437 - val_accuracy: 0.9253\n",
            "Epoch 64/500\n",
            "274/274 [==============================] - 3s 13ms/step - loss: 0.1036 - accuracy: 0.9805 - val_loss: 0.2427 - val_accuracy: 0.9287\n",
            "Epoch 65/500\n",
            "274/274 [==============================] - 4s 13ms/step - loss: 0.1021 - accuracy: 0.9814 - val_loss: 0.2406 - val_accuracy: 0.9296\n",
            "Epoch 66/500\n",
            "274/274 [==============================] - 4s 13ms/step - loss: 0.1026 - accuracy: 0.9819 - val_loss: 0.2374 - val_accuracy: 0.9287\n",
            "Epoch 67/500\n",
            "274/274 [==============================] - 3s 13ms/step - loss: 0.1016 - accuracy: 0.9821 - val_loss: 0.2388 - val_accuracy: 0.9299\n",
            "Epoch 68/500\n",
            "274/274 [==============================] - 3s 12ms/step - loss: 0.1019 - accuracy: 0.9812 - val_loss: 0.2386 - val_accuracy: 0.9285\n",
            "Epoch 69/500\n",
            "274/274 [==============================] - 4s 13ms/step - loss: 0.1016 - accuracy: 0.9815 - val_loss: 0.2411 - val_accuracy: 0.9285\n",
            "Epoch 70/500\n",
            "274/274 [==============================] - 4s 13ms/step - loss: 0.1007 - accuracy: 0.9837 - val_loss: 0.2442 - val_accuracy: 0.9284\n",
            "Epoch 71/500\n",
            "274/274 [==============================] - 4s 13ms/step - loss: 0.1008 - accuracy: 0.9817 - val_loss: 0.2373 - val_accuracy: 0.9292\n",
            "Epoch 72/500\n",
            "274/274 [==============================] - 3s 13ms/step - loss: 0.1002 - accuracy: 0.9818 - val_loss: 0.2380 - val_accuracy: 0.9305\n",
            "Epoch 73/500\n",
            "274/274 [==============================] - 3s 12ms/step - loss: 0.1005 - accuracy: 0.9805 - val_loss: 0.2414 - val_accuracy: 0.9296\n",
            "Epoch 74/500\n",
            "274/274 [==============================] - 3s 12ms/step - loss: 0.0999 - accuracy: 0.9829 - val_loss: 0.2382 - val_accuracy: 0.9296\n",
            "Epoch 75/500\n",
            "274/274 [==============================] - 3s 12ms/step - loss: 0.1001 - accuracy: 0.9831 - val_loss: 0.2386 - val_accuracy: 0.9309\n",
            "Epoch 76/500\n",
            "274/274 [==============================] - 3s 12ms/step - loss: 0.0989 - accuracy: 0.9842 - val_loss: 0.2395 - val_accuracy: 0.9295\n",
            "Epoch 77/500\n",
            "274/274 [==============================] - 3s 11ms/step - loss: 0.0983 - accuracy: 0.9836 - val_loss: 0.2407 - val_accuracy: 0.9289\n",
            "Epoch 78/500\n",
            "274/274 [==============================] - 3s 11ms/step - loss: 0.0987 - accuracy: 0.9818 - val_loss: 0.2412 - val_accuracy: 0.9296\n",
            "Epoch 79/500\n",
            "274/274 [==============================] - 3s 12ms/step - loss: 0.0986 - accuracy: 0.9833 - val_loss: 0.2398 - val_accuracy: 0.9304\n",
            "Epoch 80/500\n",
            "274/274 [==============================] - 3s 13ms/step - loss: 0.0980 - accuracy: 0.9833 - val_loss: 0.2377 - val_accuracy: 0.9312\n",
            "Epoch 81/500\n",
            "274/274 [==============================] - 4s 14ms/step - loss: 0.0982 - accuracy: 0.9838 - val_loss: 0.2385 - val_accuracy: 0.9304\n",
            "Epoch 82/500\n",
            "274/274 [==============================] - 3s 12ms/step - loss: 0.0982 - accuracy: 0.9827 - val_loss: 0.2379 - val_accuracy: 0.9325\n",
            "Epoch 83/500\n",
            "274/274 [==============================] - 3s 13ms/step - loss: 0.0976 - accuracy: 0.9836 - val_loss: 0.2407 - val_accuracy: 0.9293\n",
            "Epoch 84/500\n",
            "274/274 [==============================] - 4s 13ms/step - loss: 0.0981 - accuracy: 0.9843 - val_loss: 0.2392 - val_accuracy: 0.9287\n",
            "Epoch 85/500\n",
            "274/274 [==============================] - 4s 13ms/step - loss: 0.0975 - accuracy: 0.9835 - val_loss: 0.2406 - val_accuracy: 0.9291\n",
            "Epoch 86/500\n",
            "274/274 [==============================] - 4s 13ms/step - loss: 0.0974 - accuracy: 0.9829 - val_loss: 0.2374 - val_accuracy: 0.9307\n",
            "Epoch 87/500\n",
            "274/274 [==============================] - 3s 12ms/step - loss: 0.0972 - accuracy: 0.9821 - val_loss: 0.2388 - val_accuracy: 0.9295\n",
            "Epoch 88/500\n",
            "274/274 [==============================] - 3s 12ms/step - loss: 0.0965 - accuracy: 0.9849 - val_loss: 0.2369 - val_accuracy: 0.9312\n",
            "Epoch 89/500\n",
            "274/274 [==============================] - 3s 13ms/step - loss: 0.0966 - accuracy: 0.9832 - val_loss: 0.2394 - val_accuracy: 0.9311\n",
            "Epoch 90/500\n",
            "274/274 [==============================] - 3s 12ms/step - loss: 0.0972 - accuracy: 0.9836 - val_loss: 0.2374 - val_accuracy: 0.9301\n",
            "Epoch 91/500\n",
            "274/274 [==============================] - 3s 12ms/step - loss: 0.0966 - accuracy: 0.9842 - val_loss: 0.2387 - val_accuracy: 0.9304\n",
            "Epoch 92/500\n",
            "274/274 [==============================] - 3s 12ms/step - loss: 0.0963 - accuracy: 0.9833 - val_loss: 0.2395 - val_accuracy: 0.9291\n",
            "Epoch 93/500\n",
            "274/274 [==============================] - 4s 13ms/step - loss: 0.0965 - accuracy: 0.9832 - val_loss: 0.2382 - val_accuracy: 0.9304\n",
            "Epoch 94/500\n",
            "274/274 [==============================] - 3s 13ms/step - loss: 0.0962 - accuracy: 0.9842 - val_loss: 0.2371 - val_accuracy: 0.9303\n",
            "Epoch 95/500\n",
            "274/274 [==============================] - 4s 13ms/step - loss: 0.0957 - accuracy: 0.9847 - val_loss: 0.2407 - val_accuracy: 0.9284\n",
            "Epoch 96/500\n",
            "274/274 [==============================] - 3s 11ms/step - loss: 0.0963 - accuracy: 0.9835 - val_loss: 0.2381 - val_accuracy: 0.9293\n",
            "Epoch 97/500\n",
            "274/274 [==============================] - 3s 12ms/step - loss: 0.0960 - accuracy: 0.9838 - val_loss: 0.2390 - val_accuracy: 0.9311\n",
            "Epoch 98/500\n",
            "274/274 [==============================] - 3s 12ms/step - loss: 0.0957 - accuracy: 0.9841 - val_loss: 0.2388 - val_accuracy: 0.9312\n",
            "Epoch 99/500\n",
            "274/274 [==============================] - 3s 12ms/step - loss: 0.0959 - accuracy: 0.9849 - val_loss: 0.2364 - val_accuracy: 0.9304\n",
            "Epoch 100/500\n",
            "274/274 [==============================] - 3s 12ms/step - loss: 0.0959 - accuracy: 0.9834 - val_loss: 0.2395 - val_accuracy: 0.9301\n",
            "Epoch 101/500\n",
            "274/274 [==============================] - 3s 11ms/step - loss: 0.0958 - accuracy: 0.9842 - val_loss: 0.2386 - val_accuracy: 0.9303\n",
            "Epoch 102/500\n",
            "274/274 [==============================] - 3s 12ms/step - loss: 0.0957 - accuracy: 0.9842 - val_loss: 0.2382 - val_accuracy: 0.9312\n",
            "Epoch 103/500\n",
            "274/274 [==============================] - 4s 13ms/step - loss: 0.0954 - accuracy: 0.9845 - val_loss: 0.2368 - val_accuracy: 0.9301\n",
            "Epoch 104/500\n",
            "274/274 [==============================] - 4s 13ms/step - loss: 0.0956 - accuracy: 0.9844 - val_loss: 0.2385 - val_accuracy: 0.9313\n",
            "Epoch 105/500\n",
            "274/274 [==============================] - 4s 13ms/step - loss: 0.0951 - accuracy: 0.9854 - val_loss: 0.2366 - val_accuracy: 0.9299\n",
            "Epoch 106/500\n",
            "274/274 [==============================] - 3s 12ms/step - loss: 0.0954 - accuracy: 0.9843 - val_loss: 0.2368 - val_accuracy: 0.9289\n",
            "Epoch 107/500\n",
            "274/274 [==============================] - 4s 13ms/step - loss: 0.0955 - accuracy: 0.9845 - val_loss: 0.2372 - val_accuracy: 0.9304\n",
            "Epoch 108/500\n",
            "274/274 [==============================] - 4s 13ms/step - loss: 0.0951 - accuracy: 0.9833 - val_loss: 0.2371 - val_accuracy: 0.9301\n",
            "Epoch 109/500\n",
            "274/274 [==============================] - 3s 13ms/step - loss: 0.0955 - accuracy: 0.9841 - val_loss: 0.2373 - val_accuracy: 0.9305\n",
            "Epoch 110/500\n",
            "274/274 [==============================] - 3s 12ms/step - loss: 0.0944 - accuracy: 0.9853 - val_loss: 0.2377 - val_accuracy: 0.9288\n",
            "Epoch 111/500\n",
            "274/274 [==============================] - 3s 13ms/step - loss: 0.0947 - accuracy: 0.9869 - val_loss: 0.2363 - val_accuracy: 0.9296\n",
            "Epoch 112/500\n",
            "274/274 [==============================] - 4s 13ms/step - loss: 0.0949 - accuracy: 0.9845 - val_loss: 0.2360 - val_accuracy: 0.9300\n",
            "Epoch 1/500\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "110/110 [==============================] - 2s 13ms/step - loss: 0.2619 - accuracy: 0.9176 - val_loss: 0.3318 - val_accuracy: 0.8987\n",
            "Epoch 2/500\n",
            "110/110 [==============================] - 1s 11ms/step - loss: 0.2620 - accuracy: 0.9173 - val_loss: 0.3308 - val_accuracy: 0.8993\n",
            "Epoch 3/500\n",
            "110/110 [==============================] - 1s 11ms/step - loss: 0.2641 - accuracy: 0.9136 - val_loss: 0.3300 - val_accuracy: 0.9003\n",
            "Epoch 4/500\n",
            "110/110 [==============================] - 1s 11ms/step - loss: 0.2568 - accuracy: 0.9163 - val_loss: 0.3293 - val_accuracy: 0.8997\n",
            "Epoch 5/500\n",
            "110/110 [==============================] - 1s 11ms/step - loss: 0.2578 - accuracy: 0.9151 - val_loss: 0.3285 - val_accuracy: 0.9000\n",
            "Epoch 6/500\n",
            "110/110 [==============================] - 1s 10ms/step - loss: 0.2534 - accuracy: 0.9183 - val_loss: 0.3278 - val_accuracy: 0.9003\n",
            "Epoch 7/500\n",
            "110/110 [==============================] - 1s 9ms/step - loss: 0.2578 - accuracy: 0.9180 - val_loss: 0.3272 - val_accuracy: 0.9017\n",
            "Epoch 8/500\n",
            "110/110 [==============================] - 1s 10ms/step - loss: 0.2519 - accuracy: 0.9186 - val_loss: 0.3266 - val_accuracy: 0.9020\n",
            "Epoch 9/500\n",
            "110/110 [==============================] - 1s 11ms/step - loss: 0.2421 - accuracy: 0.9203 - val_loss: 0.3260 - val_accuracy: 0.9017\n",
            "Epoch 10/500\n",
            "110/110 [==============================] - 1s 11ms/step - loss: 0.2464 - accuracy: 0.9181 - val_loss: 0.3255 - val_accuracy: 0.9017\n",
            "Epoch 11/500\n",
            "110/110 [==============================] - 1s 11ms/step - loss: 0.2429 - accuracy: 0.9191 - val_loss: 0.3249 - val_accuracy: 0.9023\n",
            "Epoch 12/500\n",
            "110/110 [==============================] - 1s 12ms/step - loss: 0.2450 - accuracy: 0.9183 - val_loss: 0.3243 - val_accuracy: 0.9020\n",
            "Epoch 13/500\n",
            "110/110 [==============================] - 1s 12ms/step - loss: 0.2468 - accuracy: 0.9174 - val_loss: 0.3237 - val_accuracy: 0.9023\n",
            "Epoch 14/500\n",
            "110/110 [==============================] - 1s 11ms/step - loss: 0.2414 - accuracy: 0.9211 - val_loss: 0.3232 - val_accuracy: 0.9027\n",
            "Epoch 15/500\n",
            "110/110 [==============================] - 1s 11ms/step - loss: 0.2381 - accuracy: 0.9219 - val_loss: 0.3227 - val_accuracy: 0.9023\n",
            "Epoch 16/500\n",
            "110/110 [==============================] - 1s 11ms/step - loss: 0.2398 - accuracy: 0.9206 - val_loss: 0.3222 - val_accuracy: 0.9027\n",
            "Epoch 17/500\n",
            "110/110 [==============================] - 1s 11ms/step - loss: 0.2330 - accuracy: 0.9239 - val_loss: 0.3217 - val_accuracy: 0.9023\n",
            "Epoch 18/500\n",
            "110/110 [==============================] - 1s 11ms/step - loss: 0.2345 - accuracy: 0.9219 - val_loss: 0.3211 - val_accuracy: 0.9027\n",
            "Epoch 19/500\n",
            "110/110 [==============================] - 1s 10ms/step - loss: 0.2327 - accuracy: 0.9226 - val_loss: 0.3205 - val_accuracy: 0.9023\n",
            "Epoch 20/500\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.2300 - accuracy: 0.9236 - val_loss: 0.3201 - val_accuracy: 0.9020\n",
            "Epoch 21/500\n",
            "110/110 [==============================] - 1s 9ms/step - loss: 0.2336 - accuracy: 0.9223 - val_loss: 0.3195 - val_accuracy: 0.9020\n",
            "Epoch 22/500\n",
            "110/110 [==============================] - 1s 9ms/step - loss: 0.2277 - accuracy: 0.9220 - val_loss: 0.3191 - val_accuracy: 0.9020\n",
            "Epoch 23/500\n",
            "110/110 [==============================] - 1s 8ms/step - loss: 0.2271 - accuracy: 0.9247 - val_loss: 0.3187 - val_accuracy: 0.9020\n",
            "Epoch 24/500\n",
            "110/110 [==============================] - 1s 9ms/step - loss: 0.2201 - accuracy: 0.9273 - val_loss: 0.3183 - val_accuracy: 0.9030\n",
            "Epoch 25/500\n",
            "110/110 [==============================] - 1s 9ms/step - loss: 0.2243 - accuracy: 0.9261 - val_loss: 0.3179 - val_accuracy: 0.9027\n",
            "Epoch 26/500\n",
            "110/110 [==============================] - 1s 9ms/step - loss: 0.2244 - accuracy: 0.9267 - val_loss: 0.3174 - val_accuracy: 0.9033\n",
            "Epoch 27/500\n",
            "110/110 [==============================] - 1s 10ms/step - loss: 0.2203 - accuracy: 0.9246 - val_loss: 0.3170 - val_accuracy: 0.9033\n",
            "Epoch 28/500\n",
            "110/110 [==============================] - 1s 10ms/step - loss: 0.2239 - accuracy: 0.9249 - val_loss: 0.3165 - val_accuracy: 0.9037\n",
            "Epoch 29/500\n",
            "110/110 [==============================] - 1s 10ms/step - loss: 0.2170 - accuracy: 0.9267 - val_loss: 0.3161 - val_accuracy: 0.9033\n",
            "Epoch 30/500\n",
            "110/110 [==============================] - 1s 10ms/step - loss: 0.2182 - accuracy: 0.9250 - val_loss: 0.3156 - val_accuracy: 0.9037\n",
            "Epoch 31/500\n",
            "110/110 [==============================] - 1s 10ms/step - loss: 0.2132 - accuracy: 0.9264 - val_loss: 0.3154 - val_accuracy: 0.9040\n",
            "Epoch 32/500\n",
            "110/110 [==============================] - 1s 10ms/step - loss: 0.2159 - accuracy: 0.9254 - val_loss: 0.3149 - val_accuracy: 0.9040\n",
            "Epoch 33/500\n",
            "110/110 [==============================] - 1s 10ms/step - loss: 0.2099 - accuracy: 0.9279 - val_loss: 0.3144 - val_accuracy: 0.9040\n",
            "Epoch 34/500\n",
            "110/110 [==============================] - 1s 10ms/step - loss: 0.2117 - accuracy: 0.9270 - val_loss: 0.3141 - val_accuracy: 0.9040\n",
            "Epoch 35/500\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.2114 - accuracy: 0.9279 - val_loss: 0.3137 - val_accuracy: 0.9040\n",
            "Epoch 36/500\n",
            "110/110 [==============================] - 1s 9ms/step - loss: 0.2077 - accuracy: 0.9287 - val_loss: 0.3133 - val_accuracy: 0.9040\n",
            "Epoch 37/500\n",
            "110/110 [==============================] - 1s 10ms/step - loss: 0.2118 - accuracy: 0.9281 - val_loss: 0.3128 - val_accuracy: 0.9037\n",
            "Epoch 38/500\n",
            "110/110 [==============================] - 1s 10ms/step - loss: 0.2066 - accuracy: 0.9301 - val_loss: 0.3125 - val_accuracy: 0.9033\n",
            "Epoch 39/500\n",
            "110/110 [==============================] - 1s 10ms/step - loss: 0.2048 - accuracy: 0.9290 - val_loss: 0.3122 - val_accuracy: 0.9040\n",
            "Epoch 40/500\n",
            "110/110 [==============================] - 1s 9ms/step - loss: 0.2027 - accuracy: 0.9309 - val_loss: 0.3119 - val_accuracy: 0.9043\n",
            "Epoch 41/500\n",
            "110/110 [==============================] - 1s 10ms/step - loss: 0.2035 - accuracy: 0.9310 - val_loss: 0.3115 - val_accuracy: 0.9047\n",
            "Epoch 42/500\n",
            "110/110 [==============================] - 1s 9ms/step - loss: 0.2011 - accuracy: 0.9334 - val_loss: 0.3111 - val_accuracy: 0.9047\n",
            "Epoch 43/500\n",
            "110/110 [==============================] - 1s 9ms/step - loss: 0.1981 - accuracy: 0.9331 - val_loss: 0.3107 - val_accuracy: 0.9050\n",
            "Epoch 44/500\n",
            "110/110 [==============================] - 1s 10ms/step - loss: 0.1989 - accuracy: 0.9334 - val_loss: 0.3103 - val_accuracy: 0.9053\n",
            "Epoch 45/500\n",
            "110/110 [==============================] - 1s 9ms/step - loss: 0.1935 - accuracy: 0.9353 - val_loss: 0.3100 - val_accuracy: 0.9053\n",
            "Epoch 46/500\n",
            "110/110 [==============================] - 1s 11ms/step - loss: 0.2001 - accuracy: 0.9313 - val_loss: 0.3097 - val_accuracy: 0.9053\n",
            "Epoch 47/500\n",
            "110/110 [==============================] - 1s 10ms/step - loss: 0.1987 - accuracy: 0.9329 - val_loss: 0.3095 - val_accuracy: 0.9057\n",
            "Epoch 48/500\n",
            "110/110 [==============================] - 1s 11ms/step - loss: 0.1911 - accuracy: 0.9340 - val_loss: 0.3091 - val_accuracy: 0.9060\n",
            "Epoch 49/500\n",
            "110/110 [==============================] - 1s 10ms/step - loss: 0.1930 - accuracy: 0.9317 - val_loss: 0.3088 - val_accuracy: 0.9060\n",
            "Epoch 50/500\n",
            "110/110 [==============================] - 1s 8ms/step - loss: 0.1921 - accuracy: 0.9349 - val_loss: 0.3085 - val_accuracy: 0.9060\n",
            "Epoch 51/500\n",
            "110/110 [==============================] - 1s 10ms/step - loss: 0.1889 - accuracy: 0.9353 - val_loss: 0.3082 - val_accuracy: 0.9060\n",
            "Epoch 52/500\n",
            "110/110 [==============================] - 1s 11ms/step - loss: 0.1899 - accuracy: 0.9356 - val_loss: 0.3078 - val_accuracy: 0.9060\n",
            "Epoch 53/500\n",
            "110/110 [==============================] - 1s 11ms/step - loss: 0.1891 - accuracy: 0.9339 - val_loss: 0.3075 - val_accuracy: 0.9067\n",
            "Epoch 54/500\n",
            "110/110 [==============================] - 1s 9ms/step - loss: 0.1875 - accuracy: 0.9347 - val_loss: 0.3071 - val_accuracy: 0.9067\n",
            "Epoch 55/500\n",
            "110/110 [==============================] - 1s 9ms/step - loss: 0.1878 - accuracy: 0.9353 - val_loss: 0.3070 - val_accuracy: 0.9067\n",
            "Epoch 56/500\n",
            "110/110 [==============================] - 1s 9ms/step - loss: 0.1844 - accuracy: 0.9381 - val_loss: 0.3067 - val_accuracy: 0.9070\n",
            "Epoch 57/500\n",
            "110/110 [==============================] - 1s 10ms/step - loss: 0.1847 - accuracy: 0.9361 - val_loss: 0.3065 - val_accuracy: 0.9067\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 58/500\n",
            "110/110 [==============================] - 1s 9ms/step - loss: 0.1839 - accuracy: 0.9364 - val_loss: 0.3061 - val_accuracy: 0.9067\n",
            "Epoch 59/500\n",
            "110/110 [==============================] - 1s 9ms/step - loss: 0.1852 - accuracy: 0.9357 - val_loss: 0.3058 - val_accuracy: 0.9067\n",
            "Epoch 60/500\n",
            "110/110 [==============================] - 1s 9ms/step - loss: 0.1803 - accuracy: 0.9367 - val_loss: 0.3056 - val_accuracy: 0.9063\n",
            "Epoch 61/500\n",
            "110/110 [==============================] - 1s 9ms/step - loss: 0.1769 - accuracy: 0.9383 - val_loss: 0.3054 - val_accuracy: 0.9067\n",
            "Epoch 62/500\n",
            "110/110 [==============================] - 1s 9ms/step - loss: 0.1808 - accuracy: 0.9374 - val_loss: 0.3051 - val_accuracy: 0.9067\n",
            "Epoch 63/500\n",
            "110/110 [==============================] - 1s 9ms/step - loss: 0.1828 - accuracy: 0.9383 - val_loss: 0.3048 - val_accuracy: 0.9067\n",
            "Epoch 64/500\n",
            "110/110 [==============================] - 1s 8ms/step - loss: 0.1772 - accuracy: 0.9391 - val_loss: 0.3045 - val_accuracy: 0.9070\n",
            "Epoch 65/500\n",
            "110/110 [==============================] - 1s 8ms/step - loss: 0.1754 - accuracy: 0.9397 - val_loss: 0.3042 - val_accuracy: 0.9070\n",
            "Epoch 66/500\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.1760 - accuracy: 0.9407 - val_loss: 0.3039 - val_accuracy: 0.9070\n",
            "Epoch 67/500\n",
            "110/110 [==============================] - 1s 10ms/step - loss: 0.1740 - accuracy: 0.9401 - val_loss: 0.3036 - val_accuracy: 0.9073\n",
            "Epoch 68/500\n",
            "110/110 [==============================] - 1s 11ms/step - loss: 0.1743 - accuracy: 0.9379 - val_loss: 0.3032 - val_accuracy: 0.9073\n",
            "Epoch 69/500\n",
            "110/110 [==============================] - 1s 11ms/step - loss: 0.1766 - accuracy: 0.9407 - val_loss: 0.3030 - val_accuracy: 0.9073\n",
            "Epoch 70/500\n",
            "110/110 [==============================] - 1s 11ms/step - loss: 0.1684 - accuracy: 0.9423 - val_loss: 0.3028 - val_accuracy: 0.9073\n",
            "Epoch 71/500\n",
            "110/110 [==============================] - 1s 10ms/step - loss: 0.1680 - accuracy: 0.9387 - val_loss: 0.3027 - val_accuracy: 0.9070\n",
            "Epoch 72/500\n",
            "110/110 [==============================] - 1s 9ms/step - loss: 0.1670 - accuracy: 0.9429 - val_loss: 0.3024 - val_accuracy: 0.9067\n",
            "Epoch 73/500\n",
            "110/110 [==============================] - 1s 10ms/step - loss: 0.1706 - accuracy: 0.9417 - val_loss: 0.3021 - val_accuracy: 0.9067\n",
            "Epoch 74/500\n",
            "110/110 [==============================] - 1s 10ms/step - loss: 0.1667 - accuracy: 0.9430 - val_loss: 0.3020 - val_accuracy: 0.9067\n",
            "Epoch 75/500\n",
            "110/110 [==============================] - 1s 9ms/step - loss: 0.1696 - accuracy: 0.9414 - val_loss: 0.3016 - val_accuracy: 0.9067\n",
            "Epoch 76/500\n",
            "110/110 [==============================] - 1s 10ms/step - loss: 0.1658 - accuracy: 0.9419 - val_loss: 0.3013 - val_accuracy: 0.9067\n",
            "Epoch 77/500\n",
            "110/110 [==============================] - 1s 10ms/step - loss: 0.1647 - accuracy: 0.9420 - val_loss: 0.3013 - val_accuracy: 0.9063\n",
            "Epoch 78/500\n",
            "110/110 [==============================] - 1s 9ms/step - loss: 0.1638 - accuracy: 0.9409 - val_loss: 0.3010 - val_accuracy: 0.9063\n",
            "Epoch 79/500\n",
            "110/110 [==============================] - 1s 10ms/step - loss: 0.1619 - accuracy: 0.9421 - val_loss: 0.3009 - val_accuracy: 0.9063\n",
            "Epoch 80/500\n",
            "110/110 [==============================] - 1s 9ms/step - loss: 0.1647 - accuracy: 0.9426 - val_loss: 0.3007 - val_accuracy: 0.9063\n",
            "Epoch 81/500\n",
            "110/110 [==============================] - 1s 8ms/step - loss: 0.1617 - accuracy: 0.9443 - val_loss: 0.3005 - val_accuracy: 0.9063\n",
            "Epoch 82/500\n",
            "110/110 [==============================] - 1s 9ms/step - loss: 0.1619 - accuracy: 0.9447 - val_loss: 0.3003 - val_accuracy: 0.9067\n",
            "Epoch 83/500\n",
            "110/110 [==============================] - 1s 10ms/step - loss: 0.1612 - accuracy: 0.9457 - val_loss: 0.3001 - val_accuracy: 0.9067\n",
            "Epoch 84/500\n",
            "110/110 [==============================] - 1s 10ms/step - loss: 0.1563 - accuracy: 0.9484 - val_loss: 0.2999 - val_accuracy: 0.9063\n",
            "Epoch 85/500\n",
            "110/110 [==============================] - 1s 10ms/step - loss: 0.1570 - accuracy: 0.9450 - val_loss: 0.2996 - val_accuracy: 0.9067\n",
            "Epoch 86/500\n",
            "110/110 [==============================] - 1s 11ms/step - loss: 0.1575 - accuracy: 0.9463 - val_loss: 0.2995 - val_accuracy: 0.9063\n",
            "Epoch 87/500\n",
            "110/110 [==============================] - 1s 11ms/step - loss: 0.1568 - accuracy: 0.9470 - val_loss: 0.2994 - val_accuracy: 0.9067\n",
            "Epoch 88/500\n",
            "110/110 [==============================] - 1s 10ms/step - loss: 0.1550 - accuracy: 0.9464 - val_loss: 0.2990 - val_accuracy: 0.9067\n",
            "Epoch 89/500\n",
            "110/110 [==============================] - 1s 10ms/step - loss: 0.1498 - accuracy: 0.9489 - val_loss: 0.2989 - val_accuracy: 0.9067\n",
            "Epoch 90/500\n",
            "110/110 [==============================] - 1s 10ms/step - loss: 0.1532 - accuracy: 0.9469 - val_loss: 0.2986 - val_accuracy: 0.9063\n",
            "Epoch 91/500\n",
            "110/110 [==============================] - 1s 10ms/step - loss: 0.1497 - accuracy: 0.9499 - val_loss: 0.2984 - val_accuracy: 0.9063\n",
            "Epoch 92/500\n",
            "110/110 [==============================] - 1s 9ms/step - loss: 0.1517 - accuracy: 0.9474 - val_loss: 0.2982 - val_accuracy: 0.9063\n",
            "Epoch 93/500\n",
            "110/110 [==============================] - 1s 10ms/step - loss: 0.1508 - accuracy: 0.9469 - val_loss: 0.2979 - val_accuracy: 0.9067\n",
            "Epoch 94/500\n",
            "110/110 [==============================] - 1s 10ms/step - loss: 0.1469 - accuracy: 0.9483 - val_loss: 0.2978 - val_accuracy: 0.9067\n",
            "Epoch 95/500\n",
            "110/110 [==============================] - 1s 8ms/step - loss: 0.1490 - accuracy: 0.9489 - val_loss: 0.2976 - val_accuracy: 0.9063\n",
            "Epoch 96/500\n",
            "110/110 [==============================] - 1s 8ms/step - loss: 0.1466 - accuracy: 0.9521 - val_loss: 0.2973 - val_accuracy: 0.9070\n",
            "Epoch 97/500\n",
            "110/110 [==============================] - 1s 9ms/step - loss: 0.1445 - accuracy: 0.9501 - val_loss: 0.2972 - val_accuracy: 0.9070\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0.8974"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "lr_reducer = ReduceLROnPlateau(monitor='val_loss', factor=0.9, patience=3)\n",
        "early_stopper = EarlyStopping(monitor='val_accuracy', min_delta=0, patience=30, mode='auto')\n",
        "model = create_simple_net()\n",
        "\n",
        "model.fit(\n",
        "    x=train_data_3,\n",
        "    y=train_labels_3,\n",
        "    epochs=500,\n",
        "    verbose=1,\n",
        "    validation_split=0.3,\n",
        "    batch_size=64,\n",
        "    callbacks=[lr_reducer, early_stopper]\n",
        ")\n",
        "\n",
        "for i in range(len(model.layers)-1):\n",
        "    model.layers[i].trainable = False\n",
        "    \n",
        "model.compile(\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=0.00001),\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "lr_reducer = ReduceLROnPlateau(monitor='val_loss', factor=0.9, patience=3)\n",
        "early_stopper = EarlyStopping(monitor='val_accuracy', min_delta=0, patience=30, mode='auto')\n",
        "\n",
        "model.fit(\n",
        "    x=train_data,\n",
        "    y=train_labels,\n",
        "    epochs=500,\n",
        "    verbose=1,\n",
        "    validation_split=0.3,\n",
        "    batch_size=64,\n",
        "    callbacks=[lr_reducer, early_stopper]\n",
        ")\n",
        "\n",
        "model.save('/content/drive/MyDrive/파이썬스터디 프로젝트/labeling_fer_resnet_c1.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HPJMkp-jQ-Vb"
      },
      "outputs": [],
      "source": [
        "model_eval()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "uncertaintylabeling_fer2013+resnet.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}