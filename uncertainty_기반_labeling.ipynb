{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YianKim/2022_PythonStudy_face_emotion_recognition/blob/main/uncertainty_%EA%B8%B0%EB%B0%98_labeling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5FQpjWg4Ld6m"
      },
      "source": [
        "## 구글 드라이브\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SyTEuhg7fR9P",
        "outputId": "7e2a54ca-26bc-4187-ca2f-a08ae50f78c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UQy7KUb6NBs-"
      },
      "source": [
        "## 라이브러리 불러오기\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XRPQRtXGmm2W"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import PIL\n",
        "import pickle\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "from collections import Counter\n",
        "\n",
        "from keras.layers.core import Lambda\n",
        "from keras import backend as K\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.regularizers import l2\n",
        "from keras.layers import Activation\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Reshape\n",
        "from keras.layers import LSTM\n",
        "from keras import optimizers\n",
        "from keras.callbacks import ReduceLROnPlateau, EarlyStopping, TensorBoard, ModelCheckpoint\n",
        "from sklearn.metrics import *\n",
        "from keras.models import load_model\n",
        "\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xpAjYytuPDaU"
      },
      "source": [
        "## 데이터 불러오기\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e6b1qO5dSAyP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a836b259-1b50-4538-d1b8-e1448b7574eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "40960/29515 [=========================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "26435584/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "16384/5148 [===============================================================================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n",
            "4431872/4422102 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "fashion_mnist = keras.datasets.fashion_mnist\n",
        "(data, labels), (test_data, test_labels) = fashion_mnist.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B-e24WMOTQ4d"
      },
      "outputs": [],
      "source": [
        "train_data = data[range(10000)].reshape([10000,28,28,1])\n",
        "train_labels = labels[range(10000)].reshape([10000,1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EhhKskDITIEm"
      },
      "outputs": [],
      "source": [
        "unlab_data = data[range(10000,60000)].reshape([50000,28,28,1])\n",
        "unlab_labels = labels[range(10000,60000)].reshape([50000,1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W5aNLvjxVUq0"
      },
      "outputs": [],
      "source": [
        "test_data = test_data.reshape([10000,28,28,1])\n",
        "test_labels = test_labels.reshape([10000,1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2K2wXxMmUxRV"
      },
      "outputs": [],
      "source": [
        "train_labels2 = []\n",
        "unlab_labels2 = []\n",
        "test_labels2 = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8c9LL8JVThd-"
      },
      "outputs": [],
      "source": [
        "for i in range(10000):\n",
        "  white = [0,0,0,0,0,0,0,0,0,0]\n",
        "  white[train_labels[i][0]] = 1\n",
        "  train_labels2.append(white)\n",
        "\n",
        "for i in range(50000):\n",
        "  white = [0,0,0,0,0,0,0,0,0,0]\n",
        "  white[unlab_labels[i][0]] = 1\n",
        "  unlab_labels2.append(white)\n",
        "\n",
        "for i in range(10000):\n",
        "  white = [0,0,0,0,0,0,0,0,0,0]\n",
        "  white[test_labels[i][0]] = 1\n",
        "  test_labels2.append(white)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iULFrchUU5nt"
      },
      "outputs": [],
      "source": [
        "train_labels = np.array(train_labels2)\n",
        "unlab_labels = np.array(unlab_labels2)\n",
        "test_labels = np.array(test_labels2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sa7KYMfrkKU5"
      },
      "source": [
        "## CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zn3v_W8wJQ68"
      },
      "outputs": [],
      "source": [
        "def PermaDropout(rate):\n",
        "    return Lambda(lambda x: K.dropout(x, level=rate))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L5scE9yKkIZb",
        "outputId": "931fe7b5-fae8-4a39-9334-9f27244b9cb1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2000\n",
            "110/110 [==============================] - 15s 18ms/step - loss: 3.2566 - accuracy: 0.5900 - val_loss: 0.8345 - val_accuracy: 0.7040 - lr: 0.0010\n",
            "Epoch 2/2000\n",
            "110/110 [==============================] - 2s 14ms/step - loss: 0.6978 - accuracy: 0.7519 - val_loss: 0.6845 - val_accuracy: 0.7440 - lr: 0.0010\n",
            "Epoch 3/2000\n",
            "110/110 [==============================] - 1s 13ms/step - loss: 0.5848 - accuracy: 0.7866 - val_loss: 0.6348 - val_accuracy: 0.7847 - lr: 0.0010\n",
            "Epoch 4/2000\n",
            "110/110 [==============================] - 2s 14ms/step - loss: 0.5179 - accuracy: 0.8086 - val_loss: 0.6325 - val_accuracy: 0.7720 - lr: 0.0010\n",
            "Epoch 5/2000\n",
            "110/110 [==============================] - 2s 14ms/step - loss: 0.4800 - accuracy: 0.8259 - val_loss: 0.6128 - val_accuracy: 0.7900 - lr: 0.0010\n",
            "Epoch 6/2000\n",
            "110/110 [==============================] - 1s 13ms/step - loss: 0.4445 - accuracy: 0.8356 - val_loss: 0.5553 - val_accuracy: 0.8027 - lr: 0.0010\n",
            "Epoch 7/2000\n",
            "110/110 [==============================] - 1s 13ms/step - loss: 0.4360 - accuracy: 0.8380 - val_loss: 0.5891 - val_accuracy: 0.8073 - lr: 0.0010\n",
            "Epoch 8/2000\n",
            "110/110 [==============================] - 1s 14ms/step - loss: 0.3818 - accuracy: 0.8561 - val_loss: 0.6144 - val_accuracy: 0.7977 - lr: 0.0010\n",
            "Epoch 9/2000\n",
            "110/110 [==============================] - 1s 13ms/step - loss: 0.3798 - accuracy: 0.8577 - val_loss: 0.5875 - val_accuracy: 0.8047 - lr: 0.0010\n",
            "Epoch 10/2000\n",
            "110/110 [==============================] - 1s 14ms/step - loss: 0.3432 - accuracy: 0.8711 - val_loss: 0.5378 - val_accuracy: 0.8120 - lr: 9.0000e-04\n",
            "Epoch 11/2000\n",
            "110/110 [==============================] - 2s 14ms/step - loss: 0.3228 - accuracy: 0.8791 - val_loss: 0.5614 - val_accuracy: 0.8070 - lr: 9.0000e-04\n",
            "Epoch 12/2000\n",
            "110/110 [==============================] - 1s 13ms/step - loss: 0.3197 - accuracy: 0.8764 - val_loss: 0.5673 - val_accuracy: 0.8107 - lr: 9.0000e-04\n",
            "Epoch 13/2000\n",
            "110/110 [==============================] - 1s 14ms/step - loss: 0.2817 - accuracy: 0.8921 - val_loss: 0.5336 - val_accuracy: 0.8360 - lr: 9.0000e-04\n",
            "Epoch 14/2000\n",
            "110/110 [==============================] - 1s 13ms/step - loss: 0.2838 - accuracy: 0.8899 - val_loss: 0.5572 - val_accuracy: 0.8193 - lr: 9.0000e-04\n",
            "Epoch 15/2000\n",
            "110/110 [==============================] - 1s 13ms/step - loss: 0.2856 - accuracy: 0.8917 - val_loss: 0.5524 - val_accuracy: 0.8257 - lr: 9.0000e-04\n",
            "Epoch 16/2000\n",
            "110/110 [==============================] - 1s 12ms/step - loss: 0.2586 - accuracy: 0.8981 - val_loss: 0.5302 - val_accuracy: 0.8297 - lr: 9.0000e-04\n",
            "Epoch 17/2000\n",
            "110/110 [==============================] - 1s 13ms/step - loss: 0.2625 - accuracy: 0.8986 - val_loss: 0.5847 - val_accuracy: 0.8227 - lr: 9.0000e-04\n",
            "Epoch 18/2000\n",
            "110/110 [==============================] - 1s 13ms/step - loss: 0.2484 - accuracy: 0.9086 - val_loss: 0.6040 - val_accuracy: 0.8210 - lr: 9.0000e-04\n",
            "Epoch 19/2000\n",
            "110/110 [==============================] - 1s 13ms/step - loss: 0.2378 - accuracy: 0.9067 - val_loss: 0.5948 - val_accuracy: 0.8270 - lr: 9.0000e-04\n",
            "Epoch 20/2000\n",
            "110/110 [==============================] - 1s 13ms/step - loss: 0.2165 - accuracy: 0.9167 - val_loss: 0.6055 - val_accuracy: 0.8300 - lr: 8.1000e-04\n",
            "Epoch 21/2000\n",
            "110/110 [==============================] - 1s 12ms/step - loss: 0.2147 - accuracy: 0.9194 - val_loss: 0.6250 - val_accuracy: 0.8280 - lr: 8.1000e-04\n",
            "Epoch 22/2000\n",
            "110/110 [==============================] - 1s 12ms/step - loss: 0.2105 - accuracy: 0.9173 - val_loss: 0.6180 - val_accuracy: 0.8373 - lr: 8.1000e-04\n",
            "Epoch 23/2000\n",
            "110/110 [==============================] - 1s 12ms/step - loss: 0.2059 - accuracy: 0.9193 - val_loss: 0.6070 - val_accuracy: 0.8417 - lr: 7.2900e-04\n",
            "Epoch 24/2000\n",
            "110/110 [==============================] - 1s 13ms/step - loss: 0.1961 - accuracy: 0.9223 - val_loss: 0.6557 - val_accuracy: 0.8380 - lr: 7.2900e-04\n",
            "Epoch 25/2000\n",
            "110/110 [==============================] - 1s 12ms/step - loss: 0.1878 - accuracy: 0.9296 - val_loss: 0.6172 - val_accuracy: 0.8393 - lr: 7.2900e-04\n",
            "Epoch 26/2000\n",
            "110/110 [==============================] - 1s 13ms/step - loss: 0.1794 - accuracy: 0.9311 - val_loss: 0.6405 - val_accuracy: 0.8420 - lr: 6.5610e-04\n",
            "Epoch 27/2000\n",
            "110/110 [==============================] - 1s 12ms/step - loss: 0.1701 - accuracy: 0.9367 - val_loss: 0.5890 - val_accuracy: 0.8327 - lr: 6.5610e-04\n",
            "Epoch 28/2000\n",
            "110/110 [==============================] - 1s 12ms/step - loss: 0.1695 - accuracy: 0.9383 - val_loss: 0.5847 - val_accuracy: 0.8390 - lr: 6.5610e-04\n",
            "Epoch 29/2000\n",
            "110/110 [==============================] - 1s 13ms/step - loss: 0.1683 - accuracy: 0.9340 - val_loss: 0.6060 - val_accuracy: 0.8403 - lr: 5.9049e-04\n",
            "Epoch 30/2000\n",
            "110/110 [==============================] - 1s 12ms/step - loss: 0.1477 - accuracy: 0.9427 - val_loss: 0.6009 - val_accuracy: 0.8440 - lr: 5.9049e-04\n",
            "Epoch 31/2000\n",
            "110/110 [==============================] - 1s 14ms/step - loss: 0.1520 - accuracy: 0.9437 - val_loss: 0.6496 - val_accuracy: 0.8350 - lr: 5.9049e-04\n",
            "Epoch 32/2000\n",
            "110/110 [==============================] - 2s 14ms/step - loss: 0.1462 - accuracy: 0.9437 - val_loss: 0.6060 - val_accuracy: 0.8400 - lr: 5.3144e-04\n",
            "Epoch 33/2000\n",
            "110/110 [==============================] - 1s 13ms/step - loss: 0.1311 - accuracy: 0.9493 - val_loss: 0.5904 - val_accuracy: 0.8423 - lr: 5.3144e-04\n",
            "Epoch 34/2000\n",
            "110/110 [==============================] - 1s 13ms/step - loss: 0.1323 - accuracy: 0.9493 - val_loss: 0.7093 - val_accuracy: 0.8383 - lr: 5.3144e-04\n",
            "Epoch 35/2000\n",
            "110/110 [==============================] - 1s 14ms/step - loss: 0.1243 - accuracy: 0.9499 - val_loss: 0.6789 - val_accuracy: 0.8483 - lr: 4.7830e-04\n",
            "Epoch 36/2000\n",
            "110/110 [==============================] - 1s 13ms/step - loss: 0.1279 - accuracy: 0.9520 - val_loss: 0.6720 - val_accuracy: 0.8517 - lr: 4.7830e-04\n",
            "Epoch 37/2000\n",
            "110/110 [==============================] - 1s 14ms/step - loss: 0.1222 - accuracy: 0.9524 - val_loss: 0.6442 - val_accuracy: 0.8407 - lr: 4.7830e-04\n",
            "Epoch 38/2000\n",
            "110/110 [==============================] - 2s 14ms/step - loss: 0.1106 - accuracy: 0.9579 - val_loss: 0.6864 - val_accuracy: 0.8417 - lr: 4.3047e-04\n",
            "Epoch 39/2000\n",
            "110/110 [==============================] - 2s 14ms/step - loss: 0.1131 - accuracy: 0.9561 - val_loss: 0.6177 - val_accuracy: 0.8567 - lr: 4.3047e-04\n",
            "Epoch 40/2000\n",
            "110/110 [==============================] - 2s 14ms/step - loss: 0.1194 - accuracy: 0.9519 - val_loss: 0.6810 - val_accuracy: 0.8523 - lr: 4.3047e-04\n",
            "Epoch 41/2000\n",
            "110/110 [==============================] - 1s 13ms/step - loss: 0.0914 - accuracy: 0.9634 - val_loss: 0.6817 - val_accuracy: 0.8503 - lr: 3.8742e-04\n",
            "Epoch 42/2000\n",
            "110/110 [==============================] - 2s 16ms/step - loss: 0.0946 - accuracy: 0.9627 - val_loss: 0.6793 - val_accuracy: 0.8527 - lr: 3.8742e-04\n",
            "Epoch 43/2000\n",
            "110/110 [==============================] - 2s 18ms/step - loss: 0.0982 - accuracy: 0.9616 - val_loss: 0.7570 - val_accuracy: 0.8460 - lr: 3.8742e-04\n",
            "Epoch 44/2000\n",
            "110/110 [==============================] - 2s 14ms/step - loss: 0.0878 - accuracy: 0.9661 - val_loss: 0.7277 - val_accuracy: 0.8473 - lr: 3.4868e-04\n",
            "Epoch 45/2000\n",
            "110/110 [==============================] - 1s 13ms/step - loss: 0.0902 - accuracy: 0.9649 - val_loss: 0.7174 - val_accuracy: 0.8530 - lr: 3.4868e-04\n",
            "Epoch 46/2000\n",
            "110/110 [==============================] - 1s 13ms/step - loss: 0.0901 - accuracy: 0.9666 - val_loss: 0.6406 - val_accuracy: 0.8543 - lr: 3.4868e-04\n",
            "Epoch 47/2000\n",
            "110/110 [==============================] - 2s 14ms/step - loss: 0.0849 - accuracy: 0.9704 - val_loss: 0.6887 - val_accuracy: 0.8543 - lr: 3.1381e-04\n",
            "Epoch 48/2000\n",
            "110/110 [==============================] - 2s 14ms/step - loss: 0.0833 - accuracy: 0.9666 - val_loss: 0.7294 - val_accuracy: 0.8540 - lr: 3.1381e-04\n",
            "Epoch 49/2000\n",
            "110/110 [==============================] - 1s 14ms/step - loss: 0.0758 - accuracy: 0.9724 - val_loss: 0.7458 - val_accuracy: 0.8483 - lr: 3.1381e-04\n",
            "Epoch 50/2000\n",
            "110/110 [==============================] - 1s 14ms/step - loss: 0.0778 - accuracy: 0.9684 - val_loss: 0.6981 - val_accuracy: 0.8473 - lr: 2.8243e-04\n",
            "Epoch 51/2000\n",
            "110/110 [==============================] - 1s 13ms/step - loss: 0.0762 - accuracy: 0.9710 - val_loss: 0.7267 - val_accuracy: 0.8517 - lr: 2.8243e-04\n",
            "Epoch 52/2000\n",
            "110/110 [==============================] - 1s 13ms/step - loss: 0.0716 - accuracy: 0.9714 - val_loss: 0.7616 - val_accuracy: 0.8480 - lr: 2.8243e-04\n",
            "Epoch 53/2000\n",
            "110/110 [==============================] - 2s 14ms/step - loss: 0.0729 - accuracy: 0.9733 - val_loss: 0.7640 - val_accuracy: 0.8520 - lr: 2.5419e-04\n",
            "Epoch 54/2000\n",
            "110/110 [==============================] - 1s 13ms/step - loss: 0.0706 - accuracy: 0.9717 - val_loss: 0.7776 - val_accuracy: 0.8450 - lr: 2.5419e-04\n",
            "Epoch 55/2000\n",
            "110/110 [==============================] - 1s 13ms/step - loss: 0.0735 - accuracy: 0.9734 - val_loss: 0.7880 - val_accuracy: 0.8473 - lr: 2.5419e-04\n",
            "Epoch 56/2000\n",
            "110/110 [==============================] - 1s 13ms/step - loss: 0.0711 - accuracy: 0.9731 - val_loss: 0.7332 - val_accuracy: 0.8470 - lr: 2.2877e-04\n",
            "Epoch 57/2000\n",
            "110/110 [==============================] - 1s 14ms/step - loss: 0.0701 - accuracy: 0.9759 - val_loss: 0.7378 - val_accuracy: 0.8583 - lr: 2.2877e-04\n",
            "Epoch 58/2000\n",
            "110/110 [==============================] - 1s 14ms/step - loss: 0.0674 - accuracy: 0.9736 - val_loss: 0.7819 - val_accuracy: 0.8543 - lr: 2.2877e-04\n",
            "Epoch 59/2000\n",
            "110/110 [==============================] - 1s 13ms/step - loss: 0.0710 - accuracy: 0.9729 - val_loss: 0.7577 - val_accuracy: 0.8500 - lr: 2.0589e-04\n",
            "Epoch 60/2000\n",
            "110/110 [==============================] - 2s 14ms/step - loss: 0.0751 - accuracy: 0.9726 - val_loss: 0.8253 - val_accuracy: 0.8533 - lr: 2.0589e-04\n",
            "Epoch 61/2000\n",
            "110/110 [==============================] - 1s 13ms/step - loss: 0.0649 - accuracy: 0.9750 - val_loss: 0.7261 - val_accuracy: 0.8547 - lr: 2.0589e-04\n",
            "Epoch 62/2000\n",
            "110/110 [==============================] - 1s 13ms/step - loss: 0.0552 - accuracy: 0.9781 - val_loss: 0.7736 - val_accuracy: 0.8570 - lr: 1.8530e-04\n",
            "Epoch 63/2000\n",
            "110/110 [==============================] - 1s 13ms/step - loss: 0.0615 - accuracy: 0.9767 - val_loss: 0.7714 - val_accuracy: 0.8527 - lr: 1.8530e-04\n",
            "Epoch 64/2000\n",
            "110/110 [==============================] - 1s 13ms/step - loss: 0.0569 - accuracy: 0.9784 - val_loss: 0.7658 - val_accuracy: 0.8527 - lr: 1.8530e-04\n",
            "Epoch 65/2000\n",
            "110/110 [==============================] - 1s 13ms/step - loss: 0.0624 - accuracy: 0.9766 - val_loss: 0.7685 - val_accuracy: 0.8603 - lr: 1.6677e-04\n",
            "Epoch 66/2000\n",
            "110/110 [==============================] - 2s 14ms/step - loss: 0.0553 - accuracy: 0.9779 - val_loss: 0.7504 - val_accuracy: 0.8597 - lr: 1.6677e-04\n",
            "Epoch 67/2000\n",
            "110/110 [==============================] - 1s 13ms/step - loss: 0.0495 - accuracy: 0.9799 - val_loss: 0.8052 - val_accuracy: 0.8660 - lr: 1.6677e-04\n",
            "Epoch 68/2000\n",
            "110/110 [==============================] - 2s 14ms/step - loss: 0.0559 - accuracy: 0.9783 - val_loss: 0.7879 - val_accuracy: 0.8527 - lr: 1.5009e-04\n",
            "Epoch 69/2000\n",
            "110/110 [==============================] - 1s 13ms/step - loss: 0.0543 - accuracy: 0.9781 - val_loss: 0.7542 - val_accuracy: 0.8553 - lr: 1.5009e-04\n",
            "Epoch 70/2000\n",
            "110/110 [==============================] - 2s 14ms/step - loss: 0.0478 - accuracy: 0.9841 - val_loss: 0.8305 - val_accuracy: 0.8553 - lr: 1.5009e-04\n",
            "Epoch 71/2000\n",
            "110/110 [==============================] - 2s 14ms/step - loss: 0.0491 - accuracy: 0.9806 - val_loss: 0.8306 - val_accuracy: 0.8573 - lr: 1.3509e-04\n",
            "Epoch 72/2000\n",
            "110/110 [==============================] - 1s 14ms/step - loss: 0.0459 - accuracy: 0.9823 - val_loss: 0.7824 - val_accuracy: 0.8643 - lr: 1.3509e-04\n",
            "Epoch 73/2000\n",
            "110/110 [==============================] - 1s 14ms/step - loss: 0.0542 - accuracy: 0.9793 - val_loss: 0.8285 - val_accuracy: 0.8557 - lr: 1.3509e-04\n",
            "Epoch 74/2000\n",
            "110/110 [==============================] - 1s 13ms/step - loss: 0.0505 - accuracy: 0.9799 - val_loss: 0.8358 - val_accuracy: 0.8560 - lr: 1.2158e-04\n",
            "Epoch 75/2000\n",
            "110/110 [==============================] - 1s 13ms/step - loss: 0.0430 - accuracy: 0.9826 - val_loss: 0.8360 - val_accuracy: 0.8543 - lr: 1.2158e-04\n",
            "Epoch 76/2000\n",
            "110/110 [==============================] - 1s 13ms/step - loss: 0.0429 - accuracy: 0.9823 - val_loss: 0.8155 - val_accuracy: 0.8600 - lr: 1.2158e-04\n",
            "Epoch 77/2000\n",
            "110/110 [==============================] - 1s 12ms/step - loss: 0.0519 - accuracy: 0.9813 - val_loss: 0.7945 - val_accuracy: 0.8547 - lr: 1.0942e-04\n",
            "Epoch 78/2000\n",
            "110/110 [==============================] - 1s 13ms/step - loss: 0.0439 - accuracy: 0.9833 - val_loss: 0.7928 - val_accuracy: 0.8620 - lr: 1.0942e-04\n",
            "Epoch 79/2000\n",
            "110/110 [==============================] - 1s 14ms/step - loss: 0.0444 - accuracy: 0.9826 - val_loss: 0.8409 - val_accuracy: 0.8617 - lr: 1.0942e-04\n",
            "Epoch 80/2000\n",
            "110/110 [==============================] - 1s 13ms/step - loss: 0.0473 - accuracy: 0.9810 - val_loss: 0.8089 - val_accuracy: 0.8650 - lr: 9.8477e-05\n",
            "Epoch 81/2000\n",
            "110/110 [==============================] - 1s 13ms/step - loss: 0.0455 - accuracy: 0.9814 - val_loss: 0.7492 - val_accuracy: 0.8637 - lr: 9.8477e-05\n",
            "Epoch 82/2000\n",
            "110/110 [==============================] - 2s 14ms/step - loss: 0.0406 - accuracy: 0.9864 - val_loss: 0.8131 - val_accuracy: 0.8623 - lr: 9.8477e-05\n",
            "Epoch 83/2000\n",
            "110/110 [==============================] - 2s 14ms/step - loss: 0.0392 - accuracy: 0.9856 - val_loss: 0.8182 - val_accuracy: 0.8653 - lr: 8.8629e-05\n",
            "Epoch 84/2000\n",
            "110/110 [==============================] - 2s 14ms/step - loss: 0.0418 - accuracy: 0.9840 - val_loss: 0.8678 - val_accuracy: 0.8617 - lr: 8.8629e-05\n",
            "Epoch 85/2000\n",
            "110/110 [==============================] - 1s 13ms/step - loss: 0.0366 - accuracy: 0.9873 - val_loss: 0.8462 - val_accuracy: 0.8613 - lr: 8.8629e-05\n",
            "Epoch 86/2000\n",
            "110/110 [==============================] - 1s 13ms/step - loss: 0.0418 - accuracy: 0.9854 - val_loss: 0.8462 - val_accuracy: 0.8607 - lr: 7.9766e-05\n",
            "Epoch 87/2000\n",
            "110/110 [==============================] - 1s 13ms/step - loss: 0.0403 - accuracy: 0.9839 - val_loss: 0.9078 - val_accuracy: 0.8540 - lr: 7.9766e-05\n",
            "Epoch 88/2000\n",
            "110/110 [==============================] - 1s 13ms/step - loss: 0.0387 - accuracy: 0.9866 - val_loss: 0.8438 - val_accuracy: 0.8603 - lr: 7.9766e-05\n",
            "Epoch 89/2000\n",
            "110/110 [==============================] - 1s 13ms/step - loss: 0.0427 - accuracy: 0.9833 - val_loss: 0.8210 - val_accuracy: 0.8673 - lr: 7.1790e-05\n",
            "Epoch 90/2000\n",
            "110/110 [==============================] - 2s 14ms/step - loss: 0.0356 - accuracy: 0.9867 - val_loss: 0.8437 - val_accuracy: 0.8607 - lr: 7.1790e-05\n",
            "Epoch 91/2000\n",
            "110/110 [==============================] - 2s 14ms/step - loss: 0.0346 - accuracy: 0.9864 - val_loss: 0.8283 - val_accuracy: 0.8637 - lr: 7.1790e-05\n",
            "Epoch 92/2000\n",
            "110/110 [==============================] - 2s 14ms/step - loss: 0.0353 - accuracy: 0.9879 - val_loss: 0.8993 - val_accuracy: 0.8567 - lr: 6.4611e-05\n",
            "Epoch 93/2000\n",
            "110/110 [==============================] - 1s 13ms/step - loss: 0.0391 - accuracy: 0.9843 - val_loss: 0.8945 - val_accuracy: 0.8587 - lr: 6.4611e-05\n",
            "Epoch 94/2000\n",
            "110/110 [==============================] - 1s 13ms/step - loss: 0.0360 - accuracy: 0.9864 - val_loss: 0.7804 - val_accuracy: 0.8637 - lr: 6.4611e-05\n",
            "Epoch 95/2000\n",
            "110/110 [==============================] - 1s 13ms/step - loss: 0.0409 - accuracy: 0.9844 - val_loss: 0.8294 - val_accuracy: 0.8587 - lr: 5.8150e-05\n",
            "Epoch 96/2000\n",
            "110/110 [==============================] - 1s 13ms/step - loss: 0.0313 - accuracy: 0.9867 - val_loss: 0.8909 - val_accuracy: 0.8650 - lr: 5.8150e-05\n",
            "Epoch 97/2000\n",
            "110/110 [==============================] - 2s 14ms/step - loss: 0.0338 - accuracy: 0.9874 - val_loss: 0.8657 - val_accuracy: 0.8677 - lr: 5.8150e-05\n",
            "Epoch 98/2000\n",
            "110/110 [==============================] - 1s 13ms/step - loss: 0.0350 - accuracy: 0.9874 - val_loss: 0.8900 - val_accuracy: 0.8623 - lr: 5.2335e-05\n",
            "Epoch 99/2000\n",
            "110/110 [==============================] - 1s 13ms/step - loss: 0.0348 - accuracy: 0.9860 - val_loss: 0.8767 - val_accuracy: 0.8593 - lr: 5.2335e-05\n",
            "Epoch 100/2000\n",
            "110/110 [==============================] - 1s 14ms/step - loss: 0.0324 - accuracy: 0.9881 - val_loss: 0.9359 - val_accuracy: 0.8587 - lr: 5.2335e-05\n",
            "Epoch 101/2000\n",
            "110/110 [==============================] - 1s 13ms/step - loss: 0.0314 - accuracy: 0.9877 - val_loss: 0.8649 - val_accuracy: 0.8683 - lr: 4.7101e-05\n",
            "Epoch 102/2000\n",
            "110/110 [==============================] - 1s 13ms/step - loss: 0.0345 - accuracy: 0.9870 - val_loss: 0.9242 - val_accuracy: 0.8543 - lr: 4.7101e-05\n",
            "Epoch 103/2000\n",
            "110/110 [==============================] - 1s 13ms/step - loss: 0.0367 - accuracy: 0.9850 - val_loss: 0.8090 - val_accuracy: 0.8633 - lr: 4.7101e-05\n",
            "Epoch 104/2000\n",
            "110/110 [==============================] - 1s 13ms/step - loss: 0.0370 - accuracy: 0.9860 - val_loss: 0.8064 - val_accuracy: 0.8633 - lr: 4.2391e-05\n",
            "Epoch 105/2000\n",
            "110/110 [==============================] - 1s 13ms/step - loss: 0.0344 - accuracy: 0.9874 - val_loss: 0.8787 - val_accuracy: 0.8550 - lr: 4.2391e-05\n",
            "Epoch 106/2000\n",
            "110/110 [==============================] - 1s 13ms/step - loss: 0.0309 - accuracy: 0.9886 - val_loss: 0.8220 - val_accuracy: 0.8723 - lr: 4.2391e-05\n",
            "Epoch 107/2000\n",
            "110/110 [==============================] - 2s 14ms/step - loss: 0.0349 - accuracy: 0.9881 - val_loss: 0.8593 - val_accuracy: 0.8603 - lr: 3.8152e-05\n",
            "Epoch 108/2000\n",
            "110/110 [==============================] - 2s 14ms/step - loss: 0.0327 - accuracy: 0.9876 - val_loss: 0.8626 - val_accuracy: 0.8563 - lr: 3.8152e-05\n",
            "Epoch 109/2000\n",
            "110/110 [==============================] - 1s 13ms/step - loss: 0.0330 - accuracy: 0.9867 - val_loss: 0.8304 - val_accuracy: 0.8690 - lr: 3.8152e-05\n",
            "Epoch 110/2000\n",
            "110/110 [==============================] - 2s 14ms/step - loss: 0.0330 - accuracy: 0.9877 - val_loss: 0.8940 - val_accuracy: 0.8640 - lr: 3.4337e-05\n",
            "Epoch 111/2000\n",
            "110/110 [==============================] - 2s 14ms/step - loss: 0.0286 - accuracy: 0.9894 - val_loss: 0.8802 - val_accuracy: 0.8670 - lr: 3.4337e-05\n",
            "Epoch 112/2000\n",
            "110/110 [==============================] - 1s 13ms/step - loss: 0.0335 - accuracy: 0.9870 - val_loss: 0.8800 - val_accuracy: 0.8620 - lr: 3.4337e-05\n",
            "Epoch 113/2000\n",
            "110/110 [==============================] - 1s 13ms/step - loss: 0.0303 - accuracy: 0.9889 - val_loss: 0.8235 - val_accuracy: 0.8663 - lr: 3.0903e-05\n",
            "Epoch 114/2000\n",
            "110/110 [==============================] - 1s 13ms/step - loss: 0.0309 - accuracy: 0.9883 - val_loss: 0.9380 - val_accuracy: 0.8690 - lr: 3.0903e-05\n",
            "Epoch 115/2000\n",
            "110/110 [==============================] - 1s 13ms/step - loss: 0.0307 - accuracy: 0.9880 - val_loss: 0.9026 - val_accuracy: 0.8717 - lr: 3.0903e-05\n",
            "Epoch 116/2000\n",
            "110/110 [==============================] - 1s 13ms/step - loss: 0.0310 - accuracy: 0.9880 - val_loss: 0.8441 - val_accuracy: 0.8673 - lr: 2.7813e-05\n",
            "Epoch 117/2000\n",
            "110/110 [==============================] - 1s 13ms/step - loss: 0.0367 - accuracy: 0.9880 - val_loss: 0.8649 - val_accuracy: 0.8640 - lr: 2.7813e-05\n",
            "Epoch 118/2000\n",
            "110/110 [==============================] - 1s 13ms/step - loss: 0.0270 - accuracy: 0.9900 - val_loss: 0.8914 - val_accuracy: 0.8633 - lr: 2.7813e-05\n",
            "Epoch 119/2000\n",
            "110/110 [==============================] - 1s 14ms/step - loss: 0.0308 - accuracy: 0.9873 - val_loss: 0.8249 - val_accuracy: 0.8750 - lr: 2.5032e-05\n",
            "Epoch 120/2000\n",
            "110/110 [==============================] - 2s 14ms/step - loss: 0.0329 - accuracy: 0.9879 - val_loss: 0.9194 - val_accuracy: 0.8607 - lr: 2.5032e-05\n",
            "Epoch 121/2000\n",
            "110/110 [==============================] - 1s 13ms/step - loss: 0.0325 - accuracy: 0.9874 - val_loss: 0.8637 - val_accuracy: 0.8660 - lr: 2.5032e-05\n",
            "Epoch 122/2000\n",
            "110/110 [==============================] - 1s 13ms/step - loss: 0.0301 - accuracy: 0.9903 - val_loss: 0.8713 - val_accuracy: 0.8577 - lr: 2.2528e-05\n",
            "Epoch 123/2000\n",
            "110/110 [==============================] - 1s 13ms/step - loss: 0.0320 - accuracy: 0.9889 - val_loss: 0.8556 - val_accuracy: 0.8627 - lr: 2.2528e-05\n",
            "Epoch 124/2000\n",
            "110/110 [==============================] - 1s 13ms/step - loss: 0.0304 - accuracy: 0.9889 - val_loss: 0.8479 - val_accuracy: 0.8693 - lr: 2.2528e-05\n",
            "Epoch 125/2000\n",
            "110/110 [==============================] - 1s 14ms/step - loss: 0.0269 - accuracy: 0.9900 - val_loss: 0.8246 - val_accuracy: 0.8703 - lr: 2.0276e-05\n",
            "Epoch 126/2000\n",
            "110/110 [==============================] - 1s 13ms/step - loss: 0.0274 - accuracy: 0.9914 - val_loss: 0.9198 - val_accuracy: 0.8600 - lr: 2.0276e-05\n",
            "Epoch 127/2000\n",
            "110/110 [==============================] - 2s 14ms/step - loss: 0.0298 - accuracy: 0.9893 - val_loss: 0.9342 - val_accuracy: 0.8623 - lr: 2.0276e-05\n",
            "Epoch 128/2000\n",
            "110/110 [==============================] - 1s 13ms/step - loss: 0.0308 - accuracy: 0.9874 - val_loss: 0.8591 - val_accuracy: 0.8650 - lr: 1.8248e-05\n",
            "Epoch 129/2000\n",
            "110/110 [==============================] - 2s 14ms/step - loss: 0.0292 - accuracy: 0.9896 - val_loss: 0.8816 - val_accuracy: 0.8683 - lr: 1.8248e-05\n",
            "Epoch 130/2000\n",
            "110/110 [==============================] - 1s 13ms/step - loss: 0.0298 - accuracy: 0.9886 - val_loss: 0.8437 - val_accuracy: 0.8673 - lr: 1.8248e-05\n",
            "Epoch 131/2000\n",
            "110/110 [==============================] - 2s 14ms/step - loss: 0.0300 - accuracy: 0.9880 - val_loss: 0.8395 - val_accuracy: 0.8633 - lr: 1.6423e-05\n",
            "Epoch 132/2000\n",
            "110/110 [==============================] - 1s 13ms/step - loss: 0.0274 - accuracy: 0.9891 - val_loss: 0.9264 - val_accuracy: 0.8673 - lr: 1.6423e-05\n",
            "Epoch 133/2000\n",
            "110/110 [==============================] - 2s 14ms/step - loss: 0.0328 - accuracy: 0.9891 - val_loss: 0.8726 - val_accuracy: 0.8627 - lr: 1.6423e-05\n",
            "Epoch 134/2000\n",
            "110/110 [==============================] - 1s 13ms/step - loss: 0.0295 - accuracy: 0.9891 - val_loss: 0.8847 - val_accuracy: 0.8673 - lr: 1.4781e-05\n",
            "Epoch 135/2000\n",
            "110/110 [==============================] - 2s 14ms/step - loss: 0.0298 - accuracy: 0.9886 - val_loss: 0.9158 - val_accuracy: 0.8623 - lr: 1.4781e-05\n",
            "Epoch 136/2000\n",
            "110/110 [==============================] - 2s 14ms/step - loss: 0.0363 - accuracy: 0.9863 - val_loss: 0.9191 - val_accuracy: 0.8600 - lr: 1.4781e-05\n",
            "Epoch 137/2000\n",
            "110/110 [==============================] - 2s 14ms/step - loss: 0.0283 - accuracy: 0.9887 - val_loss: 0.8277 - val_accuracy: 0.8707 - lr: 1.3303e-05\n",
            "Epoch 138/2000\n",
            "110/110 [==============================] - 2s 14ms/step - loss: 0.0246 - accuracy: 0.9901 - val_loss: 0.8798 - val_accuracy: 0.8643 - lr: 1.3303e-05\n",
            "Epoch 139/2000\n",
            "110/110 [==============================] - 2s 15ms/step - loss: 0.0308 - accuracy: 0.9881 - val_loss: 0.8619 - val_accuracy: 0.8657 - lr: 1.3303e-05\n",
            "Epoch 140/2000\n",
            "110/110 [==============================] - 2s 14ms/step - loss: 0.0286 - accuracy: 0.9879 - val_loss: 0.9436 - val_accuracy: 0.8650 - lr: 1.1973e-05\n",
            "Epoch 141/2000\n",
            "110/110 [==============================] - 2s 14ms/step - loss: 0.0319 - accuracy: 0.9876 - val_loss: 0.8645 - val_accuracy: 0.8640 - lr: 1.1973e-05\n",
            "Epoch 142/2000\n",
            "110/110 [==============================] - 2s 14ms/step - loss: 0.0277 - accuracy: 0.9894 - val_loss: 0.8877 - val_accuracy: 0.8713 - lr: 1.1973e-05\n",
            "Epoch 143/2000\n",
            "110/110 [==============================] - 1s 13ms/step - loss: 0.0257 - accuracy: 0.9914 - val_loss: 0.8854 - val_accuracy: 0.8637 - lr: 1.0775e-05\n",
            "Epoch 144/2000\n",
            "110/110 [==============================] - 1s 13ms/step - loss: 0.0273 - accuracy: 0.9889 - val_loss: 0.9329 - val_accuracy: 0.8497 - lr: 1.0775e-05\n",
            "Epoch 145/2000\n",
            "110/110 [==============================] - 2s 14ms/step - loss: 0.0251 - accuracy: 0.9897 - val_loss: 0.8784 - val_accuracy: 0.8637 - lr: 1.0775e-05\n",
            "Epoch 146/2000\n",
            "110/110 [==============================] - 2s 14ms/step - loss: 0.0276 - accuracy: 0.9894 - val_loss: 0.9001 - val_accuracy: 0.8673 - lr: 9.6977e-06\n",
            "Epoch 147/2000\n",
            "110/110 [==============================] - 1s 14ms/step - loss: 0.0288 - accuracy: 0.9894 - val_loss: 0.9058 - val_accuracy: 0.8560 - lr: 9.6977e-06\n",
            "Epoch 148/2000\n",
            "110/110 [==============================] - 2s 14ms/step - loss: 0.0247 - accuracy: 0.9909 - val_loss: 0.9580 - val_accuracy: 0.8583 - lr: 9.6977e-06\n",
            "Epoch 149/2000\n",
            "110/110 [==============================] - 1s 13ms/step - loss: 0.0228 - accuracy: 0.9931 - val_loss: 0.9599 - val_accuracy: 0.8560 - lr: 8.7280e-06\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f3ec06f6a10>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "#######HYPERPARAMATERS###########\n",
        "epochs = 2000\n",
        "batch_size = 64\n",
        "learning_rate = 0.001\n",
        "#################################\n",
        "  \n",
        "model = Sequential()\n",
        "    \n",
        "model.add(Conv2D(32, kernel_size = (3,3), input_shape=(28,28,1), activation='relu'))\n",
        "model.add(Conv2D(64,(3,3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=2))\n",
        "model.add(PermaDropout(0.5))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(PermaDropout(0.5))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "adam = keras.optimizers.Adam(learning_rate)\n",
        "model.compile(optimizer = adam, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
        "    \n",
        "# print(model.summary())\n",
        "\n",
        "lr_reducer = ReduceLROnPlateau(monitor='val_loss', factor=0.9, patience=3)\n",
        "early_stopper = EarlyStopping(monitor='val_accuracy', min_delta=0, patience=30, mode='auto')\n",
        "checkpointer = ModelCheckpoint('weights.hd5', monitor='val_loss', verbose=1, save_best_only=True)\n",
        "\n",
        "model.fit(\n",
        "          train_data,\n",
        "          train_labels,\n",
        "          epochs = epochs,\n",
        "          batch_size = batch_size,\n",
        "          validation_split = 0.3,\n",
        "          shuffle = True,\n",
        "          callbacks=[lr_reducer, early_stopper]\n",
        "          )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LVOc3hYIkXrl"
      },
      "outputs": [],
      "source": [
        "model.save('/content/drive/MyDrive/파이썬스터디 프로젝트/labeling_cnn.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n5D8i_BCkdjS"
      },
      "outputs": [],
      "source": [
        "model = keras.models.load_model('/content/drive/MyDrive/파이썬스터디 프로젝트/labeling_cnn.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TD8ppILhFUrz"
      },
      "source": [
        "## 모델 결과"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Ljx2EWA2v2n"
      },
      "outputs": [],
      "source": [
        "def model_eval():\n",
        "  pred_mu = model.predict(test_data)\n",
        "  for i in range(1, 30):\n",
        "    pred_mu += model.predict(test_data)\n",
        "  pred_mu = pred_mu/30\n",
        "  predicted_test_labels = np.argmax(pred_mu, axis=1)\n",
        "  return(accuracy_score(np.argmax(test_labels, axis=1), predicted_test_labels))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OzhQw9NOWjl3",
        "outputId": "34350c78-d52d-42fe-b5f1-d9effa37e7d2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8852"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "model = keras.models.load_model('/content/drive/MyDrive/파이썬스터디 프로젝트/labeling_cnn.h5')\n",
        "model_eval()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rcbs04885lTu"
      },
      "source": [
        "# 라벨링"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mAtfoQKLZDJC"
      },
      "source": [
        "## 라벨링; 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GKJgmFGWhlfl"
      },
      "outputs": [],
      "source": [
        "model = keras.models.load_model('/content/drive/MyDrive/파이썬스터디 프로젝트/labeling_cnn.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J_Jb5VX9ZC3y",
        "outputId": "9824475d-3efb-417a-c96d-2ae67d6fc750"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 30/30 [02:18<00:00,  4.63s/it]\n",
            "100%|██████████| 50000/50000 [00:10<00:00, 4889.33it/s]\n"
          ]
        }
      ],
      "source": [
        "# Vars : 분산들\n",
        "# Outs : 결과 값들\n",
        "\n",
        "Vars = []\n",
        "Outs = []\n",
        "\n",
        "temp1 = []\n",
        "\n",
        "for i in tqdm(range(30)):\n",
        "  temp1.append(model.predict(unlab_data))\n",
        "\n",
        "for j in tqdm(range(unlab_data.shape[0])):\n",
        "\n",
        "  temp2 = np.array([0,0,0,0,0,0,0,0,0,0], 'float32')\n",
        "  \n",
        "  for i in range(30):\n",
        "    temp2 += temp1[i][j]\n",
        "  Outs.append(temp2/30)\n",
        "  \n",
        "  outputs=[]\n",
        "\n",
        "  for i in range(30):\n",
        "    outputs.append(temp1[i][j][np.argmax(temp2)])\n",
        "  Vars.append(np.var(outputs))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-NnAVIXTXlAa"
      },
      "outputs": [],
      "source": [
        "Outs = np.array(Outs)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "class마다 균등하게 선택"
      ],
      "metadata": {
        "id": "XxIFHtGqAF9B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Counter(np.argmax(unlab_labels, axis=1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IGGGKCzvAiZb",
        "outputId": "6ff307c4-5f20-4dc6-b120-f6d704b906ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({0: 5058,\n",
              "         1: 4973,\n",
              "         2: 4984,\n",
              "         3: 4981,\n",
              "         4: 5026,\n",
              "         5: 5011,\n",
              "         6: 4979,\n",
              "         7: 4978,\n",
              "         8: 5010,\n",
              "         9: 5000})"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# upper bound of variance?\n",
        "\n",
        "UB = []\n",
        "\n",
        "for h in range(10):\n",
        "  classvars = []\n",
        "  for i in tqdm(range(50000)):\n",
        "    if np.argmax(unlab_labels, axis=1).tolist()[i]==h:\n",
        "      classvars.append(Vars[i])\n",
        "  UB.append(np.percentile(classvars, 50))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uDAwvSCVBLA4",
        "outputId": "2fc40e80-4c31-46d8-a5ab-273d54f3d629"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50000/50000 [01:24<00:00, 590.23it/s]\n",
            "100%|██████████| 50000/50000 [01:29<00:00, 561.58it/s]\n",
            "100%|██████████| 50000/50000 [01:25<00:00, 585.09it/s]\n",
            "100%|██████████| 50000/50000 [01:24<00:00, 589.09it/s]\n",
            "100%|██████████| 50000/50000 [01:25<00:00, 585.43it/s]\n",
            "100%|██████████| 50000/50000 [01:26<00:00, 578.97it/s]\n",
            "100%|██████████| 50000/50000 [01:26<00:00, 578.81it/s]\n",
            "100%|██████████| 50000/50000 [01:27<00:00, 573.93it/s]\n",
            "100%|██████████| 50000/50000 [01:27<00:00, 573.30it/s]\n",
            "100%|██████████| 50000/50000 [01:24<00:00, 589.32it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6BUHoKvtkJ37"
      },
      "outputs": [],
      "source": [
        "lowvars = []\n",
        "ind = 0 \n",
        "\n",
        "for i in Vars:\n",
        "  if i <= UB[np.argmax(unlab_labels, axis=1)[ind]]:\n",
        "    lowvars.append(ind)\n",
        "  ind += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9WhEDezq362P"
      },
      "outputs": [],
      "source": [
        "highvars = []\n",
        "for i in range(unlab_data.shape[0]):\n",
        "  if i not in lowvars:\n",
        "    highvars.append(i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0uSdhE1VmF5a",
        "outputId": "c427ea32-0e5c-4928-be41-4cdef55df959"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.89192"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "# 같은 길이의 랜덤하게 고른 data들에 모델로 label 부여 후 정확도 측정\n",
        "randomindx = random.sample(range(50000), 50000)\n",
        "randomindx2 = randomindx[0:25000]\n",
        "randomindx = randomindx[25000:50000]\n",
        "accuracy_score(np.argmax(np.array(Outs)[randomindx], axis=1), np.argmax(unlab_labels[randomindx], axis=1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gtEPD5p5kM-z",
        "outputId": "e6c93b65-dfe5-49f6-ab77-79f7d0814c6c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9728878433874247"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "# 저분산의 data들만 모아서 모델로 label 부여 후 정확도 측정 : 95% 이상\n",
        "accuracy_score(np.argmax(np.array(Outs)[lowvars], axis=1), np.argmax(unlab_labels[lowvars], axis=1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C2ab4GUWwe30"
      },
      "outputs": [],
      "source": [
        "train_data_1 = np.concatenate([train_data, unlab_data[lowvars]], axis=0)\n",
        "train_labels_1 = np.concatenate([train_labels, Outs[lowvars]], axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1xahhoBY8mKc"
      },
      "outputs": [],
      "source": [
        "shufindx = random.sample(range(train_data_1.shape[0]),train_data_1.shape[0])\n",
        "train_data_1 = train_data_1[shufindx]\n",
        "train_labels_1 = train_labels_1[shufindx]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_2 = np.concatenate([train_data, unlab_data[randomindx]], axis=0)\n",
        "train_labels_2 = np.concatenate([train_labels, Outs[randomindx]], axis=0)"
      ],
      "metadata": {
        "id": "7gQWZXNojDvb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shufindx = random.sample(range(train_data_2.shape[0]),train_data_2.shape[0])\n",
        "train_data_2 = train_data_2[shufindx]\n",
        "train_labels_2 = train_labels_2[shufindx]"
      ],
      "metadata": {
        "id": "4tdOxYBQjFGT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_t9J8vlJ5TDO"
      },
      "outputs": [],
      "source": [
        "unlab_data_1 = unlab_data[highvars]\n",
        "unlab_labels_1 = unlab_labels[highvars]\n",
        "unlab_data_2 = unlab_data[randomindx2]\n",
        "unlab_labels_2 = unlab_labels[randomindx2]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Counter(np.argmax(train_labels_1, axis=1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z7Jq-n0L8diD",
        "outputId": "9dfcefff-d842-4581-de6b-579daea38e94"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({0: 3600,\n",
              "         1: 3599,\n",
              "         2: 3613,\n",
              "         3: 3638,\n",
              "         4: 3469,\n",
              "         5: 3491,\n",
              "         6: 3151,\n",
              "         7: 3507,\n",
              "         8: 3505,\n",
              "         9: 3508})"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Counter(np.argmax(train_labels_2, axis=1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4CLpAKvu8kD6",
        "outputId": "00fce93a-128c-471e-d460-410106f853da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({0: 3409,\n",
              "         1: 3473,\n",
              "         2: 3582,\n",
              "         3: 3546,\n",
              "         4: 3512,\n",
              "         5: 3488,\n",
              "         6: 3448,\n",
              "         7: 3581,\n",
              "         8: 3447,\n",
              "         9: 3514})"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Counter(np.argmax(unlab_labels_1, axis=1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C5t5J130x7pe",
        "outputId": "6c32f60a-2251-4d7c-e35a-b8e445dbb790"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({0: 2529,\n",
              "         1: 2407,\n",
              "         2: 2492,\n",
              "         3: 2490,\n",
              "         4: 2513,\n",
              "         5: 2505,\n",
              "         6: 2489,\n",
              "         7: 2489,\n",
              "         8: 2505,\n",
              "         9: 2500})"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Counter(np.argmax(unlab_labels_2, axis=1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OBMxw6eEx92l",
        "outputId": "57ac6607-fa7f-4bc9-8e0b-f4e876ab52d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({0: 2565,\n",
              "         1: 2496,\n",
              "         2: 2452,\n",
              "         3: 2497,\n",
              "         4: 2506,\n",
              "         5: 2458,\n",
              "         6: 2504,\n",
              "         7: 2474,\n",
              "         8: 2554,\n",
              "         9: 2494})"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bOtFA9fr5oDF"
      },
      "source": [
        "## 모델링\n",
        "\n",
        "간단한 모델에서 받은 지식를 복잡한 모델에서 학습 \n",
        "\n",
        "uncertainty aware data vs random sampling data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m7Pd9SYK5tv_"
      },
      "outputs": [],
      "source": [
        "def PermaDropout(rate):\n",
        "    return Lambda(lambda x: K.dropout(x, level=rate))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W6WgyM3Y5twA",
        "outputId": "8bb6c96b-eaf5-4c6a-c9dd-ad622ebf5148"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2000\n",
            "384/384 [==============================] - 11s 24ms/step - loss: 1.0012 - accuracy: 0.6886 - val_loss: 0.5072 - val_accuracy: 0.8266 - lr: 0.0010\n",
            "Epoch 2/2000\n",
            "384/384 [==============================] - 9s 22ms/step - loss: 0.4127 - accuracy: 0.8674 - val_loss: 0.3816 - val_accuracy: 0.8791 - lr: 0.0010\n",
            "Epoch 3/2000\n",
            "384/384 [==============================] - 8s 22ms/step - loss: 0.3427 - accuracy: 0.8944 - val_loss: 0.3175 - val_accuracy: 0.9002 - lr: 0.0010\n",
            "Epoch 4/2000\n",
            "384/384 [==============================] - 8s 22ms/step - loss: 0.2910 - accuracy: 0.9115 - val_loss: 0.2988 - val_accuracy: 0.9161 - lr: 0.0010\n",
            "Epoch 5/2000\n",
            "384/384 [==============================] - 9s 22ms/step - loss: 0.2704 - accuracy: 0.9202 - val_loss: 0.2644 - val_accuracy: 0.9214 - lr: 0.0010\n",
            "Epoch 6/2000\n",
            "384/384 [==============================] - 8s 22ms/step - loss: 0.2438 - accuracy: 0.9299 - val_loss: 0.2580 - val_accuracy: 0.9280 - lr: 0.0010\n",
            "Epoch 7/2000\n",
            "384/384 [==============================] - 8s 22ms/step - loss: 0.2332 - accuracy: 0.9303 - val_loss: 0.2685 - val_accuracy: 0.9255 - lr: 0.0010\n",
            "Epoch 8/2000\n",
            "384/384 [==============================] - 9s 22ms/step - loss: 0.2240 - accuracy: 0.9368 - val_loss: 0.2418 - val_accuracy: 0.9319 - lr: 0.0010\n",
            "Epoch 9/2000\n",
            "384/384 [==============================] - 9s 22ms/step - loss: 0.2147 - accuracy: 0.9396 - val_loss: 0.2480 - val_accuracy: 0.9343 - lr: 0.0010\n",
            "Epoch 10/2000\n",
            "384/384 [==============================] - 8s 22ms/step - loss: 0.2026 - accuracy: 0.9440 - val_loss: 0.2263 - val_accuracy: 0.9381 - lr: 0.0010\n",
            "Epoch 11/2000\n",
            "384/384 [==============================] - 8s 22ms/step - loss: 0.1974 - accuracy: 0.9468 - val_loss: 0.2329 - val_accuracy: 0.9375 - lr: 0.0010\n",
            "Epoch 12/2000\n",
            "384/384 [==============================] - 9s 22ms/step - loss: 0.1922 - accuracy: 0.9468 - val_loss: 0.2324 - val_accuracy: 0.9369 - lr: 0.0010\n",
            "Epoch 13/2000\n",
            "384/384 [==============================] - 9s 22ms/step - loss: 0.1903 - accuracy: 0.9465 - val_loss: 0.2334 - val_accuracy: 0.9375 - lr: 0.0010\n",
            "Epoch 14/2000\n",
            "384/384 [==============================] - 8s 22ms/step - loss: 0.1795 - accuracy: 0.9504 - val_loss: 0.2117 - val_accuracy: 0.9443 - lr: 9.0000e-04\n",
            "Epoch 15/2000\n",
            "384/384 [==============================] - 8s 22ms/step - loss: 0.1703 - accuracy: 0.9529 - val_loss: 0.2187 - val_accuracy: 0.9406 - lr: 9.0000e-04\n",
            "Epoch 16/2000\n",
            "384/384 [==============================] - 8s 22ms/step - loss: 0.1702 - accuracy: 0.9527 - val_loss: 0.2207 - val_accuracy: 0.9393 - lr: 9.0000e-04\n",
            "Epoch 17/2000\n",
            "384/384 [==============================] - 8s 22ms/step - loss: 0.1653 - accuracy: 0.9550 - val_loss: 0.2164 - val_accuracy: 0.9436 - lr: 9.0000e-04\n",
            "Epoch 18/2000\n",
            "384/384 [==============================] - 8s 22ms/step - loss: 0.1609 - accuracy: 0.9568 - val_loss: 0.2164 - val_accuracy: 0.9454 - lr: 8.1000e-04\n",
            "Epoch 19/2000\n",
            "384/384 [==============================] - 8s 22ms/step - loss: 0.1538 - accuracy: 0.9596 - val_loss: 0.2055 - val_accuracy: 0.9471 - lr: 8.1000e-04\n",
            "Epoch 20/2000\n",
            "384/384 [==============================] - 9s 23ms/step - loss: 0.1491 - accuracy: 0.9610 - val_loss: 0.2112 - val_accuracy: 0.9458 - lr: 8.1000e-04\n",
            "Epoch 21/2000\n",
            "384/384 [==============================] - 8s 22ms/step - loss: 0.1495 - accuracy: 0.9599 - val_loss: 0.2022 - val_accuracy: 0.9476 - lr: 8.1000e-04\n",
            "Epoch 22/2000\n",
            "384/384 [==============================] - 9s 22ms/step - loss: 0.1463 - accuracy: 0.9622 - val_loss: 0.1989 - val_accuracy: 0.9481 - lr: 8.1000e-04\n",
            "Epoch 23/2000\n",
            "384/384 [==============================] - 8s 22ms/step - loss: 0.1440 - accuracy: 0.9612 - val_loss: 0.2032 - val_accuracy: 0.9502 - lr: 8.1000e-04\n",
            "Epoch 24/2000\n",
            "384/384 [==============================] - 8s 22ms/step - loss: 0.1445 - accuracy: 0.9622 - val_loss: 0.2094 - val_accuracy: 0.9491 - lr: 8.1000e-04\n",
            "Epoch 25/2000\n",
            "384/384 [==============================] - 8s 22ms/step - loss: 0.1435 - accuracy: 0.9625 - val_loss: 0.1982 - val_accuracy: 0.9501 - lr: 8.1000e-04\n",
            "Epoch 26/2000\n",
            "384/384 [==============================] - 8s 22ms/step - loss: 0.1431 - accuracy: 0.9625 - val_loss: 0.2100 - val_accuracy: 0.9488 - lr: 8.1000e-04\n",
            "Epoch 27/2000\n",
            "384/384 [==============================] - 8s 22ms/step - loss: 0.1381 - accuracy: 0.9643 - val_loss: 0.2075 - val_accuracy: 0.9496 - lr: 8.1000e-04\n",
            "Epoch 28/2000\n",
            "384/384 [==============================] - 9s 22ms/step - loss: 0.1346 - accuracy: 0.9637 - val_loss: 0.2229 - val_accuracy: 0.9483 - lr: 8.1000e-04\n",
            "Epoch 29/2000\n",
            "384/384 [==============================] - 8s 22ms/step - loss: 0.1347 - accuracy: 0.9653 - val_loss: 0.2060 - val_accuracy: 0.9510 - lr: 7.2900e-04\n",
            "Epoch 30/2000\n",
            "384/384 [==============================] - 9s 22ms/step - loss: 0.1259 - accuracy: 0.9679 - val_loss: 0.2133 - val_accuracy: 0.9500 - lr: 7.2900e-04\n",
            "Epoch 31/2000\n",
            "384/384 [==============================] - 8s 22ms/step - loss: 0.1281 - accuracy: 0.9674 - val_loss: 0.1943 - val_accuracy: 0.9529 - lr: 7.2900e-04\n",
            "Epoch 32/2000\n",
            "384/384 [==============================] - 9s 23ms/step - loss: 0.1251 - accuracy: 0.9684 - val_loss: 0.1984 - val_accuracy: 0.9507 - lr: 7.2900e-04\n",
            "Epoch 33/2000\n",
            "384/384 [==============================] - 9s 22ms/step - loss: 0.1248 - accuracy: 0.9677 - val_loss: 0.2113 - val_accuracy: 0.9480 - lr: 7.2900e-04\n",
            "Epoch 34/2000\n",
            "384/384 [==============================] - 9s 23ms/step - loss: 0.1242 - accuracy: 0.9693 - val_loss: 0.2179 - val_accuracy: 0.9517 - lr: 7.2900e-04\n",
            "Epoch 35/2000\n",
            "384/384 [==============================] - 9s 23ms/step - loss: 0.1195 - accuracy: 0.9723 - val_loss: 0.1866 - val_accuracy: 0.9555 - lr: 6.5610e-04\n",
            "Epoch 36/2000\n",
            "384/384 [==============================] - 9s 22ms/step - loss: 0.1175 - accuracy: 0.9702 - val_loss: 0.2270 - val_accuracy: 0.9496 - lr: 6.5610e-04\n",
            "Epoch 37/2000\n",
            "384/384 [==============================] - 9s 23ms/step - loss: 0.1160 - accuracy: 0.9724 - val_loss: 0.2001 - val_accuracy: 0.9548 - lr: 6.5610e-04\n",
            "Epoch 38/2000\n",
            "384/384 [==============================] - 9s 22ms/step - loss: 0.1178 - accuracy: 0.9721 - val_loss: 0.1914 - val_accuracy: 0.9538 - lr: 6.5610e-04\n",
            "Epoch 39/2000\n",
            "384/384 [==============================] - 9s 22ms/step - loss: 0.1179 - accuracy: 0.9724 - val_loss: 0.2143 - val_accuracy: 0.9514 - lr: 5.9049e-04\n",
            "Epoch 40/2000\n",
            "384/384 [==============================] - 9s 22ms/step - loss: 0.1104 - accuracy: 0.9745 - val_loss: 0.2038 - val_accuracy: 0.9548 - lr: 5.9049e-04\n",
            "Epoch 41/2000\n",
            "384/384 [==============================] - 9s 23ms/step - loss: 0.1112 - accuracy: 0.9739 - val_loss: 0.2358 - val_accuracy: 0.9511 - lr: 5.9049e-04\n",
            "Epoch 42/2000\n",
            "384/384 [==============================] - 9s 23ms/step - loss: 0.1075 - accuracy: 0.9740 - val_loss: 0.2000 - val_accuracy: 0.9562 - lr: 5.3144e-04\n",
            "Epoch 43/2000\n",
            "384/384 [==============================] - 8s 22ms/step - loss: 0.1012 - accuracy: 0.9776 - val_loss: 0.2021 - val_accuracy: 0.9550 - lr: 5.3144e-04\n",
            "Epoch 44/2000\n",
            "384/384 [==============================] - 8s 22ms/step - loss: 0.1023 - accuracy: 0.9771 - val_loss: 0.1944 - val_accuracy: 0.9552 - lr: 5.3144e-04\n",
            "Epoch 45/2000\n",
            "384/384 [==============================] - 9s 22ms/step - loss: 0.0980 - accuracy: 0.9780 - val_loss: 0.2015 - val_accuracy: 0.9556 - lr: 4.7830e-04\n",
            "Epoch 46/2000\n",
            "384/384 [==============================] - 8s 22ms/step - loss: 0.1004 - accuracy: 0.9772 - val_loss: 0.2008 - val_accuracy: 0.9550 - lr: 4.7830e-04\n",
            "Epoch 47/2000\n",
            "384/384 [==============================] - 9s 22ms/step - loss: 0.0977 - accuracy: 0.9775 - val_loss: 0.2068 - val_accuracy: 0.9560 - lr: 4.7830e-04\n",
            "Epoch 48/2000\n",
            "384/384 [==============================] - 8s 22ms/step - loss: 0.0982 - accuracy: 0.9786 - val_loss: 0.1991 - val_accuracy: 0.9601 - lr: 4.3047e-04\n",
            "Epoch 49/2000\n",
            "384/384 [==============================] - 9s 22ms/step - loss: 0.0924 - accuracy: 0.9802 - val_loss: 0.2029 - val_accuracy: 0.9571 - lr: 4.3047e-04\n",
            "Epoch 50/2000\n",
            "384/384 [==============================] - 8s 22ms/step - loss: 0.1001 - accuracy: 0.9794 - val_loss: 0.2009 - val_accuracy: 0.9551 - lr: 4.3047e-04\n",
            "Epoch 51/2000\n",
            "384/384 [==============================] - 8s 22ms/step - loss: 0.0901 - accuracy: 0.9812 - val_loss: 0.2037 - val_accuracy: 0.9571 - lr: 3.8742e-04\n",
            "Epoch 52/2000\n",
            "384/384 [==============================] - 8s 22ms/step - loss: 0.0895 - accuracy: 0.9819 - val_loss: 0.2025 - val_accuracy: 0.9563 - lr: 3.8742e-04\n",
            "Epoch 53/2000\n",
            "384/384 [==============================] - 9s 22ms/step - loss: 0.0871 - accuracy: 0.9828 - val_loss: 0.2246 - val_accuracy: 0.9570 - lr: 3.8742e-04\n",
            "Epoch 54/2000\n",
            "384/384 [==============================] - 8s 22ms/step - loss: 0.0934 - accuracy: 0.9806 - val_loss: 0.2245 - val_accuracy: 0.9550 - lr: 3.4868e-04\n",
            "Epoch 55/2000\n",
            "384/384 [==============================] - 8s 22ms/step - loss: 0.0874 - accuracy: 0.9821 - val_loss: 0.2050 - val_accuracy: 0.9566 - lr: 3.4868e-04\n",
            "Epoch 56/2000\n",
            "384/384 [==============================] - 8s 22ms/step - loss: 0.0859 - accuracy: 0.9828 - val_loss: 0.1992 - val_accuracy: 0.9599 - lr: 3.4868e-04\n",
            "Epoch 57/2000\n",
            "384/384 [==============================] - 8s 22ms/step - loss: 0.0824 - accuracy: 0.9844 - val_loss: 0.2016 - val_accuracy: 0.9548 - lr: 3.1381e-04\n",
            "Epoch 58/2000\n",
            "384/384 [==============================] - 8s 22ms/step - loss: 0.0817 - accuracy: 0.9844 - val_loss: 0.2093 - val_accuracy: 0.9571 - lr: 3.1381e-04\n",
            "Epoch 59/2000\n",
            "384/384 [==============================] - 8s 22ms/step - loss: 0.0789 - accuracy: 0.9857 - val_loss: 0.2087 - val_accuracy: 0.9602 - lr: 3.1381e-04\n",
            "Epoch 60/2000\n",
            "384/384 [==============================] - 8s 22ms/step - loss: 0.0796 - accuracy: 0.9849 - val_loss: 0.2098 - val_accuracy: 0.9572 - lr: 2.8243e-04\n",
            "Epoch 61/2000\n",
            "384/384 [==============================] - 8s 22ms/step - loss: 0.0820 - accuracy: 0.9840 - val_loss: 0.2204 - val_accuracy: 0.9571 - lr: 2.8243e-04\n",
            "Epoch 62/2000\n",
            "384/384 [==============================] - 9s 22ms/step - loss: 0.0769 - accuracy: 0.9858 - val_loss: 0.2130 - val_accuracy: 0.9597 - lr: 2.8243e-04\n",
            "Epoch 63/2000\n",
            "384/384 [==============================] - 8s 22ms/step - loss: 0.0777 - accuracy: 0.9854 - val_loss: 0.2216 - val_accuracy: 0.9575 - lr: 2.5419e-04\n",
            "Epoch 64/2000\n",
            "384/384 [==============================] - 8s 22ms/step - loss: 0.0763 - accuracy: 0.9866 - val_loss: 0.2119 - val_accuracy: 0.9588 - lr: 2.5419e-04\n",
            "Epoch 65/2000\n",
            "384/384 [==============================] - 9s 22ms/step - loss: 0.0731 - accuracy: 0.9882 - val_loss: 0.2066 - val_accuracy: 0.9556 - lr: 2.5419e-04\n",
            "Epoch 66/2000\n",
            "384/384 [==============================] - 9s 22ms/step - loss: 0.0782 - accuracy: 0.9864 - val_loss: 0.2068 - val_accuracy: 0.9581 - lr: 2.2877e-04\n",
            "Epoch 67/2000\n",
            "384/384 [==============================] - 8s 22ms/step - loss: 0.0744 - accuracy: 0.9875 - val_loss: 0.2147 - val_accuracy: 0.9588 - lr: 2.2877e-04\n",
            "Epoch 68/2000\n",
            "384/384 [==============================] - 8s 22ms/step - loss: 0.0736 - accuracy: 0.9884 - val_loss: 0.2226 - val_accuracy: 0.9601 - lr: 2.2877e-04\n",
            "Epoch 69/2000\n",
            "384/384 [==============================] - 8s 22ms/step - loss: 0.0741 - accuracy: 0.9875 - val_loss: 0.2067 - val_accuracy: 0.9586 - lr: 2.0589e-04\n",
            "Epoch 70/2000\n",
            "384/384 [==============================] - 8s 22ms/step - loss: 0.0704 - accuracy: 0.9888 - val_loss: 0.2157 - val_accuracy: 0.9582 - lr: 2.0589e-04\n",
            "Epoch 71/2000\n",
            "384/384 [==============================] - 8s 22ms/step - loss: 0.0714 - accuracy: 0.9888 - val_loss: 0.2144 - val_accuracy: 0.9595 - lr: 2.0589e-04\n",
            "Epoch 72/2000\n",
            "384/384 [==============================] - 9s 23ms/step - loss: 0.0713 - accuracy: 0.9885 - val_loss: 0.2041 - val_accuracy: 0.9610 - lr: 1.8530e-04\n",
            "Epoch 73/2000\n",
            "384/384 [==============================] - 9s 22ms/step - loss: 0.0711 - accuracy: 0.9880 - val_loss: 0.2087 - val_accuracy: 0.9587 - lr: 1.8530e-04\n",
            "Epoch 74/2000\n",
            "384/384 [==============================] - 9s 24ms/step - loss: 0.0705 - accuracy: 0.9890 - val_loss: 0.2146 - val_accuracy: 0.9587 - lr: 1.8530e-04\n",
            "Epoch 75/2000\n",
            "384/384 [==============================] - 9s 23ms/step - loss: 0.0664 - accuracy: 0.9900 - val_loss: 0.2148 - val_accuracy: 0.9599 - lr: 1.6677e-04\n",
            "Epoch 76/2000\n",
            "384/384 [==============================] - 9s 22ms/step - loss: 0.0674 - accuracy: 0.9905 - val_loss: 0.2135 - val_accuracy: 0.9584 - lr: 1.6677e-04\n",
            "Epoch 77/2000\n",
            "384/384 [==============================] - 8s 22ms/step - loss: 0.0670 - accuracy: 0.9899 - val_loss: 0.2268 - val_accuracy: 0.9572 - lr: 1.6677e-04\n",
            "Epoch 78/2000\n",
            "384/384 [==============================] - 9s 22ms/step - loss: 0.0686 - accuracy: 0.9886 - val_loss: 0.2106 - val_accuracy: 0.9602 - lr: 1.5009e-04\n",
            "Epoch 79/2000\n",
            "384/384 [==============================] - 8s 22ms/step - loss: 0.0672 - accuracy: 0.9910 - val_loss: 0.2137 - val_accuracy: 0.9589 - lr: 1.5009e-04\n",
            "Epoch 80/2000\n",
            "384/384 [==============================] - 9s 22ms/step - loss: 0.0651 - accuracy: 0.9907 - val_loss: 0.2067 - val_accuracy: 0.9587 - lr: 1.5009e-04\n",
            "Epoch 81/2000\n",
            "384/384 [==============================] - 8s 22ms/step - loss: 0.0663 - accuracy: 0.9900 - val_loss: 0.2046 - val_accuracy: 0.9589 - lr: 1.3509e-04\n",
            "Epoch 82/2000\n",
            "384/384 [==============================] - 8s 22ms/step - loss: 0.0663 - accuracy: 0.9906 - val_loss: 0.2175 - val_accuracy: 0.9592 - lr: 1.3509e-04\n",
            "Epoch 83/2000\n",
            "384/384 [==============================] - 9s 22ms/step - loss: 0.0665 - accuracy: 0.9903 - val_loss: 0.2115 - val_accuracy: 0.9597 - lr: 1.3509e-04\n",
            "Epoch 84/2000\n",
            "384/384 [==============================] - 8s 22ms/step - loss: 0.0643 - accuracy: 0.9910 - val_loss: 0.2213 - val_accuracy: 0.9572 - lr: 1.2158e-04\n",
            "Epoch 85/2000\n",
            "384/384 [==============================] - 9s 22ms/step - loss: 0.0640 - accuracy: 0.9917 - val_loss: 0.2263 - val_accuracy: 0.9585 - lr: 1.2158e-04\n",
            "Epoch 86/2000\n",
            "384/384 [==============================] - 9s 23ms/step - loss: 0.0642 - accuracy: 0.9913 - val_loss: 0.2104 - val_accuracy: 0.9602 - lr: 1.2158e-04\n",
            "Epoch 87/2000\n",
            "384/384 [==============================] - 9s 23ms/step - loss: 0.0617 - accuracy: 0.9925 - val_loss: 0.2008 - val_accuracy: 0.9628 - lr: 1.0942e-04\n",
            "Epoch 88/2000\n",
            "384/384 [==============================] - 9s 23ms/step - loss: 0.0626 - accuracy: 0.9918 - val_loss: 0.2099 - val_accuracy: 0.9592 - lr: 1.0942e-04\n",
            "Epoch 89/2000\n",
            "384/384 [==============================] - 9s 22ms/step - loss: 0.0629 - accuracy: 0.9923 - val_loss: 0.2182 - val_accuracy: 0.9602 - lr: 1.0942e-04\n",
            "Epoch 90/2000\n",
            "384/384 [==============================] - 8s 22ms/step - loss: 0.0619 - accuracy: 0.9919 - val_loss: 0.2317 - val_accuracy: 0.9610 - lr: 9.8477e-05\n",
            "Epoch 91/2000\n",
            "384/384 [==============================] - 8s 22ms/step - loss: 0.0614 - accuracy: 0.9926 - val_loss: 0.2210 - val_accuracy: 0.9599 - lr: 9.8477e-05\n",
            "Epoch 92/2000\n",
            "384/384 [==============================] - 9s 23ms/step - loss: 0.0616 - accuracy: 0.9930 - val_loss: 0.2212 - val_accuracy: 0.9614 - lr: 9.8477e-05\n",
            "Epoch 93/2000\n",
            "384/384 [==============================] - 8s 22ms/step - loss: 0.0605 - accuracy: 0.9926 - val_loss: 0.2164 - val_accuracy: 0.9597 - lr: 8.8629e-05\n",
            "Epoch 94/2000\n",
            "384/384 [==============================] - 8s 22ms/step - loss: 0.0613 - accuracy: 0.9923 - val_loss: 0.2206 - val_accuracy: 0.9590 - lr: 8.8629e-05\n",
            "Epoch 95/2000\n",
            "384/384 [==============================] - 9s 22ms/step - loss: 0.0617 - accuracy: 0.9926 - val_loss: 0.2294 - val_accuracy: 0.9569 - lr: 8.8629e-05\n",
            "Epoch 96/2000\n",
            "384/384 [==============================] - 8s 22ms/step - loss: 0.0609 - accuracy: 0.9930 - val_loss: 0.2170 - val_accuracy: 0.9603 - lr: 7.9766e-05\n",
            "Epoch 97/2000\n",
            "384/384 [==============================] - 8s 22ms/step - loss: 0.0599 - accuracy: 0.9933 - val_loss: 0.2114 - val_accuracy: 0.9600 - lr: 7.9766e-05\n",
            "Epoch 98/2000\n",
            "384/384 [==============================] - 8s 22ms/step - loss: 0.0603 - accuracy: 0.9934 - val_loss: 0.2141 - val_accuracy: 0.9602 - lr: 7.9766e-05\n",
            "Epoch 99/2000\n",
            "384/384 [==============================] - 9s 23ms/step - loss: 0.0599 - accuracy: 0.9930 - val_loss: 0.2232 - val_accuracy: 0.9592 - lr: 7.1790e-05\n",
            "Epoch 100/2000\n",
            "384/384 [==============================] - 8s 22ms/step - loss: 0.0590 - accuracy: 0.9937 - val_loss: 0.2180 - val_accuracy: 0.9600 - lr: 7.1790e-05\n",
            "Epoch 101/2000\n",
            "384/384 [==============================] - 8s 22ms/step - loss: 0.0571 - accuracy: 0.9938 - val_loss: 0.2039 - val_accuracy: 0.9615 - lr: 7.1790e-05\n",
            "Epoch 102/2000\n",
            "384/384 [==============================] - 9s 23ms/step - loss: 0.0587 - accuracy: 0.9937 - val_loss: 0.2046 - val_accuracy: 0.9606 - lr: 6.4611e-05\n",
            "Epoch 103/2000\n",
            "384/384 [==============================] - 8s 22ms/step - loss: 0.0581 - accuracy: 0.9935 - val_loss: 0.2193 - val_accuracy: 0.9612 - lr: 6.4611e-05\n",
            "Epoch 104/2000\n",
            "384/384 [==============================] - 9s 23ms/step - loss: 0.0586 - accuracy: 0.9941 - val_loss: 0.2203 - val_accuracy: 0.9602 - lr: 6.4611e-05\n",
            "Epoch 105/2000\n",
            "384/384 [==============================] - 8s 22ms/step - loss: 0.0586 - accuracy: 0.9930 - val_loss: 0.2163 - val_accuracy: 0.9609 - lr: 5.8150e-05\n",
            "Epoch 106/2000\n",
            "384/384 [==============================] - 8s 22ms/step - loss: 0.0578 - accuracy: 0.9939 - val_loss: 0.2082 - val_accuracy: 0.9620 - lr: 5.8150e-05\n",
            "Epoch 107/2000\n",
            "384/384 [==============================] - 8s 22ms/step - loss: 0.0601 - accuracy: 0.9928 - val_loss: 0.2205 - val_accuracy: 0.9571 - lr: 5.8150e-05\n",
            "Epoch 108/2000\n",
            "384/384 [==============================] - 8s 22ms/step - loss: 0.0599 - accuracy: 0.9937 - val_loss: 0.2150 - val_accuracy: 0.9610 - lr: 5.2335e-05\n",
            "Epoch 109/2000\n",
            "384/384 [==============================] - 8s 22ms/step - loss: 0.0576 - accuracy: 0.9944 - val_loss: 0.2015 - val_accuracy: 0.9607 - lr: 5.2335e-05\n",
            "Epoch 110/2000\n",
            "384/384 [==============================] - 8s 22ms/step - loss: 0.0588 - accuracy: 0.9940 - val_loss: 0.2239 - val_accuracy: 0.9604 - lr: 5.2335e-05\n",
            "Epoch 111/2000\n",
            "384/384 [==============================] - 8s 22ms/step - loss: 0.0587 - accuracy: 0.9936 - val_loss: 0.2102 - val_accuracy: 0.9591 - lr: 4.7101e-05\n",
            "Epoch 112/2000\n",
            "384/384 [==============================] - 9s 23ms/step - loss: 0.0578 - accuracy: 0.9941 - val_loss: 0.2281 - val_accuracy: 0.9592 - lr: 4.7101e-05\n",
            "Epoch 113/2000\n",
            "384/384 [==============================] - 8s 22ms/step - loss: 0.0574 - accuracy: 0.9940 - val_loss: 0.2164 - val_accuracy: 0.9620 - lr: 4.7101e-05\n",
            "Epoch 114/2000\n",
            "384/384 [==============================] - 9s 23ms/step - loss: 0.0586 - accuracy: 0.9932 - val_loss: 0.2092 - val_accuracy: 0.9600 - lr: 4.2391e-05\n",
            "Epoch 115/2000\n",
            "384/384 [==============================] - 8s 22ms/step - loss: 0.0569 - accuracy: 0.9947 - val_loss: 0.2069 - val_accuracy: 0.9623 - lr: 4.2391e-05\n",
            "Epoch 116/2000\n",
            "384/384 [==============================] - 9s 23ms/step - loss: 0.0577 - accuracy: 0.9943 - val_loss: 0.2114 - val_accuracy: 0.9610 - lr: 4.2391e-05\n",
            "Epoch 117/2000\n",
            "384/384 [==============================] - 8s 22ms/step - loss: 0.0567 - accuracy: 0.9950 - val_loss: 0.2068 - val_accuracy: 0.9591 - lr: 3.8152e-05\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fe96c28a3d0>"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ],
      "source": [
        "#######HYPERPARAMATERS###########\n",
        "epochs = 2000\n",
        "batch_size = 64\n",
        "learning_rate = 0.001\n",
        "#################################\n",
        "  \n",
        "model = Sequential()\n",
        "    \n",
        "model.add(Conv2D(32, kernel_size = (3,3), input_shape=(28,28,1), activation='relu'))\n",
        "\n",
        "model.add(Conv2D(64,(3,3), activation='relu'))\n",
        "model.add(Conv2D(64,(3,3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=2))\n",
        "model.add(PermaDropout(0.5))\n",
        "\n",
        "model.add(Conv2D(128,(3,3), activation='relu'))\n",
        "model.add(Conv2D(128,(3,3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=2))\n",
        "model.add(PermaDropout(0.5))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(PermaDropout(0.5))\n",
        "\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "adam = keras.optimizers.Adam(learning_rate)\n",
        "model.compile(optimizer = adam, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
        "    \n",
        "# print(model.summary())\n",
        "\n",
        "lr_reducer = ReduceLROnPlateau(monitor='val_loss', factor=0.9, patience=3)\n",
        "early_stopper = EarlyStopping(monitor='val_accuracy', min_delta=0, patience=30, mode='auto')\n",
        "checkpointer = ModelCheckpoint('weights.hd5', monitor='val_loss', verbose=1, save_best_only=True)\n",
        "\n",
        "\n",
        "model.fit(\n",
        "          train_data_1,\n",
        "          train_labels_1,\n",
        "          epochs = epochs,\n",
        "          batch_size = batch_size,\n",
        "          validation_split = 0.3,\n",
        "          shuffle = True,\n",
        "          callbacks=[lr_reducer, early_stopper]\n",
        "          )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9_zB1OL252B3"
      },
      "outputs": [],
      "source": [
        "model.save('/content/drive/MyDrive/파이썬스터디 프로젝트/labeling_cnn2.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BbEZKkhn52B4",
        "outputId": "2cc7cd07-02c9-49c6-c39f-b7ad168fa8e6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8938"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ],
      "source": [
        "model = keras.models.load_model('/content/drive/MyDrive/파이썬스터디 프로젝트/labeling_cnn2.h5')\n",
        "model_eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec1d2308-5f5e-4ec4-bede-122d1e784c5a",
        "id": "9KTK643Nkt4E"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2000\n",
            "383/383 [==============================] - 10s 23ms/step - loss: 1.2074 - accuracy: 0.6101 - val_loss: 0.6716 - val_accuracy: 0.7693 - lr: 0.0010\n",
            "Epoch 2/2000\n",
            "383/383 [==============================] - 8s 22ms/step - loss: 0.6132 - accuracy: 0.7924 - val_loss: 0.5614 - val_accuracy: 0.8164 - lr: 0.0010\n",
            "Epoch 3/2000\n",
            "383/383 [==============================] - 8s 22ms/step - loss: 0.5290 - accuracy: 0.8287 - val_loss: 0.5035 - val_accuracy: 0.8420 - lr: 0.0010\n",
            "Epoch 4/2000\n",
            "383/383 [==============================] - 8s 22ms/step - loss: 0.4836 - accuracy: 0.8504 - val_loss: 0.4638 - val_accuracy: 0.8570 - lr: 0.0010\n",
            "Epoch 5/2000\n",
            "383/383 [==============================] - 8s 22ms/step - loss: 0.4430 - accuracy: 0.8628 - val_loss: 0.4506 - val_accuracy: 0.8702 - lr: 0.0010\n",
            "Epoch 6/2000\n",
            "383/383 [==============================] - 8s 22ms/step - loss: 0.4222 - accuracy: 0.8691 - val_loss: 0.4217 - val_accuracy: 0.8756 - lr: 0.0010\n",
            "Epoch 7/2000\n",
            "383/383 [==============================] - 8s 22ms/step - loss: 0.4041 - accuracy: 0.8812 - val_loss: 0.4229 - val_accuracy: 0.8771 - lr: 0.0010\n",
            "Epoch 8/2000\n",
            "383/383 [==============================] - 8s 22ms/step - loss: 0.3964 - accuracy: 0.8842 - val_loss: 0.3993 - val_accuracy: 0.8869 - lr: 0.0010\n",
            "Epoch 9/2000\n",
            "383/383 [==============================] - 8s 22ms/step - loss: 0.3878 - accuracy: 0.8883 - val_loss: 0.4073 - val_accuracy: 0.8847 - lr: 0.0010\n",
            "Epoch 10/2000\n",
            "383/383 [==============================] - 8s 22ms/step - loss: 0.3782 - accuracy: 0.8913 - val_loss: 0.4039 - val_accuracy: 0.8842 - lr: 0.0010\n",
            "Epoch 11/2000\n",
            "383/383 [==============================] - 9s 22ms/step - loss: 0.3701 - accuracy: 0.8939 - val_loss: 0.3985 - val_accuracy: 0.8855 - lr: 0.0010\n",
            "Epoch 12/2000\n",
            "383/383 [==============================] - 8s 22ms/step - loss: 0.3627 - accuracy: 0.8973 - val_loss: 0.3947 - val_accuracy: 0.8918 - lr: 0.0010\n",
            "Epoch 13/2000\n",
            "383/383 [==============================] - 8s 22ms/step - loss: 0.3653 - accuracy: 0.8970 - val_loss: 0.3938 - val_accuracy: 0.8947 - lr: 0.0010\n",
            "Epoch 14/2000\n",
            "383/383 [==============================] - 8s 22ms/step - loss: 0.3608 - accuracy: 0.8997 - val_loss: 0.3835 - val_accuracy: 0.8950 - lr: 0.0010\n",
            "Epoch 15/2000\n",
            "383/383 [==============================] - 9s 22ms/step - loss: 0.3526 - accuracy: 0.9000 - val_loss: 0.3860 - val_accuracy: 0.8948 - lr: 0.0010\n",
            "Epoch 16/2000\n",
            "383/383 [==============================] - 8s 22ms/step - loss: 0.3496 - accuracy: 0.9009 - val_loss: 0.3807 - val_accuracy: 0.8952 - lr: 0.0010\n",
            "Epoch 17/2000\n",
            "383/383 [==============================] - 8s 22ms/step - loss: 0.3529 - accuracy: 0.9012 - val_loss: 0.3981 - val_accuracy: 0.8886 - lr: 0.0010\n",
            "Epoch 18/2000\n",
            "383/383 [==============================] - 9s 22ms/step - loss: 0.3449 - accuracy: 0.9078 - val_loss: 0.3850 - val_accuracy: 0.8953 - lr: 0.0010\n",
            "Epoch 19/2000\n",
            "383/383 [==============================] - 8s 22ms/step - loss: 0.3430 - accuracy: 0.9043 - val_loss: 0.3792 - val_accuracy: 0.8948 - lr: 0.0010\n",
            "Epoch 20/2000\n",
            "383/383 [==============================] - 8s 22ms/step - loss: 0.3450 - accuracy: 0.9030 - val_loss: 0.3787 - val_accuracy: 0.8948 - lr: 0.0010\n",
            "Epoch 21/2000\n",
            "383/383 [==============================] - 8s 22ms/step - loss: 0.3436 - accuracy: 0.9068 - val_loss: 0.3836 - val_accuracy: 0.8944 - lr: 0.0010\n",
            "Epoch 22/2000\n",
            "383/383 [==============================] - 8s 22ms/step - loss: 0.3365 - accuracy: 0.9071 - val_loss: 0.3825 - val_accuracy: 0.8968 - lr: 0.0010\n",
            "Epoch 23/2000\n",
            "383/383 [==============================] - 9s 22ms/step - loss: 0.3374 - accuracy: 0.9071 - val_loss: 0.3714 - val_accuracy: 0.9006 - lr: 0.0010\n",
            "Epoch 24/2000\n",
            "383/383 [==============================] - 8s 22ms/step - loss: 0.3348 - accuracy: 0.9105 - val_loss: 0.3761 - val_accuracy: 0.8949 - lr: 0.0010\n",
            "Epoch 25/2000\n",
            "383/383 [==============================] - 9s 22ms/step - loss: 0.3318 - accuracy: 0.9110 - val_loss: 0.3853 - val_accuracy: 0.8931 - lr: 0.0010\n",
            "Epoch 26/2000\n",
            "383/383 [==============================] - 8s 22ms/step - loss: 0.3277 - accuracy: 0.9119 - val_loss: 0.3735 - val_accuracy: 0.9005 - lr: 0.0010\n",
            "Epoch 27/2000\n",
            "383/383 [==============================] - 9s 22ms/step - loss: 0.3236 - accuracy: 0.9142 - val_loss: 0.3713 - val_accuracy: 0.8975 - lr: 9.0000e-04\n",
            "Epoch 28/2000\n",
            "383/383 [==============================] - 8s 22ms/step - loss: 0.3224 - accuracy: 0.9166 - val_loss: 0.3684 - val_accuracy: 0.9025 - lr: 9.0000e-04\n",
            "Epoch 29/2000\n",
            "383/383 [==============================] - 8s 22ms/step - loss: 0.3173 - accuracy: 0.9177 - val_loss: 0.3647 - val_accuracy: 0.9006 - lr: 9.0000e-04\n",
            "Epoch 30/2000\n",
            "383/383 [==============================] - 8s 22ms/step - loss: 0.3179 - accuracy: 0.9166 - val_loss: 0.3628 - val_accuracy: 0.9070 - lr: 9.0000e-04\n",
            "Epoch 31/2000\n",
            "383/383 [==============================] - 9s 22ms/step - loss: 0.3174 - accuracy: 0.9167 - val_loss: 0.3732 - val_accuracy: 0.8966 - lr: 9.0000e-04\n",
            "Epoch 32/2000\n",
            "383/383 [==============================] - 8s 22ms/step - loss: 0.3185 - accuracy: 0.9176 - val_loss: 0.3639 - val_accuracy: 0.9030 - lr: 9.0000e-04\n",
            "Epoch 33/2000\n",
            "383/383 [==============================] - 9s 22ms/step - loss: 0.3180 - accuracy: 0.9174 - val_loss: 0.3723 - val_accuracy: 0.9015 - lr: 9.0000e-04\n",
            "Epoch 34/2000\n",
            "383/383 [==============================] - 9s 22ms/step - loss: 0.3085 - accuracy: 0.9208 - val_loss: 0.3679 - val_accuracy: 0.9025 - lr: 8.1000e-04\n",
            "Epoch 35/2000\n",
            "383/383 [==============================] - 8s 22ms/step - loss: 0.3061 - accuracy: 0.9216 - val_loss: 0.3567 - val_accuracy: 0.9054 - lr: 8.1000e-04\n",
            "Epoch 36/2000\n",
            "383/383 [==============================] - 8s 22ms/step - loss: 0.3057 - accuracy: 0.9231 - val_loss: 0.3757 - val_accuracy: 0.8921 - lr: 8.1000e-04\n",
            "Epoch 37/2000\n",
            "383/383 [==============================] - 8s 22ms/step - loss: 0.3065 - accuracy: 0.9203 - val_loss: 0.3582 - val_accuracy: 0.9016 - lr: 8.1000e-04\n",
            "Epoch 38/2000\n",
            "383/383 [==============================] - 8s 22ms/step - loss: 0.3025 - accuracy: 0.9251 - val_loss: 0.3630 - val_accuracy: 0.8982 - lr: 8.1000e-04\n",
            "Epoch 39/2000\n",
            "383/383 [==============================] - 8s 22ms/step - loss: 0.2984 - accuracy: 0.9264 - val_loss: 0.3641 - val_accuracy: 0.9018 - lr: 7.2900e-04\n",
            "Epoch 40/2000\n",
            "383/383 [==============================] - 9s 22ms/step - loss: 0.2970 - accuracy: 0.9267 - val_loss: 0.3661 - val_accuracy: 0.9024 - lr: 7.2900e-04\n",
            "Epoch 41/2000\n",
            "383/383 [==============================] - 9s 22ms/step - loss: 0.2973 - accuracy: 0.9270 - val_loss: 0.3584 - val_accuracy: 0.9034 - lr: 7.2900e-04\n",
            "Epoch 42/2000\n",
            "383/383 [==============================] - 9s 22ms/step - loss: 0.2915 - accuracy: 0.9277 - val_loss: 0.3537 - val_accuracy: 0.9057 - lr: 6.5610e-04\n",
            "Epoch 43/2000\n",
            "383/383 [==============================] - 8s 22ms/step - loss: 0.2928 - accuracy: 0.9283 - val_loss: 0.3597 - val_accuracy: 0.9045 - lr: 6.5610e-04\n",
            "Epoch 44/2000\n",
            "383/383 [==============================] - 8s 22ms/step - loss: 0.2941 - accuracy: 0.9253 - val_loss: 0.3561 - val_accuracy: 0.9050 - lr: 6.5610e-04\n",
            "Epoch 45/2000\n",
            "383/383 [==============================] - 8s 22ms/step - loss: 0.2864 - accuracy: 0.9314 - val_loss: 0.3492 - val_accuracy: 0.9111 - lr: 6.5610e-04\n",
            "Epoch 46/2000\n",
            "383/383 [==============================] - 8s 22ms/step - loss: 0.2869 - accuracy: 0.9307 - val_loss: 0.3576 - val_accuracy: 0.9030 - lr: 6.5610e-04\n",
            "Epoch 47/2000\n",
            "383/383 [==============================] - 8s 22ms/step - loss: 0.2835 - accuracy: 0.9328 - val_loss: 0.3559 - val_accuracy: 0.9061 - lr: 6.5610e-04\n",
            "Epoch 48/2000\n",
            "383/383 [==============================] - 8s 22ms/step - loss: 0.2840 - accuracy: 0.9343 - val_loss: 0.3600 - val_accuracy: 0.9027 - lr: 6.5610e-04\n",
            "Epoch 49/2000\n",
            "383/383 [==============================] - 8s 22ms/step - loss: 0.2822 - accuracy: 0.9322 - val_loss: 0.3547 - val_accuracy: 0.9090 - lr: 5.9049e-04\n",
            "Epoch 50/2000\n",
            "383/383 [==============================] - 8s 22ms/step - loss: 0.2807 - accuracy: 0.9342 - val_loss: 0.3527 - val_accuracy: 0.9110 - lr: 5.9049e-04\n",
            "Epoch 51/2000\n",
            "383/383 [==============================] - 8s 22ms/step - loss: 0.2779 - accuracy: 0.9358 - val_loss: 0.3526 - val_accuracy: 0.9046 - lr: 5.9049e-04\n",
            "Epoch 52/2000\n",
            "383/383 [==============================] - 8s 22ms/step - loss: 0.2724 - accuracy: 0.9381 - val_loss: 0.3560 - val_accuracy: 0.9083 - lr: 5.3144e-04\n",
            "Epoch 53/2000\n",
            "383/383 [==============================] - 8s 22ms/step - loss: 0.2728 - accuracy: 0.9373 - val_loss: 0.3504 - val_accuracy: 0.9102 - lr: 5.3144e-04\n",
            "Epoch 54/2000\n",
            "383/383 [==============================] - 8s 22ms/step - loss: 0.2722 - accuracy: 0.9384 - val_loss: 0.3550 - val_accuracy: 0.9091 - lr: 5.3144e-04\n",
            "Epoch 55/2000\n",
            "383/383 [==============================] - 8s 22ms/step - loss: 0.2686 - accuracy: 0.9393 - val_loss: 0.3494 - val_accuracy: 0.9108 - lr: 4.7830e-04\n",
            "Epoch 56/2000\n",
            "383/383 [==============================] - 8s 22ms/step - loss: 0.2681 - accuracy: 0.9406 - val_loss: 0.3513 - val_accuracy: 0.9117 - lr: 4.7830e-04\n",
            "Epoch 57/2000\n",
            "383/383 [==============================] - 8s 22ms/step - loss: 0.2668 - accuracy: 0.9408 - val_loss: 0.3471 - val_accuracy: 0.9123 - lr: 4.7830e-04\n",
            "Epoch 58/2000\n",
            "383/383 [==============================] - 8s 22ms/step - loss: 0.2694 - accuracy: 0.9395 - val_loss: 0.3430 - val_accuracy: 0.9123 - lr: 4.7830e-04\n",
            "Epoch 59/2000\n",
            "383/383 [==============================] - 9s 22ms/step - loss: 0.2662 - accuracy: 0.9422 - val_loss: 0.3446 - val_accuracy: 0.9123 - lr: 4.7830e-04\n",
            "Epoch 60/2000\n",
            "383/383 [==============================] - 8s 22ms/step - loss: 0.2638 - accuracy: 0.9431 - val_loss: 0.3477 - val_accuracy: 0.9109 - lr: 4.7830e-04\n",
            "Epoch 61/2000\n",
            "383/383 [==============================] - 8s 22ms/step - loss: 0.2653 - accuracy: 0.9405 - val_loss: 0.3530 - val_accuracy: 0.9077 - lr: 4.7830e-04\n",
            "Epoch 62/2000\n",
            "383/383 [==============================] - 9s 22ms/step - loss: 0.2607 - accuracy: 0.9454 - val_loss: 0.3455 - val_accuracy: 0.9120 - lr: 4.3047e-04\n",
            "Epoch 63/2000\n",
            "383/383 [==============================] - 8s 22ms/step - loss: 0.2634 - accuracy: 0.9422 - val_loss: 0.3496 - val_accuracy: 0.9156 - lr: 4.3047e-04\n",
            "Epoch 64/2000\n",
            "383/383 [==============================] - 8s 22ms/step - loss: 0.2589 - accuracy: 0.9447 - val_loss: 0.3451 - val_accuracy: 0.9149 - lr: 4.3047e-04\n",
            "Epoch 65/2000\n",
            "383/383 [==============================] - 9s 22ms/step - loss: 0.2549 - accuracy: 0.9467 - val_loss: 0.3482 - val_accuracy: 0.9074 - lr: 3.8742e-04\n",
            "Epoch 66/2000\n",
            "383/383 [==============================] - 8s 22ms/step - loss: 0.2587 - accuracy: 0.9454 - val_loss: 0.3473 - val_accuracy: 0.9122 - lr: 3.8742e-04\n",
            "Epoch 67/2000\n",
            "383/383 [==============================] - 8s 22ms/step - loss: 0.2576 - accuracy: 0.9480 - val_loss: 0.3488 - val_accuracy: 0.9090 - lr: 3.8742e-04\n",
            "Epoch 68/2000\n",
            "383/383 [==============================] - 8s 22ms/step - loss: 0.2535 - accuracy: 0.9492 - val_loss: 0.3532 - val_accuracy: 0.9096 - lr: 3.4868e-04\n",
            "Epoch 69/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.2528 - accuracy: 0.9501 - val_loss: 0.3486 - val_accuracy: 0.9143 - lr: 3.4868e-04\n",
            "Epoch 70/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.2520 - accuracy: 0.9494 - val_loss: 0.3433 - val_accuracy: 0.9137 - lr: 3.4868e-04\n",
            "Epoch 71/2000\n",
            "383/383 [==============================] - 9s 22ms/step - loss: 0.2491 - accuracy: 0.9513 - val_loss: 0.3478 - val_accuracy: 0.9143 - lr: 3.1381e-04\n",
            "Epoch 72/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.2512 - accuracy: 0.9498 - val_loss: 0.3461 - val_accuracy: 0.9124 - lr: 3.1381e-04\n",
            "Epoch 73/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.2486 - accuracy: 0.9504 - val_loss: 0.3430 - val_accuracy: 0.9142 - lr: 3.1381e-04\n",
            "Epoch 74/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.2491 - accuracy: 0.9487 - val_loss: 0.3459 - val_accuracy: 0.9108 - lr: 2.8243e-04\n",
            "Epoch 75/2000\n",
            "383/383 [==============================] - 9s 22ms/step - loss: 0.2463 - accuracy: 0.9520 - val_loss: 0.3439 - val_accuracy: 0.9102 - lr: 2.8243e-04\n",
            "Epoch 76/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.2453 - accuracy: 0.9523 - val_loss: 0.3443 - val_accuracy: 0.9104 - lr: 2.8243e-04\n",
            "Epoch 77/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.2464 - accuracy: 0.9540 - val_loss: 0.3438 - val_accuracy: 0.9117 - lr: 2.5419e-04\n",
            "Epoch 78/2000\n",
            "383/383 [==============================] - 9s 22ms/step - loss: 0.2436 - accuracy: 0.9526 - val_loss: 0.3441 - val_accuracy: 0.9128 - lr: 2.5419e-04\n",
            "Epoch 79/2000\n",
            "383/383 [==============================] - 9s 22ms/step - loss: 0.2439 - accuracy: 0.9533 - val_loss: 0.3435 - val_accuracy: 0.9122 - lr: 2.5419e-04\n",
            "Epoch 80/2000\n",
            "383/383 [==============================] - 9s 22ms/step - loss: 0.2422 - accuracy: 0.9549 - val_loss: 0.3429 - val_accuracy: 0.9123 - lr: 2.2877e-04\n",
            "Epoch 81/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.2418 - accuracy: 0.9532 - val_loss: 0.3457 - val_accuracy: 0.9135 - lr: 2.2877e-04\n",
            "Epoch 82/2000\n",
            "383/383 [==============================] - 9s 22ms/step - loss: 0.2410 - accuracy: 0.9538 - val_loss: 0.3478 - val_accuracy: 0.9134 - lr: 2.2877e-04\n",
            "Epoch 83/2000\n",
            "383/383 [==============================] - 9s 22ms/step - loss: 0.2392 - accuracy: 0.9551 - val_loss: 0.3490 - val_accuracy: 0.9159 - lr: 2.0589e-04\n",
            "Epoch 84/2000\n",
            "383/383 [==============================] - 9s 22ms/step - loss: 0.2401 - accuracy: 0.9539 - val_loss: 0.3439 - val_accuracy: 0.9101 - lr: 2.0589e-04\n",
            "Epoch 85/2000\n",
            "383/383 [==============================] - 9s 22ms/step - loss: 0.2385 - accuracy: 0.9580 - val_loss: 0.3457 - val_accuracy: 0.9138 - lr: 2.0589e-04\n",
            "Epoch 86/2000\n",
            "383/383 [==============================] - 9s 22ms/step - loss: 0.2386 - accuracy: 0.9564 - val_loss: 0.3429 - val_accuracy: 0.9130 - lr: 1.8530e-04\n",
            "Epoch 87/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.2368 - accuracy: 0.9586 - val_loss: 0.3438 - val_accuracy: 0.9146 - lr: 1.8530e-04\n",
            "Epoch 88/2000\n",
            "383/383 [==============================] - 9s 22ms/step - loss: 0.2368 - accuracy: 0.9549 - val_loss: 0.3412 - val_accuracy: 0.9137 - lr: 1.8530e-04\n",
            "Epoch 89/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.2349 - accuracy: 0.9589 - val_loss: 0.3427 - val_accuracy: 0.9163 - lr: 1.8530e-04\n",
            "Epoch 90/2000\n",
            "383/383 [==============================] - 9s 22ms/step - loss: 0.2363 - accuracy: 0.9584 - val_loss: 0.3417 - val_accuracy: 0.9127 - lr: 1.8530e-04\n",
            "Epoch 91/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.2353 - accuracy: 0.9570 - val_loss: 0.3439 - val_accuracy: 0.9148 - lr: 1.8530e-04\n",
            "Epoch 92/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.2350 - accuracy: 0.9575 - val_loss: 0.3440 - val_accuracy: 0.9150 - lr: 1.6677e-04\n",
            "Epoch 93/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.2363 - accuracy: 0.9574 - val_loss: 0.3424 - val_accuracy: 0.9149 - lr: 1.6677e-04\n",
            "Epoch 94/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.2351 - accuracy: 0.9581 - val_loss: 0.3424 - val_accuracy: 0.9127 - lr: 1.6677e-04\n",
            "Epoch 95/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.2348 - accuracy: 0.9582 - val_loss: 0.3410 - val_accuracy: 0.9143 - lr: 1.5009e-04\n",
            "Epoch 96/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.2343 - accuracy: 0.9610 - val_loss: 0.3439 - val_accuracy: 0.9110 - lr: 1.5009e-04\n",
            "Epoch 97/2000\n",
            "383/383 [==============================] - 9s 22ms/step - loss: 0.2340 - accuracy: 0.9590 - val_loss: 0.3361 - val_accuracy: 0.9134 - lr: 1.5009e-04\n",
            "Epoch 98/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.2320 - accuracy: 0.9596 - val_loss: 0.3372 - val_accuracy: 0.9151 - lr: 1.5009e-04\n",
            "Epoch 99/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.2338 - accuracy: 0.9593 - val_loss: 0.3458 - val_accuracy: 0.9110 - lr: 1.5009e-04\n",
            "Epoch 100/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.2326 - accuracy: 0.9576 - val_loss: 0.3446 - val_accuracy: 0.9113 - lr: 1.5009e-04\n",
            "Epoch 101/2000\n",
            "383/383 [==============================] - 9s 22ms/step - loss: 0.2331 - accuracy: 0.9591 - val_loss: 0.3407 - val_accuracy: 0.9126 - lr: 1.3509e-04\n",
            "Epoch 102/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.2302 - accuracy: 0.9609 - val_loss: 0.3391 - val_accuracy: 0.9139 - lr: 1.3509e-04\n",
            "Epoch 103/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.2315 - accuracy: 0.9602 - val_loss: 0.3406 - val_accuracy: 0.9135 - lr: 1.3509e-04\n",
            "Epoch 104/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.2302 - accuracy: 0.9590 - val_loss: 0.3396 - val_accuracy: 0.9132 - lr: 1.2158e-04\n",
            "Epoch 105/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.2301 - accuracy: 0.9604 - val_loss: 0.3440 - val_accuracy: 0.9156 - lr: 1.2158e-04\n",
            "Epoch 106/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.2308 - accuracy: 0.9605 - val_loss: 0.3438 - val_accuracy: 0.9147 - lr: 1.2158e-04\n",
            "Epoch 107/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.2297 - accuracy: 0.9608 - val_loss: 0.3496 - val_accuracy: 0.9087 - lr: 1.0942e-04\n",
            "Epoch 108/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.2296 - accuracy: 0.9606 - val_loss: 0.3408 - val_accuracy: 0.9112 - lr: 1.0942e-04\n",
            "Epoch 109/2000\n",
            "383/383 [==============================] - 9s 22ms/step - loss: 0.2292 - accuracy: 0.9612 - val_loss: 0.3415 - val_accuracy: 0.9144 - lr: 1.0942e-04\n",
            "Epoch 110/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.2290 - accuracy: 0.9632 - val_loss: 0.3402 - val_accuracy: 0.9151 - lr: 9.8477e-05\n",
            "Epoch 111/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.2278 - accuracy: 0.9604 - val_loss: 0.3442 - val_accuracy: 0.9129 - lr: 9.8477e-05\n",
            "Epoch 112/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.2283 - accuracy: 0.9624 - val_loss: 0.3430 - val_accuracy: 0.9135 - lr: 9.8477e-05\n",
            "Epoch 113/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.2281 - accuracy: 0.9607 - val_loss: 0.3400 - val_accuracy: 0.9165 - lr: 8.8629e-05\n",
            "Epoch 114/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.2277 - accuracy: 0.9640 - val_loss: 0.3437 - val_accuracy: 0.9140 - lr: 8.8629e-05\n",
            "Epoch 115/2000\n",
            "383/383 [==============================] - 9s 22ms/step - loss: 0.2265 - accuracy: 0.9637 - val_loss: 0.3444 - val_accuracy: 0.9110 - lr: 8.8629e-05\n",
            "Epoch 116/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.2267 - accuracy: 0.9624 - val_loss: 0.3384 - val_accuracy: 0.9135 - lr: 7.9766e-05\n",
            "Epoch 117/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.2276 - accuracy: 0.9629 - val_loss: 0.3436 - val_accuracy: 0.9116 - lr: 7.9766e-05\n",
            "Epoch 118/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.2270 - accuracy: 0.9619 - val_loss: 0.3369 - val_accuracy: 0.9158 - lr: 7.9766e-05\n",
            "Epoch 119/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.2268 - accuracy: 0.9632 - val_loss: 0.3394 - val_accuracy: 0.9135 - lr: 7.1790e-05\n",
            "Epoch 120/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.2264 - accuracy: 0.9629 - val_loss: 0.3438 - val_accuracy: 0.9114 - lr: 7.1790e-05\n",
            "Epoch 121/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.2266 - accuracy: 0.9636 - val_loss: 0.3396 - val_accuracy: 0.9174 - lr: 7.1790e-05\n",
            "Epoch 122/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.2260 - accuracy: 0.9629 - val_loss: 0.3399 - val_accuracy: 0.9156 - lr: 6.4611e-05\n",
            "Epoch 123/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.2256 - accuracy: 0.9633 - val_loss: 0.3371 - val_accuracy: 0.9169 - lr: 6.4611e-05\n",
            "Epoch 124/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.2258 - accuracy: 0.9610 - val_loss: 0.3428 - val_accuracy: 0.9143 - lr: 6.4611e-05\n",
            "Epoch 125/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.2243 - accuracy: 0.9633 - val_loss: 0.3448 - val_accuracy: 0.9139 - lr: 5.8150e-05\n",
            "Epoch 126/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.2249 - accuracy: 0.9632 - val_loss: 0.3413 - val_accuracy: 0.9161 - lr: 5.8150e-05\n",
            "Epoch 127/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.2246 - accuracy: 0.9625 - val_loss: 0.3368 - val_accuracy: 0.9155 - lr: 5.8150e-05\n",
            "Epoch 128/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.2252 - accuracy: 0.9613 - val_loss: 0.3354 - val_accuracy: 0.9172 - lr: 5.2335e-05\n",
            "Epoch 129/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.2236 - accuracy: 0.9647 - val_loss: 0.3413 - val_accuracy: 0.9166 - lr: 5.2335e-05\n",
            "Epoch 130/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.2234 - accuracy: 0.9642 - val_loss: 0.3456 - val_accuracy: 0.9121 - lr: 5.2335e-05\n",
            "Epoch 131/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.2247 - accuracy: 0.9632 - val_loss: 0.3382 - val_accuracy: 0.9167 - lr: 5.2335e-05\n",
            "Epoch 132/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.2236 - accuracy: 0.9656 - val_loss: 0.3383 - val_accuracy: 0.9174 - lr: 4.7101e-05\n",
            "Epoch 133/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.2232 - accuracy: 0.9637 - val_loss: 0.3412 - val_accuracy: 0.9131 - lr: 4.7101e-05\n",
            "Epoch 134/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.2238 - accuracy: 0.9641 - val_loss: 0.3423 - val_accuracy: 0.9133 - lr: 4.7101e-05\n",
            "Epoch 135/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.2228 - accuracy: 0.9632 - val_loss: 0.3386 - val_accuracy: 0.9137 - lr: 4.2391e-05\n",
            "Epoch 136/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.2230 - accuracy: 0.9640 - val_loss: 0.3421 - val_accuracy: 0.9137 - lr: 4.2391e-05\n",
            "Epoch 137/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.2229 - accuracy: 0.9641 - val_loss: 0.3418 - val_accuracy: 0.9173 - lr: 4.2391e-05\n",
            "Epoch 138/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.2238 - accuracy: 0.9642 - val_loss: 0.3372 - val_accuracy: 0.9161 - lr: 3.8152e-05\n",
            "Epoch 139/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.2224 - accuracy: 0.9642 - val_loss: 0.3418 - val_accuracy: 0.9144 - lr: 3.8152e-05\n",
            "Epoch 140/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.2231 - accuracy: 0.9646 - val_loss: 0.3398 - val_accuracy: 0.9150 - lr: 3.8152e-05\n",
            "Epoch 141/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.2219 - accuracy: 0.9632 - val_loss: 0.3429 - val_accuracy: 0.9128 - lr: 3.4337e-05\n",
            "Epoch 142/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.2229 - accuracy: 0.9641 - val_loss: 0.3380 - val_accuracy: 0.9160 - lr: 3.4337e-05\n",
            "Epoch 143/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.2216 - accuracy: 0.9637 - val_loss: 0.3415 - val_accuracy: 0.9184 - lr: 3.4337e-05\n",
            "Epoch 144/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.2236 - accuracy: 0.9657 - val_loss: 0.3391 - val_accuracy: 0.9150 - lr: 3.0903e-05\n",
            "Epoch 145/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.2235 - accuracy: 0.9645 - val_loss: 0.3391 - val_accuracy: 0.9106 - lr: 3.0903e-05\n",
            "Epoch 146/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.2237 - accuracy: 0.9645 - val_loss: 0.3408 - val_accuracy: 0.9132 - lr: 3.0903e-05\n",
            "Epoch 147/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.2220 - accuracy: 0.9649 - val_loss: 0.3399 - val_accuracy: 0.9131 - lr: 2.7813e-05\n",
            "Epoch 148/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.2229 - accuracy: 0.9642 - val_loss: 0.3365 - val_accuracy: 0.9173 - lr: 2.7813e-05\n",
            "Epoch 149/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.2218 - accuracy: 0.9650 - val_loss: 0.3400 - val_accuracy: 0.9153 - lr: 2.7813e-05\n",
            "Epoch 150/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.2220 - accuracy: 0.9652 - val_loss: 0.3357 - val_accuracy: 0.9183 - lr: 2.5032e-05\n",
            "Epoch 151/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.2232 - accuracy: 0.9642 - val_loss: 0.3405 - val_accuracy: 0.9150 - lr: 2.5032e-05\n",
            "Epoch 152/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.2229 - accuracy: 0.9644 - val_loss: 0.3431 - val_accuracy: 0.9128 - lr: 2.5032e-05\n",
            "Epoch 153/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.2211 - accuracy: 0.9661 - val_loss: 0.3446 - val_accuracy: 0.9144 - lr: 2.2528e-05\n",
            "Epoch 154/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.2210 - accuracy: 0.9644 - val_loss: 0.3404 - val_accuracy: 0.9116 - lr: 2.2528e-05\n",
            "Epoch 155/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.2212 - accuracy: 0.9658 - val_loss: 0.3370 - val_accuracy: 0.9156 - lr: 2.2528e-05\n",
            "Epoch 156/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.2215 - accuracy: 0.9657 - val_loss: 0.3408 - val_accuracy: 0.9153 - lr: 2.0276e-05\n",
            "Epoch 157/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.2209 - accuracy: 0.9665 - val_loss: 0.3432 - val_accuracy: 0.9146 - lr: 2.0276e-05\n",
            "Epoch 158/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.2215 - accuracy: 0.9649 - val_loss: 0.3419 - val_accuracy: 0.9123 - lr: 2.0276e-05\n",
            "Epoch 159/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.2217 - accuracy: 0.9648 - val_loss: 0.3424 - val_accuracy: 0.9127 - lr: 1.8248e-05\n",
            "Epoch 160/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.2211 - accuracy: 0.9644 - val_loss: 0.3358 - val_accuracy: 0.9130 - lr: 1.8248e-05\n",
            "Epoch 161/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.2212 - accuracy: 0.9657 - val_loss: 0.3396 - val_accuracy: 0.9146 - lr: 1.8248e-05\n",
            "Epoch 162/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.2206 - accuracy: 0.9650 - val_loss: 0.3366 - val_accuracy: 0.9151 - lr: 1.6423e-05\n",
            "Epoch 163/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.2206 - accuracy: 0.9659 - val_loss: 0.3407 - val_accuracy: 0.9147 - lr: 1.6423e-05\n",
            "Epoch 164/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.2208 - accuracy: 0.9643 - val_loss: 0.3415 - val_accuracy: 0.9146 - lr: 1.6423e-05\n",
            "Epoch 165/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.2209 - accuracy: 0.9634 - val_loss: 0.3453 - val_accuracy: 0.9154 - lr: 1.4781e-05\n",
            "Epoch 166/2000\n",
            "383/383 [==============================] - 9s 22ms/step - loss: 0.2216 - accuracy: 0.9654 - val_loss: 0.3393 - val_accuracy: 0.9150 - lr: 1.4781e-05\n",
            "Epoch 167/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.2209 - accuracy: 0.9639 - val_loss: 0.3415 - val_accuracy: 0.9140 - lr: 1.4781e-05\n",
            "Epoch 168/2000\n",
            "383/383 [==============================] - 9s 22ms/step - loss: 0.2216 - accuracy: 0.9657 - val_loss: 0.3386 - val_accuracy: 0.9156 - lr: 1.3303e-05\n",
            "Epoch 169/2000\n",
            "383/383 [==============================] - 9s 22ms/step - loss: 0.2210 - accuracy: 0.9650 - val_loss: 0.3390 - val_accuracy: 0.9150 - lr: 1.3303e-05\n",
            "Epoch 170/2000\n",
            "383/383 [==============================] - 9s 22ms/step - loss: 0.2211 - accuracy: 0.9644 - val_loss: 0.3391 - val_accuracy: 0.9121 - lr: 1.3303e-05\n",
            "Epoch 171/2000\n",
            "383/383 [==============================] - 9s 22ms/step - loss: 0.2209 - accuracy: 0.9650 - val_loss: 0.3390 - val_accuracy: 0.9158 - lr: 1.1973e-05\n",
            "Epoch 172/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.2217 - accuracy: 0.9659 - val_loss: 0.3429 - val_accuracy: 0.9132 - lr: 1.1973e-05\n",
            "Epoch 173/2000\n",
            "383/383 [==============================] - 9s 22ms/step - loss: 0.2202 - accuracy: 0.9673 - val_loss: 0.3384 - val_accuracy: 0.9168 - lr: 1.1973e-05\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fe9db863210>"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ],
      "source": [
        "#######HYPERPARAMATERS###########\n",
        "epochs = 2000\n",
        "batch_size = 64\n",
        "learning_rate = 0.001\n",
        "#################################\n",
        "\n",
        "model = Sequential()\n",
        "    \n",
        "model.add(Conv2D(32, kernel_size = (3,3), input_shape=(28,28,1), activation='relu'))\n",
        "\n",
        "model.add(Conv2D(64,(3,3), activation='relu'))\n",
        "model.add(Conv2D(64,(3,3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=2))\n",
        "model.add(PermaDropout(0.5))\n",
        "\n",
        "model.add(Conv2D(128,(3,3), activation='relu'))\n",
        "model.add(Conv2D(128,(3,3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=2))\n",
        "model.add(PermaDropout(0.5))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(PermaDropout(0.5))\n",
        "\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "adam = keras.optimizers.Adam(learning_rate)\n",
        "model.compile(optimizer = adam, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
        "    \n",
        "# print(model.summary())\n",
        "\n",
        "lr_reducer = ReduceLROnPlateau(monitor='val_loss', factor=0.9, patience=3)\n",
        "early_stopper = EarlyStopping(monitor='val_accuracy', min_delta=0, patience=30, mode='auto')\n",
        "checkpointer = ModelCheckpoint('weights.hd5', monitor='val_loss', verbose=1, save_best_only=True)\n",
        "\n",
        "model.fit(\n",
        "          train_data_2,\n",
        "          train_labels_2,\n",
        "          epochs = epochs,\n",
        "          batch_size = batch_size,\n",
        "          validation_split = 0.3,\n",
        "          shuffle = True,\n",
        "          callbacks=[lr_reducer, early_stopper]\n",
        "          )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4d3W-766kt4H"
      },
      "outputs": [],
      "source": [
        "model.save('/content/drive/MyDrive/파이썬스터디 프로젝트/labeling_cnn_no.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "it79cIfekt4H",
        "outputId": "2138cf8f-b745-4b08-ddb4-a51855ac5c28"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8966"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ],
      "source": [
        "model = keras.models.load_model('/content/drive/MyDrive/파이썬스터디 프로젝트/labeling_cnn_no.h5')\n",
        "model_eval()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 남은 데이터 라벨링하기\n"
      ],
      "metadata": {
        "id": "L5kdx4FDw7ED"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model1 = keras.models.load_model('/content/drive/MyDrive/파이썬스터디 프로젝트/labeling_cnn2.h5')\n",
        "model2 = keras.models.load_model('/content/drive/MyDrive/파이썬스터디 프로젝트/labeling_cnn_no.h5')"
      ],
      "metadata": {
        "id": "s8F_ifi6w9Uq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unlab_label_1 = model1.predict(unlab_data_1)"
      ],
      "metadata": {
        "id": "74E6i_eCxCNG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unlab_label_2 = model2.predict(unlab_data_2)"
      ],
      "metadata": {
        "id": "_tz_MEzhxXos"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_1 = np.concatenate([train_data_1, unlab_data_1], axis=0)\n",
        "train_labels_1 = np.concatenate([train_labels_1, unlab_label_1], axis=0)"
      ],
      "metadata": {
        "id": "tiz6rZkT5ORw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_2 = np.concatenate([train_data_2, unlab_data[lowvars]], axis=0)\n",
        "train_labels_2 = np.concatenate([train_labels_2, Outs[lowvars]], axis=0)"
      ],
      "metadata": {
        "id": "vIe8iZLkD8pJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#######HYPERPARAMATERS###########\n",
        "epochs = 2000\n",
        "batch_size = 64\n",
        "learning_rate = 0.001\n",
        "#################################\n",
        "  \n",
        "model = Sequential()\n",
        "    \n",
        "model.add(Conv2D(32, kernel_size = (3,3), input_shape=(28,28,1), activation='relu'))\n",
        "\n",
        "model.add(Conv2D(64,(3,3), activation='relu'))\n",
        "model.add(Conv2D(64,(3,3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=2))\n",
        "model.add(PermaDropout(0.5))\n",
        "\n",
        "model.add(Conv2D(128,(3,3), activation='relu'))\n",
        "model.add(Conv2D(128,(3,3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=2))\n",
        "model.add(PermaDropout(0.5))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(PermaDropout(0.5))\n",
        "\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(PermaDropout(0.5))\n",
        "\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "adam = keras.optimizers.Adam(learning_rate)\n",
        "model.compile(optimizer = adam, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
        "    \n",
        "# print(model.summary())\n",
        "\n",
        "lr_reducer = ReduceLROnPlateau(monitor='val_loss', factor=0.9, patience=3)\n",
        "early_stopper = EarlyStopping(monitor='val_accuracy', min_delta=0, patience=30, mode='auto')\n",
        "checkpointer = ModelCheckpoint('weights.hd5', monitor='val_loss', verbose=1, save_best_only=True)\n",
        "\n",
        "\n",
        "model.fit(\n",
        "          train_data_1,\n",
        "          train_labels_1,\n",
        "          epochs = epochs,\n",
        "          batch_size = batch_size,\n",
        "          validation_split = 0.3,\n",
        "          shuffle = True,\n",
        "          callbacks=[lr_reducer, early_stopper]\n",
        "          )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ru605cBREQ_8",
        "outputId": "43fc374f-0d99-4758-e68b-5fcfdcca7011"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2000\n",
            "657/657 [==============================] - 16s 23ms/step - loss: 0.9943 - accuracy: 0.6618 - val_loss: 0.9468 - val_accuracy: 0.6839 - lr: 0.0010\n",
            "Epoch 2/2000\n",
            "657/657 [==============================] - 18s 27ms/step - loss: 0.4825 - accuracy: 0.8375 - val_loss: 0.7981 - val_accuracy: 0.7357 - lr: 0.0010\n",
            "Epoch 3/2000\n",
            "657/657 [==============================] - 15s 22ms/step - loss: 0.4059 - accuracy: 0.8680 - val_loss: 0.7622 - val_accuracy: 0.7401 - lr: 0.0010\n",
            "Epoch 4/2000\n",
            "657/657 [==============================] - 15s 22ms/step - loss: 0.3596 - accuracy: 0.8887 - val_loss: 0.7200 - val_accuracy: 0.7722 - lr: 0.0010\n",
            "Epoch 5/2000\n",
            "657/657 [==============================] - 15s 22ms/step - loss: 0.3328 - accuracy: 0.9004 - val_loss: 0.7096 - val_accuracy: 0.7649 - lr: 0.0010\n",
            "Epoch 6/2000\n",
            "657/657 [==============================] - 15s 22ms/step - loss: 0.3105 - accuracy: 0.9095 - val_loss: 0.6970 - val_accuracy: 0.7839 - lr: 0.0010\n",
            "Epoch 7/2000\n",
            "657/657 [==============================] - 15s 22ms/step - loss: 0.2891 - accuracy: 0.9161 - val_loss: 0.6627 - val_accuracy: 0.7896 - lr: 0.0010\n",
            "Epoch 8/2000\n",
            "657/657 [==============================] - 15s 23ms/step - loss: 0.2798 - accuracy: 0.9194 - val_loss: 0.6750 - val_accuracy: 0.7929 - lr: 0.0010\n",
            "Epoch 9/2000\n",
            "657/657 [==============================] - 16s 24ms/step - loss: 0.2757 - accuracy: 0.9211 - val_loss: 0.6214 - val_accuracy: 0.8057 - lr: 0.0010\n",
            "Epoch 10/2000\n",
            "657/657 [==============================] - 15s 22ms/step - loss: 0.2742 - accuracy: 0.9215 - val_loss: 0.6266 - val_accuracy: 0.8072 - lr: 0.0010\n",
            "Epoch 11/2000\n",
            "657/657 [==============================] - 15s 22ms/step - loss: 0.2577 - accuracy: 0.9254 - val_loss: 0.6379 - val_accuracy: 0.8046 - lr: 0.0010\n",
            "Epoch 12/2000\n",
            "657/657 [==============================] - 15s 22ms/step - loss: 0.2541 - accuracy: 0.9277 - val_loss: 0.6295 - val_accuracy: 0.8081 - lr: 0.0010\n",
            "Epoch 13/2000\n",
            "657/657 [==============================] - 15s 23ms/step - loss: 0.2469 - accuracy: 0.9299 - val_loss: 0.6449 - val_accuracy: 0.8050 - lr: 9.0000e-04\n",
            "Epoch 14/2000\n",
            "657/657 [==============================] - 15s 22ms/step - loss: 0.2430 - accuracy: 0.9304 - val_loss: 0.6118 - val_accuracy: 0.8156 - lr: 9.0000e-04\n",
            "Epoch 15/2000\n",
            "657/657 [==============================] - 15s 23ms/step - loss: 0.2377 - accuracy: 0.9337 - val_loss: 0.6116 - val_accuracy: 0.8109 - lr: 9.0000e-04\n",
            "Epoch 16/2000\n",
            "657/657 [==============================] - 15s 22ms/step - loss: 0.2344 - accuracy: 0.9330 - val_loss: 0.6225 - val_accuracy: 0.8101 - lr: 9.0000e-04\n",
            "Epoch 17/2000\n",
            "657/657 [==============================] - 15s 24ms/step - loss: 0.2350 - accuracy: 0.9341 - val_loss: 0.6240 - val_accuracy: 0.8189 - lr: 9.0000e-04\n",
            "Epoch 18/2000\n",
            "657/657 [==============================] - 15s 23ms/step - loss: 0.2366 - accuracy: 0.9342 - val_loss: 0.6440 - val_accuracy: 0.8205 - lr: 9.0000e-04\n",
            "Epoch 19/2000\n",
            "657/657 [==============================] - 15s 23ms/step - loss: 0.2241 - accuracy: 0.9389 - val_loss: 0.6224 - val_accuracy: 0.8234 - lr: 8.1000e-04\n",
            "Epoch 20/2000\n",
            "657/657 [==============================] - 15s 22ms/step - loss: 0.2198 - accuracy: 0.9388 - val_loss: 0.5924 - val_accuracy: 0.8237 - lr: 8.1000e-04\n",
            "Epoch 21/2000\n",
            "657/657 [==============================] - 15s 23ms/step - loss: 0.2137 - accuracy: 0.9411 - val_loss: 0.5914 - val_accuracy: 0.8270 - lr: 8.1000e-04\n",
            "Epoch 22/2000\n",
            "657/657 [==============================] - 15s 22ms/step - loss: 0.2133 - accuracy: 0.9424 - val_loss: 0.5897 - val_accuracy: 0.8281 - lr: 8.1000e-04\n",
            "Epoch 23/2000\n",
            "657/657 [==============================] - 15s 23ms/step - loss: 0.2181 - accuracy: 0.9399 - val_loss: 0.5971 - val_accuracy: 0.8296 - lr: 8.1000e-04\n",
            "Epoch 24/2000\n",
            "657/657 [==============================] - 15s 23ms/step - loss: 0.2111 - accuracy: 0.9414 - val_loss: 0.5991 - val_accuracy: 0.8294 - lr: 8.1000e-04\n",
            "Epoch 25/2000\n",
            "657/657 [==============================] - 15s 22ms/step - loss: 0.2137 - accuracy: 0.9416 - val_loss: 0.5774 - val_accuracy: 0.8316 - lr: 8.1000e-04\n",
            "Epoch 26/2000\n",
            "657/657 [==============================] - 15s 22ms/step - loss: 0.2128 - accuracy: 0.9420 - val_loss: 0.5869 - val_accuracy: 0.8276 - lr: 8.1000e-04\n",
            "Epoch 27/2000\n",
            "657/657 [==============================] - 15s 22ms/step - loss: 0.2072 - accuracy: 0.9436 - val_loss: 0.6036 - val_accuracy: 0.8240 - lr: 8.1000e-04\n",
            "Epoch 28/2000\n",
            "657/657 [==============================] - 15s 22ms/step - loss: 0.2086 - accuracy: 0.9426 - val_loss: 0.6333 - val_accuracy: 0.8262 - lr: 8.1000e-04\n",
            "Epoch 29/2000\n",
            "657/657 [==============================] - 15s 22ms/step - loss: 0.2060 - accuracy: 0.9446 - val_loss: 0.5719 - val_accuracy: 0.8356 - lr: 7.2900e-04\n",
            "Epoch 30/2000\n",
            "657/657 [==============================] - 15s 22ms/step - loss: 0.1962 - accuracy: 0.9473 - val_loss: 0.5903 - val_accuracy: 0.8338 - lr: 7.2900e-04\n",
            "Epoch 31/2000\n",
            "657/657 [==============================] - 15s 22ms/step - loss: 0.1974 - accuracy: 0.9471 - val_loss: 0.5940 - val_accuracy: 0.8299 - lr: 7.2900e-04\n",
            "Epoch 32/2000\n",
            "657/657 [==============================] - 15s 23ms/step - loss: 0.1978 - accuracy: 0.9451 - val_loss: 0.5795 - val_accuracy: 0.8317 - lr: 7.2900e-04\n",
            "Epoch 33/2000\n",
            "657/657 [==============================] - 15s 22ms/step - loss: 0.1948 - accuracy: 0.9489 - val_loss: 0.5827 - val_accuracy: 0.8334 - lr: 6.5610e-04\n",
            "Epoch 34/2000\n",
            "657/657 [==============================] - 15s 22ms/step - loss: 0.1904 - accuracy: 0.9489 - val_loss: 0.5859 - val_accuracy: 0.8353 - lr: 6.5610e-04\n",
            "Epoch 35/2000\n",
            "657/657 [==============================] - 15s 23ms/step - loss: 0.1910 - accuracy: 0.9488 - val_loss: 0.6080 - val_accuracy: 0.8347 - lr: 6.5610e-04\n",
            "Epoch 36/2000\n",
            "657/657 [==============================] - 15s 22ms/step - loss: 0.1861 - accuracy: 0.9509 - val_loss: 0.5899 - val_accuracy: 0.8333 - lr: 5.9049e-04\n",
            "Epoch 37/2000\n",
            "657/657 [==============================] - 15s 22ms/step - loss: 0.1870 - accuracy: 0.9514 - val_loss: 0.5856 - val_accuracy: 0.8360 - lr: 5.9049e-04\n",
            "Epoch 38/2000\n",
            "657/657 [==============================] - 15s 23ms/step - loss: 0.1847 - accuracy: 0.9518 - val_loss: 0.6184 - val_accuracy: 0.8305 - lr: 5.9049e-04\n",
            "Epoch 39/2000\n",
            "657/657 [==============================] - 15s 22ms/step - loss: 0.1815 - accuracy: 0.9522 - val_loss: 0.5809 - val_accuracy: 0.8369 - lr: 5.3144e-04\n",
            "Epoch 40/2000\n",
            "657/657 [==============================] - 15s 22ms/step - loss: 0.1764 - accuracy: 0.9562 - val_loss: 0.5907 - val_accuracy: 0.8382 - lr: 5.3144e-04\n",
            "Epoch 41/2000\n",
            "657/657 [==============================] - 15s 23ms/step - loss: 0.1781 - accuracy: 0.9561 - val_loss: 0.5845 - val_accuracy: 0.8396 - lr: 5.3144e-04\n",
            "Epoch 42/2000\n",
            "657/657 [==============================] - 15s 22ms/step - loss: 0.1735 - accuracy: 0.9546 - val_loss: 0.5676 - val_accuracy: 0.8387 - lr: 4.7830e-04\n",
            "Epoch 43/2000\n",
            "657/657 [==============================] - 15s 23ms/step - loss: 0.1723 - accuracy: 0.9559 - val_loss: 0.5757 - val_accuracy: 0.8390 - lr: 4.7830e-04\n",
            "Epoch 44/2000\n",
            "657/657 [==============================] - 15s 22ms/step - loss: 0.1722 - accuracy: 0.9550 - val_loss: 0.6083 - val_accuracy: 0.8372 - lr: 4.7830e-04\n",
            "Epoch 45/2000\n",
            "657/657 [==============================] - 15s 22ms/step - loss: 0.1711 - accuracy: 0.9561 - val_loss: 0.6029 - val_accuracy: 0.8370 - lr: 4.7830e-04\n",
            "Epoch 46/2000\n",
            "657/657 [==============================] - 15s 22ms/step - loss: 0.1668 - accuracy: 0.9566 - val_loss: 0.5737 - val_accuracy: 0.8416 - lr: 4.3047e-04\n",
            "Epoch 47/2000\n",
            "657/657 [==============================] - 15s 22ms/step - loss: 0.1637 - accuracy: 0.9588 - val_loss: 0.5717 - val_accuracy: 0.8419 - lr: 4.3047e-04\n",
            "Epoch 48/2000\n",
            "657/657 [==============================] - 15s 23ms/step - loss: 0.1633 - accuracy: 0.9596 - val_loss: 0.5835 - val_accuracy: 0.8456 - lr: 4.3047e-04\n",
            "Epoch 49/2000\n",
            "657/657 [==============================] - 15s 22ms/step - loss: 0.1636 - accuracy: 0.9598 - val_loss: 0.5794 - val_accuracy: 0.8438 - lr: 3.8742e-04\n",
            "Epoch 50/2000\n",
            "657/657 [==============================] - 15s 23ms/step - loss: 0.1618 - accuracy: 0.9595 - val_loss: 0.6182 - val_accuracy: 0.8411 - lr: 3.8742e-04\n",
            "Epoch 51/2000\n",
            "657/657 [==============================] - 15s 23ms/step - loss: 0.1585 - accuracy: 0.9605 - val_loss: 0.5973 - val_accuracy: 0.8400 - lr: 3.8742e-04\n",
            "Epoch 52/2000\n",
            "657/657 [==============================] - 15s 22ms/step - loss: 0.1604 - accuracy: 0.9604 - val_loss: 0.5789 - val_accuracy: 0.8471 - lr: 3.4868e-04\n",
            "Epoch 53/2000\n",
            "657/657 [==============================] - 15s 22ms/step - loss: 0.1575 - accuracy: 0.9610 - val_loss: 0.5908 - val_accuracy: 0.8441 - lr: 3.4868e-04\n",
            "Epoch 54/2000\n",
            "657/657 [==============================] - 15s 22ms/step - loss: 0.1555 - accuracy: 0.9612 - val_loss: 0.5876 - val_accuracy: 0.8468 - lr: 3.4868e-04\n",
            "Epoch 55/2000\n",
            "657/657 [==============================] - 15s 22ms/step - loss: 0.1524 - accuracy: 0.9639 - val_loss: 0.5750 - val_accuracy: 0.8459 - lr: 3.1381e-04\n",
            "Epoch 56/2000\n",
            "657/657 [==============================] - 15s 22ms/step - loss: 0.1506 - accuracy: 0.9633 - val_loss: 0.5773 - val_accuracy: 0.8487 - lr: 3.1381e-04\n",
            "Epoch 57/2000\n",
            "657/657 [==============================] - 15s 23ms/step - loss: 0.1494 - accuracy: 0.9644 - val_loss: 0.5745 - val_accuracy: 0.8442 - lr: 3.1381e-04\n",
            "Epoch 58/2000\n",
            "657/657 [==============================] - 15s 22ms/step - loss: 0.1521 - accuracy: 0.9635 - val_loss: 0.5774 - val_accuracy: 0.8468 - lr: 2.8243e-04\n",
            "Epoch 59/2000\n",
            "657/657 [==============================] - 15s 22ms/step - loss: 0.1493 - accuracy: 0.9632 - val_loss: 0.5893 - val_accuracy: 0.8444 - lr: 2.8243e-04\n",
            "Epoch 60/2000\n",
            "657/657 [==============================] - 15s 22ms/step - loss: 0.1483 - accuracy: 0.9652 - val_loss: 0.5867 - val_accuracy: 0.8422 - lr: 2.8243e-04\n",
            "Epoch 61/2000\n",
            "657/657 [==============================] - 15s 23ms/step - loss: 0.1442 - accuracy: 0.9670 - val_loss: 0.5795 - val_accuracy: 0.8446 - lr: 2.5419e-04\n",
            "Epoch 62/2000\n",
            "657/657 [==============================] - 15s 22ms/step - loss: 0.1442 - accuracy: 0.9668 - val_loss: 0.5947 - val_accuracy: 0.8446 - lr: 2.5419e-04\n",
            "Epoch 63/2000\n",
            "657/657 [==============================] - 15s 24ms/step - loss: 0.1448 - accuracy: 0.9660 - val_loss: 0.5868 - val_accuracy: 0.8491 - lr: 2.5419e-04\n",
            "Epoch 64/2000\n",
            "657/657 [==============================] - 15s 24ms/step - loss: 0.1437 - accuracy: 0.9665 - val_loss: 0.5913 - val_accuracy: 0.8467 - lr: 2.2877e-04\n",
            "Epoch 65/2000\n",
            "657/657 [==============================] - 15s 23ms/step - loss: 0.1429 - accuracy: 0.9665 - val_loss: 0.5782 - val_accuracy: 0.8449 - lr: 2.2877e-04\n",
            "Epoch 66/2000\n",
            "657/657 [==============================] - 15s 22ms/step - loss: 0.1452 - accuracy: 0.9658 - val_loss: 0.5864 - val_accuracy: 0.8447 - lr: 2.2877e-04\n",
            "Epoch 67/2000\n",
            "657/657 [==============================] - 15s 22ms/step - loss: 0.1418 - accuracy: 0.9678 - val_loss: 0.5797 - val_accuracy: 0.8470 - lr: 2.0589e-04\n",
            "Epoch 68/2000\n",
            "657/657 [==============================] - 15s 23ms/step - loss: 0.1411 - accuracy: 0.9672 - val_loss: 0.5768 - val_accuracy: 0.8482 - lr: 2.0589e-04\n",
            "Epoch 69/2000\n",
            "657/657 [==============================] - 15s 22ms/step - loss: 0.1400 - accuracy: 0.9668 - val_loss: 0.5881 - val_accuracy: 0.8461 - lr: 2.0589e-04\n",
            "Epoch 70/2000\n",
            "657/657 [==============================] - 15s 22ms/step - loss: 0.1390 - accuracy: 0.9681 - val_loss: 0.5828 - val_accuracy: 0.8465 - lr: 1.8530e-04\n",
            "Epoch 71/2000\n",
            "657/657 [==============================] - 16s 24ms/step - loss: 0.1375 - accuracy: 0.9689 - val_loss: 0.5967 - val_accuracy: 0.8474 - lr: 1.8530e-04\n",
            "Epoch 72/2000\n",
            "657/657 [==============================] - 15s 22ms/step - loss: 0.1357 - accuracy: 0.9711 - val_loss: 0.5966 - val_accuracy: 0.8477 - lr: 1.8530e-04\n",
            "Epoch 73/2000\n",
            "657/657 [==============================] - 15s 23ms/step - loss: 0.1345 - accuracy: 0.9701 - val_loss: 0.6024 - val_accuracy: 0.8471 - lr: 1.6677e-04\n",
            "Epoch 74/2000\n",
            "657/657 [==============================] - 15s 23ms/step - loss: 0.1370 - accuracy: 0.9688 - val_loss: 0.5813 - val_accuracy: 0.8495 - lr: 1.6677e-04\n",
            "Epoch 75/2000\n",
            "657/657 [==============================] - 15s 23ms/step - loss: 0.1338 - accuracy: 0.9703 - val_loss: 0.6028 - val_accuracy: 0.8422 - lr: 1.6677e-04\n",
            "Epoch 76/2000\n",
            "657/657 [==============================] - 15s 22ms/step - loss: 0.1333 - accuracy: 0.9706 - val_loss: 0.5825 - val_accuracy: 0.8463 - lr: 1.5009e-04\n",
            "Epoch 77/2000\n",
            "657/657 [==============================] - 15s 23ms/step - loss: 0.1352 - accuracy: 0.9701 - val_loss: 0.5836 - val_accuracy: 0.8479 - lr: 1.5009e-04\n",
            "Epoch 78/2000\n",
            "657/657 [==============================] - 15s 22ms/step - loss: 0.1323 - accuracy: 0.9715 - val_loss: 0.5994 - val_accuracy: 0.8471 - lr: 1.5009e-04\n",
            "Epoch 79/2000\n",
            "657/657 [==============================] - 15s 22ms/step - loss: 0.1318 - accuracy: 0.9708 - val_loss: 0.5939 - val_accuracy: 0.8487 - lr: 1.3509e-04\n",
            "Epoch 80/2000\n",
            "657/657 [==============================] - 15s 22ms/step - loss: 0.1308 - accuracy: 0.9714 - val_loss: 0.5961 - val_accuracy: 0.8454 - lr: 1.3509e-04\n",
            "Epoch 81/2000\n",
            "657/657 [==============================] - 15s 22ms/step - loss: 0.1300 - accuracy: 0.9714 - val_loss: 0.5806 - val_accuracy: 0.8476 - lr: 1.3509e-04\n",
            "Epoch 82/2000\n",
            "657/657 [==============================] - 15s 23ms/step - loss: 0.1294 - accuracy: 0.9722 - val_loss: 0.5896 - val_accuracy: 0.8481 - lr: 1.2158e-04\n",
            "Epoch 83/2000\n",
            "657/657 [==============================] - 15s 23ms/step - loss: 0.1280 - accuracy: 0.9724 - val_loss: 0.5910 - val_accuracy: 0.8488 - lr: 1.2158e-04\n",
            "Epoch 84/2000\n",
            "657/657 [==============================] - 15s 22ms/step - loss: 0.1276 - accuracy: 0.9730 - val_loss: 0.5946 - val_accuracy: 0.8485 - lr: 1.2158e-04\n",
            "Epoch 85/2000\n",
            "657/657 [==============================] - 15s 22ms/step - loss: 0.1283 - accuracy: 0.9733 - val_loss: 0.5869 - val_accuracy: 0.8474 - lr: 1.0942e-04\n",
            "Epoch 86/2000\n",
            "657/657 [==============================] - 15s 23ms/step - loss: 0.1278 - accuracy: 0.9728 - val_loss: 0.5969 - val_accuracy: 0.8446 - lr: 1.0942e-04\n",
            "Epoch 87/2000\n",
            "657/657 [==============================] - 15s 23ms/step - loss: 0.1280 - accuracy: 0.9730 - val_loss: 0.5747 - val_accuracy: 0.8468 - lr: 1.0942e-04\n",
            "Epoch 88/2000\n",
            "657/657 [==============================] - 15s 22ms/step - loss: 0.1262 - accuracy: 0.9735 - val_loss: 0.5897 - val_accuracy: 0.8508 - lr: 9.8477e-05\n",
            "Epoch 89/2000\n",
            "657/657 [==============================] - 15s 22ms/step - loss: 0.1266 - accuracy: 0.9739 - val_loss: 0.5790 - val_accuracy: 0.8484 - lr: 9.8477e-05\n",
            "Epoch 90/2000\n",
            "657/657 [==============================] - 15s 24ms/step - loss: 0.1264 - accuracy: 0.9732 - val_loss: 0.5830 - val_accuracy: 0.8466 - lr: 9.8477e-05\n",
            "Epoch 91/2000\n",
            "657/657 [==============================] - 16s 24ms/step - loss: 0.1272 - accuracy: 0.9735 - val_loss: 0.5876 - val_accuracy: 0.8496 - lr: 8.8629e-05\n",
            "Epoch 92/2000\n",
            "657/657 [==============================] - 15s 24ms/step - loss: 0.1263 - accuracy: 0.9735 - val_loss: 0.5941 - val_accuracy: 0.8480 - lr: 8.8629e-05\n",
            "Epoch 93/2000\n",
            "657/657 [==============================] - 15s 23ms/step - loss: 0.1276 - accuracy: 0.9721 - val_loss: 0.5930 - val_accuracy: 0.8477 - lr: 8.8629e-05\n",
            "Epoch 94/2000\n",
            "657/657 [==============================] - 15s 23ms/step - loss: 0.1254 - accuracy: 0.9734 - val_loss: 0.5895 - val_accuracy: 0.8489 - lr: 7.9766e-05\n",
            "Epoch 95/2000\n",
            "657/657 [==============================] - 15s 24ms/step - loss: 0.1254 - accuracy: 0.9742 - val_loss: 0.5872 - val_accuracy: 0.8481 - lr: 7.9766e-05\n",
            "Epoch 96/2000\n",
            "657/657 [==============================] - 15s 23ms/step - loss: 0.1259 - accuracy: 0.9734 - val_loss: 0.5907 - val_accuracy: 0.8461 - lr: 7.9766e-05\n",
            "Epoch 97/2000\n",
            "657/657 [==============================] - 15s 23ms/step - loss: 0.1233 - accuracy: 0.9742 - val_loss: 0.5892 - val_accuracy: 0.8493 - lr: 7.1790e-05\n",
            "Epoch 98/2000\n",
            "657/657 [==============================] - 15s 23ms/step - loss: 0.1242 - accuracy: 0.9743 - val_loss: 0.5910 - val_accuracy: 0.8481 - lr: 7.1790e-05\n",
            "Epoch 99/2000\n",
            "657/657 [==============================] - 15s 24ms/step - loss: 0.1231 - accuracy: 0.9752 - val_loss: 0.5978 - val_accuracy: 0.8463 - lr: 7.1790e-05\n",
            "Epoch 100/2000\n",
            "657/657 [==============================] - 15s 23ms/step - loss: 0.1222 - accuracy: 0.9755 - val_loss: 0.5951 - val_accuracy: 0.8498 - lr: 6.4611e-05\n",
            "Epoch 101/2000\n",
            "657/657 [==============================] - 15s 24ms/step - loss: 0.1214 - accuracy: 0.9759 - val_loss: 0.6004 - val_accuracy: 0.8507 - lr: 6.4611e-05\n",
            "Epoch 102/2000\n",
            "657/657 [==============================] - 15s 22ms/step - loss: 0.1228 - accuracy: 0.9759 - val_loss: 0.5774 - val_accuracy: 0.8533 - lr: 6.4611e-05\n",
            "Epoch 103/2000\n",
            "657/657 [==============================] - 15s 23ms/step - loss: 0.1232 - accuracy: 0.9757 - val_loss: 0.5852 - val_accuracy: 0.8469 - lr: 5.8150e-05\n",
            "Epoch 104/2000\n",
            "657/657 [==============================] - 15s 24ms/step - loss: 0.1215 - accuracy: 0.9756 - val_loss: 0.5881 - val_accuracy: 0.8500 - lr: 5.8150e-05\n",
            "Epoch 105/2000\n",
            "657/657 [==============================] - 15s 22ms/step - loss: 0.1211 - accuracy: 0.9761 - val_loss: 0.6001 - val_accuracy: 0.8487 - lr: 5.8150e-05\n",
            "Epoch 106/2000\n",
            "657/657 [==============================] - 15s 24ms/step - loss: 0.1225 - accuracy: 0.9754 - val_loss: 0.5944 - val_accuracy: 0.8522 - lr: 5.2335e-05\n",
            "Epoch 107/2000\n",
            "657/657 [==============================] - 15s 23ms/step - loss: 0.1230 - accuracy: 0.9753 - val_loss: 0.5893 - val_accuracy: 0.8486 - lr: 5.2335e-05\n",
            "Epoch 108/2000\n",
            "657/657 [==============================] - 15s 23ms/step - loss: 0.1212 - accuracy: 0.9760 - val_loss: 0.5895 - val_accuracy: 0.8478 - lr: 5.2335e-05\n",
            "Epoch 109/2000\n",
            "657/657 [==============================] - 15s 22ms/step - loss: 0.1207 - accuracy: 0.9759 - val_loss: 0.5954 - val_accuracy: 0.8495 - lr: 4.7101e-05\n",
            "Epoch 110/2000\n",
            "657/657 [==============================] - 15s 23ms/step - loss: 0.1203 - accuracy: 0.9770 - val_loss: 0.5986 - val_accuracy: 0.8487 - lr: 4.7101e-05\n",
            "Epoch 111/2000\n",
            "657/657 [==============================] - 15s 22ms/step - loss: 0.1198 - accuracy: 0.9767 - val_loss: 0.6054 - val_accuracy: 0.8464 - lr: 4.7101e-05\n",
            "Epoch 112/2000\n",
            "657/657 [==============================] - 15s 23ms/step - loss: 0.1203 - accuracy: 0.9766 - val_loss: 0.5966 - val_accuracy: 0.8498 - lr: 4.2391e-05\n",
            "Epoch 113/2000\n",
            "657/657 [==============================] - 15s 23ms/step - loss: 0.1193 - accuracy: 0.9766 - val_loss: 0.5997 - val_accuracy: 0.8486 - lr: 4.2391e-05\n",
            "Epoch 114/2000\n",
            "657/657 [==============================] - 16s 24ms/step - loss: 0.1202 - accuracy: 0.9766 - val_loss: 0.5921 - val_accuracy: 0.8476 - lr: 4.2391e-05\n",
            "Epoch 115/2000\n",
            "657/657 [==============================] - 15s 23ms/step - loss: 0.1194 - accuracy: 0.9770 - val_loss: 0.5956 - val_accuracy: 0.8483 - lr: 3.8152e-05\n",
            "Epoch 116/2000\n",
            "657/657 [==============================] - 15s 23ms/step - loss: 0.1197 - accuracy: 0.9761 - val_loss: 0.5851 - val_accuracy: 0.8492 - lr: 3.8152e-05\n",
            "Epoch 117/2000\n",
            "657/657 [==============================] - 15s 22ms/step - loss: 0.1197 - accuracy: 0.9765 - val_loss: 0.5890 - val_accuracy: 0.8508 - lr: 3.8152e-05\n",
            "Epoch 118/2000\n",
            "657/657 [==============================] - 16s 24ms/step - loss: 0.1187 - accuracy: 0.9767 - val_loss: 0.5985 - val_accuracy: 0.8497 - lr: 3.4337e-05\n",
            "Epoch 119/2000\n",
            "657/657 [==============================] - 16s 24ms/step - loss: 0.1197 - accuracy: 0.9757 - val_loss: 0.5915 - val_accuracy: 0.8509 - lr: 3.4337e-05\n",
            "Epoch 120/2000\n",
            "657/657 [==============================] - 15s 23ms/step - loss: 0.1197 - accuracy: 0.9765 - val_loss: 0.5949 - val_accuracy: 0.8493 - lr: 3.4337e-05\n",
            "Epoch 121/2000\n",
            "657/657 [==============================] - 15s 23ms/step - loss: 0.1194 - accuracy: 0.9763 - val_loss: 0.5927 - val_accuracy: 0.8491 - lr: 3.0903e-05\n",
            "Epoch 122/2000\n",
            "657/657 [==============================] - 15s 23ms/step - loss: 0.1179 - accuracy: 0.9777 - val_loss: 0.5956 - val_accuracy: 0.8488 - lr: 3.0903e-05\n",
            "Epoch 123/2000\n",
            "657/657 [==============================] - 15s 23ms/step - loss: 0.1173 - accuracy: 0.9780 - val_loss: 0.6077 - val_accuracy: 0.8506 - lr: 3.0903e-05\n",
            "Epoch 124/2000\n",
            "657/657 [==============================] - 16s 24ms/step - loss: 0.1197 - accuracy: 0.9769 - val_loss: 0.6000 - val_accuracy: 0.8464 - lr: 2.7813e-05\n",
            "Epoch 125/2000\n",
            "657/657 [==============================] - 15s 24ms/step - loss: 0.1185 - accuracy: 0.9775 - val_loss: 0.5876 - val_accuracy: 0.8483 - lr: 2.7813e-05\n",
            "Epoch 126/2000\n",
            "657/657 [==============================] - 15s 24ms/step - loss: 0.1176 - accuracy: 0.9772 - val_loss: 0.5930 - val_accuracy: 0.8511 - lr: 2.7813e-05\n",
            "Epoch 127/2000\n",
            "657/657 [==============================] - 15s 23ms/step - loss: 0.1174 - accuracy: 0.9776 - val_loss: 0.6032 - val_accuracy: 0.8515 - lr: 2.5032e-05\n",
            "Epoch 128/2000\n",
            "657/657 [==============================] - 16s 24ms/step - loss: 0.1178 - accuracy: 0.9771 - val_loss: 0.5963 - val_accuracy: 0.8499 - lr: 2.5032e-05\n",
            "Epoch 129/2000\n",
            "657/657 [==============================] - 16s 24ms/step - loss: 0.1177 - accuracy: 0.9767 - val_loss: 0.5947 - val_accuracy: 0.8470 - lr: 2.5032e-05\n",
            "Epoch 130/2000\n",
            "657/657 [==============================] - 15s 23ms/step - loss: 0.1184 - accuracy: 0.9765 - val_loss: 0.6022 - val_accuracy: 0.8497 - lr: 2.2528e-05\n",
            "Epoch 131/2000\n",
            "657/657 [==============================] - 15s 23ms/step - loss: 0.1180 - accuracy: 0.9779 - val_loss: 0.6055 - val_accuracy: 0.8478 - lr: 2.2528e-05\n",
            "Epoch 132/2000\n",
            "657/657 [==============================] - 16s 24ms/step - loss: 0.1179 - accuracy: 0.9778 - val_loss: 0.6000 - val_accuracy: 0.8499 - lr: 2.2528e-05\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fe96d2dd810>"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('/content/drive/MyDrive/파이썬스터디 프로젝트/labeling_cnn3.h5')"
      ],
      "metadata": {
        "id": "zuG_m7tXEi2g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.models.load_model('/content/drive/MyDrive/파이썬스터디 프로젝트/labeling_cnn3.h5')\n",
        "model_eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HDtQKCLqElcC",
        "outputId": "c39baa93-3571-40cd-e1bb-95bd5578b5b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8951"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#######HYPERPARAMATERS###########\n",
        "epochs = 2000\n",
        "batch_size = 64\n",
        "learning_rate = 0.001\n",
        "#################################\n",
        "  \n",
        "model = Sequential()\n",
        "    \n",
        "model.add(Conv2D(32, kernel_size = (3,3), input_shape=(28,28,1), activation='relu'))\n",
        "\n",
        "model.add(Conv2D(64,(3,3), activation='relu'))\n",
        "model.add(Conv2D(64,(3,3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=2))\n",
        "model.add(PermaDropout(0.5))\n",
        "\n",
        "model.add(Conv2D(128,(3,3), activation='relu'))\n",
        "model.add(Conv2D(128,(3,3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=2))\n",
        "model.add(PermaDropout(0.5))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(PermaDropout(0.5))\n",
        "\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(PermaDropout(0.5))\n",
        "\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "adam = keras.optimizers.Adam(learning_rate)\n",
        "model.compile(optimizer = adam, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
        "    \n",
        "# print(model.summary())\n",
        "\n",
        "lr_reducer = ReduceLROnPlateau(monitor='val_loss', factor=0.9, patience=3)\n",
        "early_stopper = EarlyStopping(monitor='val_accuracy', min_delta=0, patience=30, mode='auto')\n",
        "checkpointer = ModelCheckpoint('weights.hd5', monitor='val_loss', verbose=1, save_best_only=True)\n",
        "\n",
        "\n",
        "model.fit(\n",
        "          train_data_2,\n",
        "          train_labels_2,\n",
        "          epochs = epochs,\n",
        "          batch_size = batch_size,\n",
        "          validation_split = 0.3,\n",
        "          shuffle = True,\n",
        "          callbacks=[lr_reducer, early_stopper]\n",
        "          )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CJwnKwlXEVf7",
        "outputId": "3acc229d-19fc-4d3d-da7b-da6565b5b97c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2000\n",
            "658/658 [==============================] - 16s 23ms/step - loss: 1.0818 - accuracy: 0.6303 - val_loss: 0.3992 - val_accuracy: 0.8598 - lr: 0.0010\n",
            "Epoch 2/2000\n",
            "658/658 [==============================] - 15s 22ms/step - loss: 0.5546 - accuracy: 0.8151 - val_loss: 0.2712 - val_accuracy: 0.9131 - lr: 0.0010\n",
            "Epoch 3/2000\n",
            "658/658 [==============================] - 15s 23ms/step - loss: 0.4773 - accuracy: 0.8430 - val_loss: 0.2152 - val_accuracy: 0.9344 - lr: 0.0010\n",
            "Epoch 4/2000\n",
            "658/658 [==============================] - 15s 22ms/step - loss: 0.4363 - accuracy: 0.8662 - val_loss: 0.1783 - val_accuracy: 0.9547 - lr: 0.0010\n",
            "Epoch 5/2000\n",
            "658/658 [==============================] - 15s 23ms/step - loss: 0.4078 - accuracy: 0.8799 - val_loss: 0.1647 - val_accuracy: 0.9578 - lr: 0.0010\n",
            "Epoch 6/2000\n",
            "658/658 [==============================] - 15s 22ms/step - loss: 0.3868 - accuracy: 0.8877 - val_loss: 0.1529 - val_accuracy: 0.9650 - lr: 0.0010\n",
            "Epoch 7/2000\n",
            "658/658 [==============================] - 15s 23ms/step - loss: 0.3740 - accuracy: 0.8936 - val_loss: 0.1534 - val_accuracy: 0.9737 - lr: 0.0010\n",
            "Epoch 8/2000\n",
            "658/658 [==============================] - 15s 22ms/step - loss: 0.3627 - accuracy: 0.8958 - val_loss: 0.1313 - val_accuracy: 0.9746 - lr: 0.0010\n",
            "Epoch 9/2000\n",
            "658/658 [==============================] - 15s 22ms/step - loss: 0.3554 - accuracy: 0.9007 - val_loss: 0.1265 - val_accuracy: 0.9776 - lr: 0.0010\n",
            "Epoch 10/2000\n",
            "658/658 [==============================] - 15s 22ms/step - loss: 0.3497 - accuracy: 0.9033 - val_loss: 0.1335 - val_accuracy: 0.9740 - lr: 0.0010\n",
            "Epoch 11/2000\n",
            "658/658 [==============================] - 15s 22ms/step - loss: 0.3482 - accuracy: 0.9039 - val_loss: 0.1080 - val_accuracy: 0.9822 - lr: 0.0010\n",
            "Epoch 12/2000\n",
            "658/658 [==============================] - 15s 23ms/step - loss: 0.3471 - accuracy: 0.9068 - val_loss: 0.1263 - val_accuracy: 0.9764 - lr: 0.0010\n",
            "Epoch 13/2000\n",
            "658/658 [==============================] - 15s 23ms/step - loss: 0.3368 - accuracy: 0.9096 - val_loss: 0.1143 - val_accuracy: 0.9814 - lr: 0.0010\n",
            "Epoch 14/2000\n",
            "658/658 [==============================] - 15s 22ms/step - loss: 0.3346 - accuracy: 0.9100 - val_loss: 0.1147 - val_accuracy: 0.9819 - lr: 0.0010\n",
            "Epoch 15/2000\n",
            "658/658 [==============================] - 15s 22ms/step - loss: 0.3241 - accuracy: 0.9136 - val_loss: 0.1004 - val_accuracy: 0.9847 - lr: 9.0000e-04\n",
            "Epoch 16/2000\n",
            "658/658 [==============================] - 15s 22ms/step - loss: 0.3211 - accuracy: 0.9149 - val_loss: 0.1013 - val_accuracy: 0.9841 - lr: 9.0000e-04\n",
            "Epoch 17/2000\n",
            "658/658 [==============================] - 15s 23ms/step - loss: 0.3175 - accuracy: 0.9169 - val_loss: 0.1008 - val_accuracy: 0.9838 - lr: 9.0000e-04\n",
            "Epoch 18/2000\n",
            "658/658 [==============================] - 15s 22ms/step - loss: 0.3202 - accuracy: 0.9154 - val_loss: 0.1102 - val_accuracy: 0.9832 - lr: 9.0000e-04\n",
            "Epoch 19/2000\n",
            "658/658 [==============================] - 15s 24ms/step - loss: 0.3087 - accuracy: 0.9191 - val_loss: 0.1036 - val_accuracy: 0.9865 - lr: 8.1000e-04\n",
            "Epoch 20/2000\n",
            "658/658 [==============================] - 15s 23ms/step - loss: 0.3126 - accuracy: 0.9175 - val_loss: 0.1011 - val_accuracy: 0.9855 - lr: 8.1000e-04\n",
            "Epoch 21/2000\n",
            "658/658 [==============================] - 15s 22ms/step - loss: 0.3041 - accuracy: 0.9215 - val_loss: 0.1004 - val_accuracy: 0.9870 - lr: 8.1000e-04\n",
            "Epoch 22/2000\n",
            "658/658 [==============================] - 15s 22ms/step - loss: 0.2985 - accuracy: 0.9244 - val_loss: 0.1005 - val_accuracy: 0.9844 - lr: 7.2900e-04\n",
            "Epoch 23/2000\n",
            "658/658 [==============================] - 15s 22ms/step - loss: 0.3024 - accuracy: 0.9231 - val_loss: 0.0894 - val_accuracy: 0.9901 - lr: 7.2900e-04\n",
            "Epoch 24/2000\n",
            "658/658 [==============================] - 15s 22ms/step - loss: 0.2929 - accuracy: 0.9257 - val_loss: 0.0987 - val_accuracy: 0.9865 - lr: 7.2900e-04\n",
            "Epoch 25/2000\n",
            "658/658 [==============================] - 15s 22ms/step - loss: 0.2952 - accuracy: 0.9257 - val_loss: 0.0955 - val_accuracy: 0.9847 - lr: 7.2900e-04\n",
            "Epoch 26/2000\n",
            "658/658 [==============================] - 15s 22ms/step - loss: 0.2918 - accuracy: 0.9268 - val_loss: 0.0963 - val_accuracy: 0.9878 - lr: 7.2900e-04\n",
            "Epoch 27/2000\n",
            "658/658 [==============================] - 15s 22ms/step - loss: 0.2892 - accuracy: 0.9282 - val_loss: 0.0910 - val_accuracy: 0.9877 - lr: 6.5610e-04\n",
            "Epoch 28/2000\n",
            "658/658 [==============================] - 15s 23ms/step - loss: 0.2854 - accuracy: 0.9289 - val_loss: 0.0909 - val_accuracy: 0.9892 - lr: 6.5610e-04\n",
            "Epoch 29/2000\n",
            "658/658 [==============================] - 15s 22ms/step - loss: 0.2820 - accuracy: 0.9303 - val_loss: 0.0972 - val_accuracy: 0.9890 - lr: 6.5610e-04\n",
            "Epoch 30/2000\n",
            "658/658 [==============================] - 15s 22ms/step - loss: 0.2808 - accuracy: 0.9309 - val_loss: 0.0937 - val_accuracy: 0.9895 - lr: 5.9049e-04\n",
            "Epoch 31/2000\n",
            "658/658 [==============================] - 15s 22ms/step - loss: 0.2780 - accuracy: 0.9332 - val_loss: 0.0863 - val_accuracy: 0.9900 - lr: 5.9049e-04\n",
            "Epoch 32/2000\n",
            "658/658 [==============================] - 15s 23ms/step - loss: 0.2753 - accuracy: 0.9339 - val_loss: 0.0869 - val_accuracy: 0.9900 - lr: 5.9049e-04\n",
            "Epoch 33/2000\n",
            "658/658 [==============================] - 15s 22ms/step - loss: 0.2786 - accuracy: 0.9332 - val_loss: 0.0861 - val_accuracy: 0.9897 - lr: 5.9049e-04\n",
            "Epoch 34/2000\n",
            "658/658 [==============================] - 15s 22ms/step - loss: 0.2759 - accuracy: 0.9351 - val_loss: 0.0919 - val_accuracy: 0.9893 - lr: 5.9049e-04\n",
            "Epoch 35/2000\n",
            "658/658 [==============================] - 15s 22ms/step - loss: 0.2739 - accuracy: 0.9344 - val_loss: 0.0988 - val_accuracy: 0.9857 - lr: 5.9049e-04\n",
            "Epoch 36/2000\n",
            "658/658 [==============================] - 15s 22ms/step - loss: 0.2741 - accuracy: 0.9334 - val_loss: 0.0851 - val_accuracy: 0.9908 - lr: 5.9049e-04\n",
            "Epoch 37/2000\n",
            "658/658 [==============================] - 15s 22ms/step - loss: 0.2727 - accuracy: 0.9348 - val_loss: 0.0857 - val_accuracy: 0.9912 - lr: 5.9049e-04\n",
            "Epoch 38/2000\n",
            "658/658 [==============================] - 15s 24ms/step - loss: 0.2708 - accuracy: 0.9336 - val_loss: 0.0893 - val_accuracy: 0.9903 - lr: 5.9049e-04\n",
            "Epoch 39/2000\n",
            "658/658 [==============================] - 15s 23ms/step - loss: 0.2704 - accuracy: 0.9352 - val_loss: 0.0905 - val_accuracy: 0.9883 - lr: 5.9049e-04\n",
            "Epoch 40/2000\n",
            "658/658 [==============================] - 16s 24ms/step - loss: 0.2689 - accuracy: 0.9359 - val_loss: 0.0831 - val_accuracy: 0.9898 - lr: 5.3144e-04\n",
            "Epoch 41/2000\n",
            "658/658 [==============================] - 15s 22ms/step - loss: 0.2647 - accuracy: 0.9395 - val_loss: 0.0868 - val_accuracy: 0.9911 - lr: 5.3144e-04\n",
            "Epoch 42/2000\n",
            "658/658 [==============================] - 15s 23ms/step - loss: 0.2660 - accuracy: 0.9396 - val_loss: 0.0854 - val_accuracy: 0.9907 - lr: 5.3144e-04\n",
            "Epoch 43/2000\n",
            "658/658 [==============================] - 15s 22ms/step - loss: 0.2660 - accuracy: 0.9364 - val_loss: 0.0865 - val_accuracy: 0.9908 - lr: 5.3144e-04\n",
            "Epoch 44/2000\n",
            "658/658 [==============================] - 15s 22ms/step - loss: 0.2615 - accuracy: 0.9387 - val_loss: 0.0845 - val_accuracy: 0.9905 - lr: 4.7830e-04\n",
            "Epoch 45/2000\n",
            "658/658 [==============================] - 15s 22ms/step - loss: 0.2588 - accuracy: 0.9409 - val_loss: 0.0811 - val_accuracy: 0.9908 - lr: 4.7830e-04\n",
            "Epoch 46/2000\n",
            "658/658 [==============================] - 15s 23ms/step - loss: 0.2581 - accuracy: 0.9401 - val_loss: 0.0889 - val_accuracy: 0.9897 - lr: 4.7830e-04\n",
            "Epoch 47/2000\n",
            "658/658 [==============================] - 15s 23ms/step - loss: 0.2580 - accuracy: 0.9410 - val_loss: 0.0807 - val_accuracy: 0.9922 - lr: 4.7830e-04\n",
            "Epoch 48/2000\n",
            "658/658 [==============================] - 15s 23ms/step - loss: 0.2608 - accuracy: 0.9413 - val_loss: 0.0781 - val_accuracy: 0.9929 - lr: 4.7830e-04\n",
            "Epoch 49/2000\n",
            "658/658 [==============================] - 15s 22ms/step - loss: 0.2568 - accuracy: 0.9427 - val_loss: 0.0834 - val_accuracy: 0.9926 - lr: 4.7830e-04\n",
            "Epoch 50/2000\n",
            "658/658 [==============================] - 15s 23ms/step - loss: 0.2574 - accuracy: 0.9417 - val_loss: 0.0806 - val_accuracy: 0.9919 - lr: 4.7830e-04\n",
            "Epoch 51/2000\n",
            "658/658 [==============================] - 16s 24ms/step - loss: 0.2563 - accuracy: 0.9422 - val_loss: 0.0823 - val_accuracy: 0.9908 - lr: 4.7830e-04\n",
            "Epoch 52/2000\n",
            "658/658 [==============================] - 15s 23ms/step - loss: 0.2540 - accuracy: 0.9440 - val_loss: 0.0781 - val_accuracy: 0.9921 - lr: 4.3047e-04\n",
            "Epoch 53/2000\n",
            "658/658 [==============================] - 15s 22ms/step - loss: 0.2515 - accuracy: 0.9436 - val_loss: 0.0806 - val_accuracy: 0.9918 - lr: 4.3047e-04\n",
            "Epoch 54/2000\n",
            "658/658 [==============================] - 15s 23ms/step - loss: 0.2522 - accuracy: 0.9437 - val_loss: 0.0785 - val_accuracy: 0.9929 - lr: 4.3047e-04\n",
            "Epoch 55/2000\n",
            "658/658 [==============================] - 15s 23ms/step - loss: 0.2502 - accuracy: 0.9440 - val_loss: 0.0829 - val_accuracy: 0.9912 - lr: 3.8742e-04\n",
            "Epoch 56/2000\n",
            "658/658 [==============================] - 15s 22ms/step - loss: 0.2473 - accuracy: 0.9458 - val_loss: 0.0783 - val_accuracy: 0.9926 - lr: 3.8742e-04\n",
            "Epoch 57/2000\n",
            "658/658 [==============================] - 15s 23ms/step - loss: 0.2482 - accuracy: 0.9446 - val_loss: 0.0771 - val_accuracy: 0.9935 - lr: 3.8742e-04\n",
            "Epoch 58/2000\n",
            "658/658 [==============================] - 15s 23ms/step - loss: 0.2478 - accuracy: 0.9465 - val_loss: 0.0787 - val_accuracy: 0.9923 - lr: 3.8742e-04\n",
            "Epoch 59/2000\n",
            "658/658 [==============================] - 15s 22ms/step - loss: 0.2452 - accuracy: 0.9463 - val_loss: 0.0786 - val_accuracy: 0.9923 - lr: 3.8742e-04\n",
            "Epoch 60/2000\n",
            "658/658 [==============================] - 15s 23ms/step - loss: 0.2452 - accuracy: 0.9459 - val_loss: 0.0789 - val_accuracy: 0.9927 - lr: 3.8742e-04\n",
            "Epoch 61/2000\n",
            "658/658 [==============================] - 15s 23ms/step - loss: 0.2432 - accuracy: 0.9487 - val_loss: 0.0760 - val_accuracy: 0.9917 - lr: 3.4868e-04\n",
            "Epoch 62/2000\n",
            "658/658 [==============================] - 15s 23ms/step - loss: 0.2406 - accuracy: 0.9494 - val_loss: 0.0783 - val_accuracy: 0.9930 - lr: 3.4868e-04\n",
            "Epoch 63/2000\n",
            "658/658 [==============================] - 16s 24ms/step - loss: 0.2428 - accuracy: 0.9483 - val_loss: 0.0774 - val_accuracy: 0.9928 - lr: 3.4868e-04\n",
            "Epoch 64/2000\n",
            "658/658 [==============================] - 15s 23ms/step - loss: 0.2429 - accuracy: 0.9488 - val_loss: 0.0772 - val_accuracy: 0.9932 - lr: 3.4868e-04\n",
            "Epoch 65/2000\n",
            "658/658 [==============================] - 15s 23ms/step - loss: 0.2377 - accuracy: 0.9492 - val_loss: 0.0779 - val_accuracy: 0.9923 - lr: 3.1381e-04\n",
            "Epoch 66/2000\n",
            "658/658 [==============================] - 15s 23ms/step - loss: 0.2397 - accuracy: 0.9499 - val_loss: 0.0770 - val_accuracy: 0.9930 - lr: 3.1381e-04\n",
            "Epoch 67/2000\n",
            "658/658 [==============================] - 15s 23ms/step - loss: 0.2390 - accuracy: 0.9503 - val_loss: 0.0746 - val_accuracy: 0.9937 - lr: 3.1381e-04\n",
            "Epoch 68/2000\n",
            "658/658 [==============================] - 15s 23ms/step - loss: 0.2379 - accuracy: 0.9506 - val_loss: 0.0763 - val_accuracy: 0.9932 - lr: 3.1381e-04\n",
            "Epoch 69/2000\n",
            "658/658 [==============================] - 16s 24ms/step - loss: 0.2374 - accuracy: 0.9503 - val_loss: 0.0750 - val_accuracy: 0.9926 - lr: 3.1381e-04\n",
            "Epoch 70/2000\n",
            "658/658 [==============================] - 15s 23ms/step - loss: 0.2362 - accuracy: 0.9511 - val_loss: 0.0759 - val_accuracy: 0.9927 - lr: 3.1381e-04\n",
            "Epoch 71/2000\n",
            "658/658 [==============================] - 15s 23ms/step - loss: 0.2348 - accuracy: 0.9518 - val_loss: 0.0759 - val_accuracy: 0.9940 - lr: 2.8243e-04\n",
            "Epoch 72/2000\n",
            "658/658 [==============================] - 16s 24ms/step - loss: 0.2336 - accuracy: 0.9530 - val_loss: 0.0741 - val_accuracy: 0.9931 - lr: 2.8243e-04\n",
            "Epoch 73/2000\n",
            "658/658 [==============================] - 15s 23ms/step - loss: 0.2351 - accuracy: 0.9513 - val_loss: 0.0729 - val_accuracy: 0.9940 - lr: 2.8243e-04\n",
            "Epoch 74/2000\n",
            "658/658 [==============================] - 15s 22ms/step - loss: 0.2325 - accuracy: 0.9533 - val_loss: 0.0726 - val_accuracy: 0.9943 - lr: 2.8243e-04\n",
            "Epoch 75/2000\n",
            "658/658 [==============================] - 16s 24ms/step - loss: 0.2346 - accuracy: 0.9529 - val_loss: 0.0750 - val_accuracy: 0.9936 - lr: 2.8243e-04\n",
            "Epoch 76/2000\n",
            "658/658 [==============================] - 15s 23ms/step - loss: 0.2334 - accuracy: 0.9522 - val_loss: 0.0738 - val_accuracy: 0.9942 - lr: 2.8243e-04\n",
            "Epoch 77/2000\n",
            "658/658 [==============================] - 16s 24ms/step - loss: 0.2337 - accuracy: 0.9522 - val_loss: 0.0770 - val_accuracy: 0.9932 - lr: 2.8243e-04\n",
            "Epoch 78/2000\n",
            "658/658 [==============================] - 16s 24ms/step - loss: 0.2307 - accuracy: 0.9536 - val_loss: 0.0759 - val_accuracy: 0.9931 - lr: 2.5419e-04\n",
            "Epoch 79/2000\n",
            "658/658 [==============================] - 15s 23ms/step - loss: 0.2312 - accuracy: 0.9539 - val_loss: 0.0716 - val_accuracy: 0.9943 - lr: 2.5419e-04\n",
            "Epoch 80/2000\n",
            "658/658 [==============================] - 15s 22ms/step - loss: 0.2289 - accuracy: 0.9551 - val_loss: 0.0744 - val_accuracy: 0.9934 - lr: 2.5419e-04\n",
            "Epoch 81/2000\n",
            "658/658 [==============================] - 15s 23ms/step - loss: 0.2298 - accuracy: 0.9545 - val_loss: 0.0749 - val_accuracy: 0.9934 - lr: 2.5419e-04\n",
            "Epoch 82/2000\n",
            "658/658 [==============================] - 15s 23ms/step - loss: 0.2297 - accuracy: 0.9555 - val_loss: 0.0732 - val_accuracy: 0.9942 - lr: 2.5419e-04\n",
            "Epoch 83/2000\n",
            "658/658 [==============================] - 15s 23ms/step - loss: 0.2264 - accuracy: 0.9559 - val_loss: 0.0718 - val_accuracy: 0.9943 - lr: 2.2877e-04\n",
            "Epoch 84/2000\n",
            "658/658 [==============================] - 15s 23ms/step - loss: 0.2259 - accuracy: 0.9559 - val_loss: 0.0719 - val_accuracy: 0.9943 - lr: 2.2877e-04\n",
            "Epoch 85/2000\n",
            "658/658 [==============================] - 15s 23ms/step - loss: 0.2257 - accuracy: 0.9565 - val_loss: 0.0737 - val_accuracy: 0.9926 - lr: 2.2877e-04\n",
            "Epoch 86/2000\n",
            "658/658 [==============================] - 15s 23ms/step - loss: 0.2255 - accuracy: 0.9573 - val_loss: 0.0726 - val_accuracy: 0.9936 - lr: 2.0589e-04\n",
            "Epoch 87/2000\n",
            "658/658 [==============================] - 16s 24ms/step - loss: 0.2241 - accuracy: 0.9569 - val_loss: 0.0737 - val_accuracy: 0.9931 - lr: 2.0589e-04\n",
            "Epoch 88/2000\n",
            "658/658 [==============================] - 15s 23ms/step - loss: 0.2251 - accuracy: 0.9567 - val_loss: 0.0725 - val_accuracy: 0.9941 - lr: 2.0589e-04\n",
            "Epoch 89/2000\n",
            "658/658 [==============================] - 16s 24ms/step - loss: 0.2245 - accuracy: 0.9578 - val_loss: 0.0720 - val_accuracy: 0.9932 - lr: 1.8530e-04\n",
            "Epoch 90/2000\n",
            "658/658 [==============================] - 16s 24ms/step - loss: 0.2225 - accuracy: 0.9570 - val_loss: 0.0709 - val_accuracy: 0.9939 - lr: 1.8530e-04\n",
            "Epoch 91/2000\n",
            "658/658 [==============================] - 15s 23ms/step - loss: 0.2226 - accuracy: 0.9582 - val_loss: 0.0717 - val_accuracy: 0.9943 - lr: 1.8530e-04\n",
            "Epoch 92/2000\n",
            "658/658 [==============================] - 15s 23ms/step - loss: 0.2232 - accuracy: 0.9567 - val_loss: 0.0705 - val_accuracy: 0.9948 - lr: 1.8530e-04\n",
            "Epoch 93/2000\n",
            "658/658 [==============================] - 15s 23ms/step - loss: 0.2220 - accuracy: 0.9580 - val_loss: 0.0706 - val_accuracy: 0.9946 - lr: 1.8530e-04\n",
            "Epoch 94/2000\n",
            "658/658 [==============================] - 15s 23ms/step - loss: 0.2217 - accuracy: 0.9586 - val_loss: 0.0719 - val_accuracy: 0.9935 - lr: 1.8530e-04\n",
            "Epoch 95/2000\n",
            "658/658 [==============================] - 15s 23ms/step - loss: 0.2221 - accuracy: 0.9588 - val_loss: 0.0725 - val_accuracy: 0.9940 - lr: 1.8530e-04\n",
            "Epoch 96/2000\n",
            "658/658 [==============================] - 15s 24ms/step - loss: 0.2232 - accuracy: 0.9572 - val_loss: 0.0701 - val_accuracy: 0.9947 - lr: 1.6677e-04\n",
            "Epoch 97/2000\n",
            "658/658 [==============================] - 15s 24ms/step - loss: 0.2205 - accuracy: 0.9579 - val_loss: 0.0710 - val_accuracy: 0.9933 - lr: 1.6677e-04\n",
            "Epoch 98/2000\n",
            "658/658 [==============================] - 15s 23ms/step - loss: 0.2204 - accuracy: 0.9585 - val_loss: 0.0705 - val_accuracy: 0.9947 - lr: 1.6677e-04\n",
            "Epoch 99/2000\n",
            "658/658 [==============================] - 16s 24ms/step - loss: 0.2194 - accuracy: 0.9589 - val_loss: 0.0719 - val_accuracy: 0.9933 - lr: 1.6677e-04\n",
            "Epoch 100/2000\n",
            "658/658 [==============================] - 15s 23ms/step - loss: 0.2193 - accuracy: 0.9594 - val_loss: 0.0716 - val_accuracy: 0.9939 - lr: 1.5009e-04\n",
            "Epoch 101/2000\n",
            "658/658 [==============================] - 15s 23ms/step - loss: 0.2180 - accuracy: 0.9610 - val_loss: 0.0707 - val_accuracy: 0.9942 - lr: 1.5009e-04\n",
            "Epoch 102/2000\n",
            "658/658 [==============================] - 15s 23ms/step - loss: 0.2173 - accuracy: 0.9601 - val_loss: 0.0699 - val_accuracy: 0.9949 - lr: 1.5009e-04\n",
            "Epoch 103/2000\n",
            "658/658 [==============================] - 15s 23ms/step - loss: 0.2186 - accuracy: 0.9598 - val_loss: 0.0699 - val_accuracy: 0.9941 - lr: 1.5009e-04\n",
            "Epoch 104/2000\n",
            "658/658 [==============================] - 15s 23ms/step - loss: 0.2169 - accuracy: 0.9599 - val_loss: 0.0702 - val_accuracy: 0.9942 - lr: 1.5009e-04\n",
            "Epoch 105/2000\n",
            "658/658 [==============================] - 15s 23ms/step - loss: 0.2164 - accuracy: 0.9607 - val_loss: 0.0709 - val_accuracy: 0.9947 - lr: 1.5009e-04\n",
            "Epoch 106/2000\n",
            "658/658 [==============================] - 16s 24ms/step - loss: 0.2170 - accuracy: 0.9608 - val_loss: 0.0710 - val_accuracy: 0.9941 - lr: 1.3509e-04\n",
            "Epoch 107/2000\n",
            "658/658 [==============================] - 15s 23ms/step - loss: 0.2160 - accuracy: 0.9595 - val_loss: 0.0704 - val_accuracy: 0.9940 - lr: 1.3509e-04\n",
            "Epoch 108/2000\n",
            "658/658 [==============================] - 16s 24ms/step - loss: 0.2165 - accuracy: 0.9610 - val_loss: 0.0703 - val_accuracy: 0.9948 - lr: 1.3509e-04\n",
            "Epoch 109/2000\n",
            "658/658 [==============================] - 15s 23ms/step - loss: 0.2158 - accuracy: 0.9606 - val_loss: 0.0687 - val_accuracy: 0.9949 - lr: 1.2158e-04\n",
            "Epoch 110/2000\n",
            "658/658 [==============================] - 15s 23ms/step - loss: 0.2155 - accuracy: 0.9603 - val_loss: 0.0708 - val_accuracy: 0.9942 - lr: 1.2158e-04\n",
            "Epoch 111/2000\n",
            "658/658 [==============================] - 15s 23ms/step - loss: 0.2152 - accuracy: 0.9606 - val_loss: 0.0709 - val_accuracy: 0.9941 - lr: 1.2158e-04\n",
            "Epoch 112/2000\n",
            "658/658 [==============================] - 15s 23ms/step - loss: 0.2133 - accuracy: 0.9616 - val_loss: 0.0695 - val_accuracy: 0.9950 - lr: 1.2158e-04\n",
            "Epoch 113/2000\n",
            "658/658 [==============================] - 15s 23ms/step - loss: 0.2139 - accuracy: 0.9618 - val_loss: 0.0691 - val_accuracy: 0.9943 - lr: 1.0942e-04\n",
            "Epoch 114/2000\n",
            "658/658 [==============================] - 16s 24ms/step - loss: 0.2137 - accuracy: 0.9614 - val_loss: 0.0697 - val_accuracy: 0.9948 - lr: 1.0942e-04\n",
            "Epoch 115/2000\n",
            "658/658 [==============================] - 15s 23ms/step - loss: 0.2143 - accuracy: 0.9610 - val_loss: 0.0703 - val_accuracy: 0.9942 - lr: 1.0942e-04\n",
            "Epoch 116/2000\n",
            "658/658 [==============================] - 16s 24ms/step - loss: 0.2132 - accuracy: 0.9620 - val_loss: 0.0697 - val_accuracy: 0.9952 - lr: 9.8477e-05\n",
            "Epoch 117/2000\n",
            "658/658 [==============================] - 16s 24ms/step - loss: 0.2133 - accuracy: 0.9627 - val_loss: 0.0696 - val_accuracy: 0.9952 - lr: 9.8477e-05\n",
            "Epoch 118/2000\n",
            "658/658 [==============================] - 16s 24ms/step - loss: 0.2135 - accuracy: 0.9616 - val_loss: 0.0689 - val_accuracy: 0.9945 - lr: 9.8477e-05\n",
            "Epoch 119/2000\n",
            "658/658 [==============================] - 16s 24ms/step - loss: 0.2128 - accuracy: 0.9630 - val_loss: 0.0691 - val_accuracy: 0.9950 - lr: 8.8629e-05\n",
            "Epoch 120/2000\n",
            "658/658 [==============================] - 15s 23ms/step - loss: 0.2116 - accuracy: 0.9626 - val_loss: 0.0690 - val_accuracy: 0.9952 - lr: 8.8629e-05\n",
            "Epoch 121/2000\n",
            "658/658 [==============================] - 16s 24ms/step - loss: 0.2123 - accuracy: 0.9635 - val_loss: 0.0693 - val_accuracy: 0.9941 - lr: 8.8629e-05\n",
            "Epoch 122/2000\n",
            "658/658 [==============================] - 15s 23ms/step - loss: 0.2114 - accuracy: 0.9629 - val_loss: 0.0692 - val_accuracy: 0.9947 - lr: 7.9766e-05\n",
            "Epoch 123/2000\n",
            "658/658 [==============================] - 15s 23ms/step - loss: 0.2110 - accuracy: 0.9639 - val_loss: 0.0690 - val_accuracy: 0.9944 - lr: 7.9766e-05\n",
            "Epoch 124/2000\n",
            "658/658 [==============================] - 15s 23ms/step - loss: 0.2112 - accuracy: 0.9632 - val_loss: 0.0689 - val_accuracy: 0.9946 - lr: 7.9766e-05\n",
            "Epoch 125/2000\n",
            "658/658 [==============================] - 15s 23ms/step - loss: 0.2104 - accuracy: 0.9645 - val_loss: 0.0684 - val_accuracy: 0.9951 - lr: 7.1790e-05\n",
            "Epoch 126/2000\n",
            "658/658 [==============================] - 15s 23ms/step - loss: 0.2112 - accuracy: 0.9639 - val_loss: 0.0689 - val_accuracy: 0.9947 - lr: 7.1790e-05\n",
            "Epoch 127/2000\n",
            "658/658 [==============================] - 15s 23ms/step - loss: 0.2103 - accuracy: 0.9638 - val_loss: 0.0697 - val_accuracy: 0.9943 - lr: 7.1790e-05\n",
            "Epoch 128/2000\n",
            "658/658 [==============================] - 15s 23ms/step - loss: 0.2094 - accuracy: 0.9645 - val_loss: 0.0682 - val_accuracy: 0.9947 - lr: 7.1790e-05\n",
            "Epoch 129/2000\n",
            "658/658 [==============================] - 15s 23ms/step - loss: 0.2105 - accuracy: 0.9633 - val_loss: 0.0690 - val_accuracy: 0.9950 - lr: 7.1790e-05\n",
            "Epoch 130/2000\n",
            "658/658 [==============================] - 15s 23ms/step - loss: 0.2097 - accuracy: 0.9645 - val_loss: 0.0681 - val_accuracy: 0.9946 - lr: 7.1790e-05\n",
            "Epoch 131/2000\n",
            "658/658 [==============================] - 15s 23ms/step - loss: 0.2091 - accuracy: 0.9637 - val_loss: 0.0694 - val_accuracy: 0.9943 - lr: 7.1790e-05\n",
            "Epoch 132/2000\n",
            "658/658 [==============================] - 16s 24ms/step - loss: 0.2098 - accuracy: 0.9641 - val_loss: 0.0682 - val_accuracy: 0.9950 - lr: 7.1790e-05\n",
            "Epoch 133/2000\n",
            "658/658 [==============================] - 15s 23ms/step - loss: 0.2097 - accuracy: 0.9639 - val_loss: 0.0688 - val_accuracy: 0.9953 - lr: 7.1790e-05\n",
            "Epoch 134/2000\n",
            "658/658 [==============================] - 16s 24ms/step - loss: 0.2093 - accuracy: 0.9641 - val_loss: 0.0688 - val_accuracy: 0.9950 - lr: 6.4611e-05\n",
            "Epoch 135/2000\n",
            "658/658 [==============================] - 15s 23ms/step - loss: 0.2082 - accuracy: 0.9637 - val_loss: 0.0679 - val_accuracy: 0.9952 - lr: 6.4611e-05\n",
            "Epoch 136/2000\n",
            "658/658 [==============================] - 15s 23ms/step - loss: 0.2084 - accuracy: 0.9637 - val_loss: 0.0691 - val_accuracy: 0.9946 - lr: 6.4611e-05\n",
            "Epoch 137/2000\n",
            "658/658 [==============================] - 15s 23ms/step - loss: 0.2093 - accuracy: 0.9638 - val_loss: 0.0687 - val_accuracy: 0.9942 - lr: 6.4611e-05\n",
            "Epoch 138/2000\n",
            "658/658 [==============================] - 16s 24ms/step - loss: 0.2100 - accuracy: 0.9629 - val_loss: 0.0684 - val_accuracy: 0.9945 - lr: 6.4611e-05\n",
            "Epoch 139/2000\n",
            "658/658 [==============================] - 15s 23ms/step - loss: 0.2077 - accuracy: 0.9650 - val_loss: 0.0680 - val_accuracy: 0.9951 - lr: 5.8150e-05\n",
            "Epoch 140/2000\n",
            "658/658 [==============================] - 15s 23ms/step - loss: 0.2091 - accuracy: 0.9638 - val_loss: 0.0687 - val_accuracy: 0.9952 - lr: 5.8150e-05\n",
            "Epoch 141/2000\n",
            "658/658 [==============================] - 15s 23ms/step - loss: 0.2085 - accuracy: 0.9643 - val_loss: 0.0688 - val_accuracy: 0.9948 - lr: 5.8150e-05\n",
            "Epoch 142/2000\n",
            "658/658 [==============================] - 15s 23ms/step - loss: 0.2079 - accuracy: 0.9650 - val_loss: 0.0690 - val_accuracy: 0.9949 - lr: 5.2335e-05\n",
            "Epoch 143/2000\n",
            "658/658 [==============================] - 15s 23ms/step - loss: 0.2078 - accuracy: 0.9649 - val_loss: 0.0679 - val_accuracy: 0.9950 - lr: 5.2335e-05\n",
            "Epoch 144/2000\n",
            "658/658 [==============================] - 16s 24ms/step - loss: 0.2071 - accuracy: 0.9654 - val_loss: 0.0696 - val_accuracy: 0.9940 - lr: 5.2335e-05\n",
            "Epoch 145/2000\n",
            "658/658 [==============================] - 15s 23ms/step - loss: 0.2072 - accuracy: 0.9658 - val_loss: 0.0687 - val_accuracy: 0.9944 - lr: 4.7101e-05\n",
            "Epoch 146/2000\n",
            "658/658 [==============================] - 16s 24ms/step - loss: 0.2068 - accuracy: 0.9656 - val_loss: 0.0686 - val_accuracy: 0.9948 - lr: 4.7101e-05\n",
            "Epoch 147/2000\n",
            "658/658 [==============================] - 16s 24ms/step - loss: 0.2080 - accuracy: 0.9645 - val_loss: 0.0696 - val_accuracy: 0.9945 - lr: 4.7101e-05\n",
            "Epoch 148/2000\n",
            "658/658 [==============================] - 15s 23ms/step - loss: 0.2073 - accuracy: 0.9659 - val_loss: 0.0682 - val_accuracy: 0.9950 - lr: 4.2391e-05\n",
            "Epoch 149/2000\n",
            "658/658 [==============================] - 15s 23ms/step - loss: 0.2078 - accuracy: 0.9650 - val_loss: 0.0685 - val_accuracy: 0.9944 - lr: 4.2391e-05\n",
            "Epoch 150/2000\n",
            "658/658 [==============================] - 16s 24ms/step - loss: 0.2080 - accuracy: 0.9643 - val_loss: 0.0685 - val_accuracy: 0.9950 - lr: 4.2391e-05\n",
            "Epoch 151/2000\n",
            "658/658 [==============================] - 16s 24ms/step - loss: 0.2070 - accuracy: 0.9656 - val_loss: 0.0675 - val_accuracy: 0.9957 - lr: 3.8152e-05\n",
            "Epoch 152/2000\n",
            "658/658 [==============================] - 15s 23ms/step - loss: 0.2068 - accuracy: 0.9662 - val_loss: 0.0669 - val_accuracy: 0.9955 - lr: 3.8152e-05\n",
            "Epoch 153/2000\n",
            "658/658 [==============================] - 15s 23ms/step - loss: 0.2070 - accuracy: 0.9645 - val_loss: 0.0683 - val_accuracy: 0.9953 - lr: 3.8152e-05\n",
            "Epoch 154/2000\n",
            "658/658 [==============================] - 15s 23ms/step - loss: 0.2066 - accuracy: 0.9649 - val_loss: 0.0683 - val_accuracy: 0.9946 - lr: 3.8152e-05\n",
            "Epoch 155/2000\n",
            "658/658 [==============================] - 15s 23ms/step - loss: 0.2056 - accuracy: 0.9659 - val_loss: 0.0687 - val_accuracy: 0.9948 - lr: 3.8152e-05\n",
            "Epoch 156/2000\n",
            "658/658 [==============================] - 16s 24ms/step - loss: 0.2077 - accuracy: 0.9649 - val_loss: 0.0683 - val_accuracy: 0.9951 - lr: 3.4337e-05\n",
            "Epoch 157/2000\n",
            "658/658 [==============================] - 16s 24ms/step - loss: 0.2058 - accuracy: 0.9656 - val_loss: 0.0682 - val_accuracy: 0.9943 - lr: 3.4337e-05\n",
            "Epoch 158/2000\n",
            "658/658 [==============================] - 15s 23ms/step - loss: 0.2053 - accuracy: 0.9659 - val_loss: 0.0674 - val_accuracy: 0.9952 - lr: 3.4337e-05\n",
            "Epoch 159/2000\n",
            "658/658 [==============================] - 15s 23ms/step - loss: 0.2062 - accuracy: 0.9649 - val_loss: 0.0679 - val_accuracy: 0.9947 - lr: 3.0903e-05\n",
            "Epoch 160/2000\n",
            "658/658 [==============================] - 16s 24ms/step - loss: 0.2058 - accuracy: 0.9651 - val_loss: 0.0675 - val_accuracy: 0.9953 - lr: 3.0903e-05\n",
            "Epoch 161/2000\n",
            "658/658 [==============================] - 16s 24ms/step - loss: 0.2051 - accuracy: 0.9660 - val_loss: 0.0678 - val_accuracy: 0.9952 - lr: 3.0903e-05\n",
            "Epoch 162/2000\n",
            "658/658 [==============================] - 16s 24ms/step - loss: 0.2062 - accuracy: 0.9653 - val_loss: 0.0681 - val_accuracy: 0.9941 - lr: 2.7813e-05\n",
            "Epoch 163/2000\n",
            "658/658 [==============================] - 15s 23ms/step - loss: 0.2053 - accuracy: 0.9651 - val_loss: 0.0679 - val_accuracy: 0.9950 - lr: 2.7813e-05\n",
            "Epoch 164/2000\n",
            "658/658 [==============================] - 15s 23ms/step - loss: 0.2046 - accuracy: 0.9668 - val_loss: 0.0680 - val_accuracy: 0.9948 - lr: 2.7813e-05\n",
            "Epoch 165/2000\n",
            "658/658 [==============================] - 15s 23ms/step - loss: 0.2054 - accuracy: 0.9669 - val_loss: 0.0674 - val_accuracy: 0.9955 - lr: 2.5032e-05\n",
            "Epoch 166/2000\n",
            "658/658 [==============================] - 15s 23ms/step - loss: 0.2053 - accuracy: 0.9657 - val_loss: 0.0673 - val_accuracy: 0.9955 - lr: 2.5032e-05\n",
            "Epoch 167/2000\n",
            "658/658 [==============================] - 15s 23ms/step - loss: 0.2054 - accuracy: 0.9663 - val_loss: 0.0680 - val_accuracy: 0.9953 - lr: 2.5032e-05\n",
            "Epoch 168/2000\n",
            "658/658 [==============================] - 15s 23ms/step - loss: 0.2042 - accuracy: 0.9662 - val_loss: 0.0683 - val_accuracy: 0.9945 - lr: 2.2528e-05\n",
            "Epoch 169/2000\n",
            "658/658 [==============================] - 15s 23ms/step - loss: 0.2060 - accuracy: 0.9656 - val_loss: 0.0680 - val_accuracy: 0.9947 - lr: 2.2528e-05\n",
            "Epoch 170/2000\n",
            "658/658 [==============================] - 15s 23ms/step - loss: 0.2049 - accuracy: 0.9660 - val_loss: 0.0676 - val_accuracy: 0.9956 - lr: 2.2528e-05\n",
            "Epoch 171/2000\n",
            "658/658 [==============================] - 15s 23ms/step - loss: 0.2047 - accuracy: 0.9659 - val_loss: 0.0682 - val_accuracy: 0.9943 - lr: 2.0276e-05\n",
            "Epoch 172/2000\n",
            "658/658 [==============================] - 15s 23ms/step - loss: 0.2046 - accuracy: 0.9653 - val_loss: 0.0677 - val_accuracy: 0.9955 - lr: 2.0276e-05\n",
            "Epoch 173/2000\n",
            "658/658 [==============================] - 16s 24ms/step - loss: 0.2054 - accuracy: 0.9651 - val_loss: 0.0682 - val_accuracy: 0.9952 - lr: 2.0276e-05\n",
            "Epoch 174/2000\n",
            "658/658 [==============================] - 15s 23ms/step - loss: 0.2054 - accuracy: 0.9654 - val_loss: 0.0671 - val_accuracy: 0.9956 - lr: 1.8248e-05\n",
            "Epoch 175/2000\n",
            "658/658 [==============================] - 15s 23ms/step - loss: 0.2057 - accuracy: 0.9663 - val_loss: 0.0679 - val_accuracy: 0.9948 - lr: 1.8248e-05\n",
            "Epoch 176/2000\n",
            "658/658 [==============================] - 15s 23ms/step - loss: 0.2049 - accuracy: 0.9653 - val_loss: 0.0677 - val_accuracy: 0.9956 - lr: 1.8248e-05\n",
            "Epoch 177/2000\n",
            "658/658 [==============================] - 15s 23ms/step - loss: 0.2056 - accuracy: 0.9652 - val_loss: 0.0686 - val_accuracy: 0.9945 - lr: 1.6423e-05\n",
            "Epoch 178/2000\n",
            "658/658 [==============================] - 15s 23ms/step - loss: 0.2046 - accuracy: 0.9668 - val_loss: 0.0675 - val_accuracy: 0.9948 - lr: 1.6423e-05\n",
            "Epoch 179/2000\n",
            "658/658 [==============================] - 15s 23ms/step - loss: 0.2053 - accuracy: 0.9659 - val_loss: 0.0670 - val_accuracy: 0.9960 - lr: 1.6423e-05\n",
            "Epoch 180/2000\n",
            "658/658 [==============================] - 15s 23ms/step - loss: 0.2034 - accuracy: 0.9670 - val_loss: 0.0680 - val_accuracy: 0.9943 - lr: 1.4781e-05\n",
            "Epoch 181/2000\n",
            "658/658 [==============================] - 15s 23ms/step - loss: 0.2049 - accuracy: 0.9662 - val_loss: 0.0676 - val_accuracy: 0.9950 - lr: 1.4781e-05\n",
            "Epoch 182/2000\n",
            "658/658 [==============================] - 15s 23ms/step - loss: 0.2034 - accuracy: 0.9671 - val_loss: 0.0681 - val_accuracy: 0.9950 - lr: 1.4781e-05\n",
            "Epoch 183/2000\n",
            "658/658 [==============================] - 15s 23ms/step - loss: 0.2046 - accuracy: 0.9666 - val_loss: 0.0673 - val_accuracy: 0.9957 - lr: 1.3303e-05\n",
            "Epoch 184/2000\n",
            "658/658 [==============================] - 16s 24ms/step - loss: 0.2043 - accuracy: 0.9655 - val_loss: 0.0678 - val_accuracy: 0.9948 - lr: 1.3303e-05\n",
            "Epoch 185/2000\n",
            "658/658 [==============================] - 15s 23ms/step - loss: 0.2047 - accuracy: 0.9654 - val_loss: 0.0674 - val_accuracy: 0.9947 - lr: 1.3303e-05\n",
            "Epoch 186/2000\n",
            "658/658 [==============================] - 15s 23ms/step - loss: 0.2044 - accuracy: 0.9670 - val_loss: 0.0669 - val_accuracy: 0.9956 - lr: 1.1973e-05\n",
            "Epoch 187/2000\n",
            "658/658 [==============================] - 15s 23ms/step - loss: 0.2044 - accuracy: 0.9663 - val_loss: 0.0678 - val_accuracy: 0.9952 - lr: 1.1973e-05\n",
            "Epoch 188/2000\n",
            "658/658 [==============================] - 16s 24ms/step - loss: 0.2039 - accuracy: 0.9674 - val_loss: 0.0673 - val_accuracy: 0.9951 - lr: 1.1973e-05\n",
            "Epoch 189/2000\n",
            "658/658 [==============================] - 15s 23ms/step - loss: 0.2037 - accuracy: 0.9676 - val_loss: 0.0669 - val_accuracy: 0.9952 - lr: 1.0775e-05\n",
            "Epoch 190/2000\n",
            "658/658 [==============================] - 15s 23ms/step - loss: 0.2045 - accuracy: 0.9674 - val_loss: 0.0683 - val_accuracy: 0.9951 - lr: 1.0775e-05\n",
            "Epoch 191/2000\n",
            "658/658 [==============================] - 15s 23ms/step - loss: 0.2047 - accuracy: 0.9660 - val_loss: 0.0682 - val_accuracy: 0.9946 - lr: 1.0775e-05\n",
            "Epoch 192/2000\n",
            "658/658 [==============================] - 15s 23ms/step - loss: 0.2040 - accuracy: 0.9669 - val_loss: 0.0679 - val_accuracy: 0.9946 - lr: 9.6977e-06\n",
            "Epoch 193/2000\n",
            "658/658 [==============================] - 15s 23ms/step - loss: 0.2042 - accuracy: 0.9662 - val_loss: 0.0676 - val_accuracy: 0.9958 - lr: 9.6977e-06\n",
            "Epoch 194/2000\n",
            "658/658 [==============================] - 16s 24ms/step - loss: 0.2032 - accuracy: 0.9683 - val_loss: 0.0681 - val_accuracy: 0.9947 - lr: 9.6977e-06\n",
            "Epoch 195/2000\n",
            "658/658 [==============================] - 15s 23ms/step - loss: 0.2041 - accuracy: 0.9673 - val_loss: 0.0687 - val_accuracy: 0.9940 - lr: 8.7280e-06\n",
            "Epoch 196/2000\n",
            "658/658 [==============================] - 15s 23ms/step - loss: 0.2038 - accuracy: 0.9662 - val_loss: 0.0671 - val_accuracy: 0.9962 - lr: 8.7280e-06\n",
            "Epoch 197/2000\n",
            "658/658 [==============================] - 15s 23ms/step - loss: 0.2039 - accuracy: 0.9667 - val_loss: 0.0689 - val_accuracy: 0.9938 - lr: 8.7280e-06\n",
            "Epoch 198/2000\n",
            "658/658 [==============================] - 15s 23ms/step - loss: 0.2035 - accuracy: 0.9671 - val_loss: 0.0663 - val_accuracy: 0.9961 - lr: 7.8552e-06\n",
            "Epoch 199/2000\n",
            "658/658 [==============================] - 15s 23ms/step - loss: 0.2035 - accuracy: 0.9670 - val_loss: 0.0667 - val_accuracy: 0.9958 - lr: 7.8552e-06\n",
            "Epoch 200/2000\n",
            "658/658 [==============================] - 15s 23ms/step - loss: 0.2041 - accuracy: 0.9662 - val_loss: 0.0668 - val_accuracy: 0.9955 - lr: 7.8552e-06\n",
            "Epoch 201/2000\n",
            "658/658 [==============================] - 15s 23ms/step - loss: 0.2035 - accuracy: 0.9674 - val_loss: 0.0675 - val_accuracy: 0.9943 - lr: 7.8552e-06\n",
            "Epoch 202/2000\n",
            "658/658 [==============================] - 15s 23ms/step - loss: 0.2040 - accuracy: 0.9667 - val_loss: 0.0673 - val_accuracy: 0.9955 - lr: 7.0697e-06\n",
            "Epoch 203/2000\n",
            "658/658 [==============================] - 15s 23ms/step - loss: 0.2038 - accuracy: 0.9679 - val_loss: 0.0673 - val_accuracy: 0.9953 - lr: 7.0697e-06\n",
            "Epoch 204/2000\n",
            "658/658 [==============================] - 16s 24ms/step - loss: 0.2035 - accuracy: 0.9663 - val_loss: 0.0683 - val_accuracy: 0.9945 - lr: 7.0697e-06\n",
            "Epoch 205/2000\n",
            "658/658 [==============================] - 16s 24ms/step - loss: 0.2038 - accuracy: 0.9665 - val_loss: 0.0672 - val_accuracy: 0.9951 - lr: 6.3627e-06\n",
            "Epoch 206/2000\n",
            "658/658 [==============================] - 15s 23ms/step - loss: 0.2032 - accuracy: 0.9669 - val_loss: 0.0679 - val_accuracy: 0.9946 - lr: 6.3627e-06\n",
            "Epoch 207/2000\n",
            "658/658 [==============================] - 16s 24ms/step - loss: 0.2031 - accuracy: 0.9664 - val_loss: 0.0685 - val_accuracy: 0.9945 - lr: 6.3627e-06\n",
            "Epoch 208/2000\n",
            "658/658 [==============================] - 16s 24ms/step - loss: 0.2040 - accuracy: 0.9660 - val_loss: 0.0685 - val_accuracy: 0.9947 - lr: 5.7264e-06\n",
            "Epoch 209/2000\n",
            "658/658 [==============================] - 15s 23ms/step - loss: 0.2046 - accuracy: 0.9669 - val_loss: 0.0678 - val_accuracy: 0.9953 - lr: 5.7264e-06\n",
            "Epoch 210/2000\n",
            "658/658 [==============================] - 15s 23ms/step - loss: 0.2035 - accuracy: 0.9661 - val_loss: 0.0669 - val_accuracy: 0.9957 - lr: 5.7264e-06\n",
            "Epoch 211/2000\n",
            "658/658 [==============================] - 15s 23ms/step - loss: 0.2033 - accuracy: 0.9674 - val_loss: 0.0669 - val_accuracy: 0.9961 - lr: 5.1538e-06\n",
            "Epoch 212/2000\n",
            "658/658 [==============================] - 15s 23ms/step - loss: 0.2037 - accuracy: 0.9664 - val_loss: 0.0676 - val_accuracy: 0.9954 - lr: 5.1538e-06\n",
            "Epoch 213/2000\n",
            "658/658 [==============================] - 15s 23ms/step - loss: 0.2043 - accuracy: 0.9665 - val_loss: 0.0678 - val_accuracy: 0.9949 - lr: 5.1538e-06\n",
            "Epoch 214/2000\n",
            "658/658 [==============================] - 15s 23ms/step - loss: 0.2031 - accuracy: 0.9673 - val_loss: 0.0672 - val_accuracy: 0.9956 - lr: 4.6384e-06\n",
            "Epoch 215/2000\n",
            "658/658 [==============================] - 15s 23ms/step - loss: 0.2040 - accuracy: 0.9675 - val_loss: 0.0675 - val_accuracy: 0.9956 - lr: 4.6384e-06\n",
            "Epoch 216/2000\n",
            "658/658 [==============================] - 15s 23ms/step - loss: 0.2034 - accuracy: 0.9674 - val_loss: 0.0671 - val_accuracy: 0.9949 - lr: 4.6384e-06\n",
            "Epoch 217/2000\n",
            "658/658 [==============================] - 15s 23ms/step - loss: 0.2023 - accuracy: 0.9682 - val_loss: 0.0670 - val_accuracy: 0.9947 - lr: 4.1746e-06\n",
            "Epoch 218/2000\n",
            "658/658 [==============================] - 15s 23ms/step - loss: 0.2026 - accuracy: 0.9667 - val_loss: 0.0671 - val_accuracy: 0.9953 - lr: 4.1746e-06\n",
            "Epoch 219/2000\n",
            "658/658 [==============================] - 15s 23ms/step - loss: 0.2031 - accuracy: 0.9683 - val_loss: 0.0679 - val_accuracy: 0.9955 - lr: 4.1746e-06\n",
            "Epoch 220/2000\n",
            "658/658 [==============================] - 15s 23ms/step - loss: 0.2029 - accuracy: 0.9667 - val_loss: 0.0666 - val_accuracy: 0.9948 - lr: 3.7571e-06\n",
            "Epoch 221/2000\n",
            "658/658 [==============================] - 16s 24ms/step - loss: 0.2033 - accuracy: 0.9676 - val_loss: 0.0674 - val_accuracy: 0.9953 - lr: 3.7571e-06\n",
            "Epoch 222/2000\n",
            "658/658 [==============================] - 15s 23ms/step - loss: 0.2036 - accuracy: 0.9678 - val_loss: 0.0670 - val_accuracy: 0.9955 - lr: 3.7571e-06\n",
            "Epoch 223/2000\n",
            "658/658 [==============================] - 15s 23ms/step - loss: 0.2031 - accuracy: 0.9668 - val_loss: 0.0677 - val_accuracy: 0.9948 - lr: 3.3814e-06\n",
            "Epoch 224/2000\n",
            "658/658 [==============================] - 15s 23ms/step - loss: 0.2031 - accuracy: 0.9677 - val_loss: 0.0675 - val_accuracy: 0.9950 - lr: 3.3814e-06\n",
            "Epoch 225/2000\n",
            "658/658 [==============================] - 15s 23ms/step - loss: 0.2031 - accuracy: 0.9674 - val_loss: 0.0685 - val_accuracy: 0.9949 - lr: 3.3814e-06\n",
            "Epoch 226/2000\n",
            "658/658 [==============================] - 15s 23ms/step - loss: 0.2028 - accuracy: 0.9671 - val_loss: 0.0672 - val_accuracy: 0.9948 - lr: 3.0433e-06\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fe95f2a8510>"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xd-ishoDEnrl"
      },
      "outputs": [],
      "source": [
        "model.save('/content/drive/MyDrive/파이썬스터디 프로젝트/labeling_cnn_no2.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41253ef5-1eb6-4bf2-d43c-b72f2196e53f",
        "id": "hImsZIESEnrl"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8958"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ],
      "source": [
        "model = keras.models.load_model('/content/drive/MyDrive/파이썬스터디 프로젝트/labeling_cnn_no2.h5')\n",
        "model_eval()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "uncertainty 기반 labeling.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}