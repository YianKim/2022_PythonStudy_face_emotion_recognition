{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YianKim/2022_PythonStudy_face_emotion_recognition/blob/main/uncertainty_%EA%B8%B0%EB%B0%98_labeling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5FQpjWg4Ld6m"
      },
      "source": [
        "## 구글 드라이브\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SyTEuhg7fR9P",
        "outputId": "bd2183e2-8545-41f2-df96-25730ddddfd9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UQy7KUb6NBs-"
      },
      "source": [
        "## 라이브러리 불러오기\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "XRPQRtXGmm2W"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import PIL\n",
        "import pickle\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "from collections import Counter\n",
        "\n",
        "from keras.layers.core import Lambda\n",
        "from keras import backend as K\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.regularizers import l2\n",
        "from keras.layers import Activation\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Reshape\n",
        "from keras.layers import LSTM\n",
        "from keras import optimizers\n",
        "from keras.callbacks import ReduceLROnPlateau, EarlyStopping, TensorBoard, ModelCheckpoint\n",
        "from sklearn.metrics import *\n",
        "from keras.models import load_model\n",
        "\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xpAjYytuPDaU"
      },
      "source": [
        "## 데이터 불러오기\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "e6b1qO5dSAyP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c4091c5f-8002-427c-ce5d-b9a0a3eded24"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "40960/29515 [=========================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "26435584/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "16384/5148 [===============================================================================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n",
            "4431872/4422102 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "fashion_mnist = keras.datasets.fashion_mnist\n",
        "(data, labels), (test_data, test_labels) = fashion_mnist.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "B-e24WMOTQ4d"
      },
      "outputs": [],
      "source": [
        "train_data = data[range(10000)].reshape([10000,28,28,1])\n",
        "train_labels = labels[range(10000)].reshape([10000,1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "EhhKskDITIEm"
      },
      "outputs": [],
      "source": [
        "unlab_data = data[range(10000,60000)].reshape([50000,28,28,1])\n",
        "unlab_labels = labels[range(10000,60000)].reshape([50000,1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "W5aNLvjxVUq0"
      },
      "outputs": [],
      "source": [
        "test_data = test_data.reshape([10000,28,28,1])\n",
        "test_labels = test_labels.reshape([10000,1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "2K2wXxMmUxRV"
      },
      "outputs": [],
      "source": [
        "train_labels2 = []\n",
        "unlab_labels2 = []\n",
        "test_labels2 = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "8c9LL8JVThd-"
      },
      "outputs": [],
      "source": [
        "for i in range(10000):\n",
        "  white = [0,0,0,0,0,0,0,0,0,0]\n",
        "  white[train_labels[i][0]] = 1\n",
        "  train_labels2.append(white)\n",
        "\n",
        "for i in range(50000):\n",
        "  white = [0,0,0,0,0,0,0,0,0,0]\n",
        "  white[unlab_labels[i][0]] = 1\n",
        "  unlab_labels2.append(white)\n",
        "\n",
        "for i in range(10000):\n",
        "  white = [0,0,0,0,0,0,0,0,0,0]\n",
        "  white[test_labels[i][0]] = 1\n",
        "  test_labels2.append(white)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "iULFrchUU5nt"
      },
      "outputs": [],
      "source": [
        "train_labels = np.array(train_labels2)\n",
        "unlab_labels = np.array(unlab_labels2)\n",
        "test_labels = np.array(test_labels2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sa7KYMfrkKU5"
      },
      "source": [
        "## CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "zn3v_W8wJQ68"
      },
      "outputs": [],
      "source": [
        "def PermaDropout(rate):\n",
        "    return Lambda(lambda x: K.dropout(x, level=rate))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L5scE9yKkIZb",
        "outputId": "931fe7b5-fae8-4a39-9334-9f27244b9cb1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2000\n",
            "110/110 [==============================] - 15s 18ms/step - loss: 3.2566 - accuracy: 0.5900 - val_loss: 0.8345 - val_accuracy: 0.7040 - lr: 0.0010\n",
            "Epoch 2/2000\n",
            "110/110 [==============================] - 2s 14ms/step - loss: 0.6978 - accuracy: 0.7519 - val_loss: 0.6845 - val_accuracy: 0.7440 - lr: 0.0010\n",
            "Epoch 3/2000\n",
            "110/110 [==============================] - 1s 13ms/step - loss: 0.5848 - accuracy: 0.7866 - val_loss: 0.6348 - val_accuracy: 0.7847 - lr: 0.0010\n",
            "Epoch 4/2000\n",
            "110/110 [==============================] - 2s 14ms/step - loss: 0.5179 - accuracy: 0.8086 - val_loss: 0.6325 - val_accuracy: 0.7720 - lr: 0.0010\n",
            "Epoch 5/2000\n",
            "110/110 [==============================] - 2s 14ms/step - loss: 0.4800 - accuracy: 0.8259 - val_loss: 0.6128 - val_accuracy: 0.7900 - lr: 0.0010\n",
            "Epoch 6/2000\n",
            "110/110 [==============================] - 1s 13ms/step - loss: 0.4445 - accuracy: 0.8356 - val_loss: 0.5553 - val_accuracy: 0.8027 - lr: 0.0010\n",
            "Epoch 7/2000\n",
            "110/110 [==============================] - 1s 13ms/step - loss: 0.4360 - accuracy: 0.8380 - val_loss: 0.5891 - val_accuracy: 0.8073 - lr: 0.0010\n",
            "Epoch 8/2000\n",
            "110/110 [==============================] - 1s 14ms/step - loss: 0.3818 - accuracy: 0.8561 - val_loss: 0.6144 - val_accuracy: 0.7977 - lr: 0.0010\n",
            "Epoch 9/2000\n",
            "110/110 [==============================] - 1s 13ms/step - loss: 0.3798 - accuracy: 0.8577 - val_loss: 0.5875 - val_accuracy: 0.8047 - lr: 0.0010\n",
            "Epoch 10/2000\n",
            "110/110 [==============================] - 1s 14ms/step - loss: 0.3432 - accuracy: 0.8711 - val_loss: 0.5378 - val_accuracy: 0.8120 - lr: 9.0000e-04\n",
            "Epoch 11/2000\n",
            "110/110 [==============================] - 2s 14ms/step - loss: 0.3228 - accuracy: 0.8791 - val_loss: 0.5614 - val_accuracy: 0.8070 - lr: 9.0000e-04\n",
            "Epoch 12/2000\n",
            "110/110 [==============================] - 1s 13ms/step - loss: 0.3197 - accuracy: 0.8764 - val_loss: 0.5673 - val_accuracy: 0.8107 - lr: 9.0000e-04\n",
            "Epoch 13/2000\n",
            "110/110 [==============================] - 1s 14ms/step - loss: 0.2817 - accuracy: 0.8921 - val_loss: 0.5336 - val_accuracy: 0.8360 - lr: 9.0000e-04\n",
            "Epoch 14/2000\n",
            "110/110 [==============================] - 1s 13ms/step - loss: 0.2838 - accuracy: 0.8899 - val_loss: 0.5572 - val_accuracy: 0.8193 - lr: 9.0000e-04\n",
            "Epoch 15/2000\n",
            "110/110 [==============================] - 1s 13ms/step - loss: 0.2856 - accuracy: 0.8917 - val_loss: 0.5524 - val_accuracy: 0.8257 - lr: 9.0000e-04\n",
            "Epoch 16/2000\n",
            "110/110 [==============================] - 1s 12ms/step - loss: 0.2586 - accuracy: 0.8981 - val_loss: 0.5302 - val_accuracy: 0.8297 - lr: 9.0000e-04\n",
            "Epoch 17/2000\n",
            "110/110 [==============================] - 1s 13ms/step - loss: 0.2625 - accuracy: 0.8986 - val_loss: 0.5847 - val_accuracy: 0.8227 - lr: 9.0000e-04\n",
            "Epoch 18/2000\n",
            "110/110 [==============================] - 1s 13ms/step - loss: 0.2484 - accuracy: 0.9086 - val_loss: 0.6040 - val_accuracy: 0.8210 - lr: 9.0000e-04\n",
            "Epoch 19/2000\n",
            "110/110 [==============================] - 1s 13ms/step - loss: 0.2378 - accuracy: 0.9067 - val_loss: 0.5948 - val_accuracy: 0.8270 - lr: 9.0000e-04\n",
            "Epoch 20/2000\n",
            "110/110 [==============================] - 1s 13ms/step - loss: 0.2165 - accuracy: 0.9167 - val_loss: 0.6055 - val_accuracy: 0.8300 - lr: 8.1000e-04\n",
            "Epoch 21/2000\n",
            "110/110 [==============================] - 1s 12ms/step - loss: 0.2147 - accuracy: 0.9194 - val_loss: 0.6250 - val_accuracy: 0.8280 - lr: 8.1000e-04\n",
            "Epoch 22/2000\n",
            "110/110 [==============================] - 1s 12ms/step - loss: 0.2105 - accuracy: 0.9173 - val_loss: 0.6180 - val_accuracy: 0.8373 - lr: 8.1000e-04\n",
            "Epoch 23/2000\n",
            "110/110 [==============================] - 1s 12ms/step - loss: 0.2059 - accuracy: 0.9193 - val_loss: 0.6070 - val_accuracy: 0.8417 - lr: 7.2900e-04\n",
            "Epoch 24/2000\n",
            "110/110 [==============================] - 1s 13ms/step - loss: 0.1961 - accuracy: 0.9223 - val_loss: 0.6557 - val_accuracy: 0.8380 - lr: 7.2900e-04\n",
            "Epoch 25/2000\n",
            "110/110 [==============================] - 1s 12ms/step - loss: 0.1878 - accuracy: 0.9296 - val_loss: 0.6172 - val_accuracy: 0.8393 - lr: 7.2900e-04\n",
            "Epoch 26/2000\n",
            "110/110 [==============================] - 1s 13ms/step - loss: 0.1794 - accuracy: 0.9311 - val_loss: 0.6405 - val_accuracy: 0.8420 - lr: 6.5610e-04\n",
            "Epoch 27/2000\n",
            "110/110 [==============================] - 1s 12ms/step - loss: 0.1701 - accuracy: 0.9367 - val_loss: 0.5890 - val_accuracy: 0.8327 - lr: 6.5610e-04\n",
            "Epoch 28/2000\n",
            "110/110 [==============================] - 1s 12ms/step - loss: 0.1695 - accuracy: 0.9383 - val_loss: 0.5847 - val_accuracy: 0.8390 - lr: 6.5610e-04\n",
            "Epoch 29/2000\n",
            "110/110 [==============================] - 1s 13ms/step - loss: 0.1683 - accuracy: 0.9340 - val_loss: 0.6060 - val_accuracy: 0.8403 - lr: 5.9049e-04\n",
            "Epoch 30/2000\n",
            "110/110 [==============================] - 1s 12ms/step - loss: 0.1477 - accuracy: 0.9427 - val_loss: 0.6009 - val_accuracy: 0.8440 - lr: 5.9049e-04\n",
            "Epoch 31/2000\n",
            "110/110 [==============================] - 1s 14ms/step - loss: 0.1520 - accuracy: 0.9437 - val_loss: 0.6496 - val_accuracy: 0.8350 - lr: 5.9049e-04\n",
            "Epoch 32/2000\n",
            "110/110 [==============================] - 2s 14ms/step - loss: 0.1462 - accuracy: 0.9437 - val_loss: 0.6060 - val_accuracy: 0.8400 - lr: 5.3144e-04\n",
            "Epoch 33/2000\n",
            "110/110 [==============================] - 1s 13ms/step - loss: 0.1311 - accuracy: 0.9493 - val_loss: 0.5904 - val_accuracy: 0.8423 - lr: 5.3144e-04\n",
            "Epoch 34/2000\n",
            "110/110 [==============================] - 1s 13ms/step - loss: 0.1323 - accuracy: 0.9493 - val_loss: 0.7093 - val_accuracy: 0.8383 - lr: 5.3144e-04\n",
            "Epoch 35/2000\n",
            "110/110 [==============================] - 1s 14ms/step - loss: 0.1243 - accuracy: 0.9499 - val_loss: 0.6789 - val_accuracy: 0.8483 - lr: 4.7830e-04\n",
            "Epoch 36/2000\n",
            "110/110 [==============================] - 1s 13ms/step - loss: 0.1279 - accuracy: 0.9520 - val_loss: 0.6720 - val_accuracy: 0.8517 - lr: 4.7830e-04\n",
            "Epoch 37/2000\n",
            "110/110 [==============================] - 1s 14ms/step - loss: 0.1222 - accuracy: 0.9524 - val_loss: 0.6442 - val_accuracy: 0.8407 - lr: 4.7830e-04\n",
            "Epoch 38/2000\n",
            "110/110 [==============================] - 2s 14ms/step - loss: 0.1106 - accuracy: 0.9579 - val_loss: 0.6864 - val_accuracy: 0.8417 - lr: 4.3047e-04\n",
            "Epoch 39/2000\n",
            "110/110 [==============================] - 2s 14ms/step - loss: 0.1131 - accuracy: 0.9561 - val_loss: 0.6177 - val_accuracy: 0.8567 - lr: 4.3047e-04\n",
            "Epoch 40/2000\n",
            "110/110 [==============================] - 2s 14ms/step - loss: 0.1194 - accuracy: 0.9519 - val_loss: 0.6810 - val_accuracy: 0.8523 - lr: 4.3047e-04\n",
            "Epoch 41/2000\n",
            "110/110 [==============================] - 1s 13ms/step - loss: 0.0914 - accuracy: 0.9634 - val_loss: 0.6817 - val_accuracy: 0.8503 - lr: 3.8742e-04\n",
            "Epoch 42/2000\n",
            "110/110 [==============================] - 2s 16ms/step - loss: 0.0946 - accuracy: 0.9627 - val_loss: 0.6793 - val_accuracy: 0.8527 - lr: 3.8742e-04\n",
            "Epoch 43/2000\n",
            "110/110 [==============================] - 2s 18ms/step - loss: 0.0982 - accuracy: 0.9616 - val_loss: 0.7570 - val_accuracy: 0.8460 - lr: 3.8742e-04\n",
            "Epoch 44/2000\n",
            "110/110 [==============================] - 2s 14ms/step - loss: 0.0878 - accuracy: 0.9661 - val_loss: 0.7277 - val_accuracy: 0.8473 - lr: 3.4868e-04\n",
            "Epoch 45/2000\n",
            "110/110 [==============================] - 1s 13ms/step - loss: 0.0902 - accuracy: 0.9649 - val_loss: 0.7174 - val_accuracy: 0.8530 - lr: 3.4868e-04\n",
            "Epoch 46/2000\n",
            "110/110 [==============================] - 1s 13ms/step - loss: 0.0901 - accuracy: 0.9666 - val_loss: 0.6406 - val_accuracy: 0.8543 - lr: 3.4868e-04\n",
            "Epoch 47/2000\n",
            "110/110 [==============================] - 2s 14ms/step - loss: 0.0849 - accuracy: 0.9704 - val_loss: 0.6887 - val_accuracy: 0.8543 - lr: 3.1381e-04\n",
            "Epoch 48/2000\n",
            "110/110 [==============================] - 2s 14ms/step - loss: 0.0833 - accuracy: 0.9666 - val_loss: 0.7294 - val_accuracy: 0.8540 - lr: 3.1381e-04\n",
            "Epoch 49/2000\n",
            "110/110 [==============================] - 1s 14ms/step - loss: 0.0758 - accuracy: 0.9724 - val_loss: 0.7458 - val_accuracy: 0.8483 - lr: 3.1381e-04\n",
            "Epoch 50/2000\n",
            "110/110 [==============================] - 1s 14ms/step - loss: 0.0778 - accuracy: 0.9684 - val_loss: 0.6981 - val_accuracy: 0.8473 - lr: 2.8243e-04\n",
            "Epoch 51/2000\n",
            "110/110 [==============================] - 1s 13ms/step - loss: 0.0762 - accuracy: 0.9710 - val_loss: 0.7267 - val_accuracy: 0.8517 - lr: 2.8243e-04\n",
            "Epoch 52/2000\n",
            "110/110 [==============================] - 1s 13ms/step - loss: 0.0716 - accuracy: 0.9714 - val_loss: 0.7616 - val_accuracy: 0.8480 - lr: 2.8243e-04\n",
            "Epoch 53/2000\n",
            "110/110 [==============================] - 2s 14ms/step - loss: 0.0729 - accuracy: 0.9733 - val_loss: 0.7640 - val_accuracy: 0.8520 - lr: 2.5419e-04\n",
            "Epoch 54/2000\n",
            "110/110 [==============================] - 1s 13ms/step - loss: 0.0706 - accuracy: 0.9717 - val_loss: 0.7776 - val_accuracy: 0.8450 - lr: 2.5419e-04\n",
            "Epoch 55/2000\n",
            "110/110 [==============================] - 1s 13ms/step - loss: 0.0735 - accuracy: 0.9734 - val_loss: 0.7880 - val_accuracy: 0.8473 - lr: 2.5419e-04\n",
            "Epoch 56/2000\n",
            "110/110 [==============================] - 1s 13ms/step - loss: 0.0711 - accuracy: 0.9731 - val_loss: 0.7332 - val_accuracy: 0.8470 - lr: 2.2877e-04\n",
            "Epoch 57/2000\n",
            "110/110 [==============================] - 1s 14ms/step - loss: 0.0701 - accuracy: 0.9759 - val_loss: 0.7378 - val_accuracy: 0.8583 - lr: 2.2877e-04\n",
            "Epoch 58/2000\n",
            "110/110 [==============================] - 1s 14ms/step - loss: 0.0674 - accuracy: 0.9736 - val_loss: 0.7819 - val_accuracy: 0.8543 - lr: 2.2877e-04\n",
            "Epoch 59/2000\n",
            "110/110 [==============================] - 1s 13ms/step - loss: 0.0710 - accuracy: 0.9729 - val_loss: 0.7577 - val_accuracy: 0.8500 - lr: 2.0589e-04\n",
            "Epoch 60/2000\n",
            "110/110 [==============================] - 2s 14ms/step - loss: 0.0751 - accuracy: 0.9726 - val_loss: 0.8253 - val_accuracy: 0.8533 - lr: 2.0589e-04\n",
            "Epoch 61/2000\n",
            "110/110 [==============================] - 1s 13ms/step - loss: 0.0649 - accuracy: 0.9750 - val_loss: 0.7261 - val_accuracy: 0.8547 - lr: 2.0589e-04\n",
            "Epoch 62/2000\n",
            "110/110 [==============================] - 1s 13ms/step - loss: 0.0552 - accuracy: 0.9781 - val_loss: 0.7736 - val_accuracy: 0.8570 - lr: 1.8530e-04\n",
            "Epoch 63/2000\n",
            "110/110 [==============================] - 1s 13ms/step - loss: 0.0615 - accuracy: 0.9767 - val_loss: 0.7714 - val_accuracy: 0.8527 - lr: 1.8530e-04\n",
            "Epoch 64/2000\n",
            "110/110 [==============================] - 1s 13ms/step - loss: 0.0569 - accuracy: 0.9784 - val_loss: 0.7658 - val_accuracy: 0.8527 - lr: 1.8530e-04\n",
            "Epoch 65/2000\n",
            "110/110 [==============================] - 1s 13ms/step - loss: 0.0624 - accuracy: 0.9766 - val_loss: 0.7685 - val_accuracy: 0.8603 - lr: 1.6677e-04\n",
            "Epoch 66/2000\n",
            "110/110 [==============================] - 2s 14ms/step - loss: 0.0553 - accuracy: 0.9779 - val_loss: 0.7504 - val_accuracy: 0.8597 - lr: 1.6677e-04\n",
            "Epoch 67/2000\n",
            "110/110 [==============================] - 1s 13ms/step - loss: 0.0495 - accuracy: 0.9799 - val_loss: 0.8052 - val_accuracy: 0.8660 - lr: 1.6677e-04\n",
            "Epoch 68/2000\n",
            "110/110 [==============================] - 2s 14ms/step - loss: 0.0559 - accuracy: 0.9783 - val_loss: 0.7879 - val_accuracy: 0.8527 - lr: 1.5009e-04\n",
            "Epoch 69/2000\n",
            "110/110 [==============================] - 1s 13ms/step - loss: 0.0543 - accuracy: 0.9781 - val_loss: 0.7542 - val_accuracy: 0.8553 - lr: 1.5009e-04\n",
            "Epoch 70/2000\n",
            "110/110 [==============================] - 2s 14ms/step - loss: 0.0478 - accuracy: 0.9841 - val_loss: 0.8305 - val_accuracy: 0.8553 - lr: 1.5009e-04\n",
            "Epoch 71/2000\n",
            "110/110 [==============================] - 2s 14ms/step - loss: 0.0491 - accuracy: 0.9806 - val_loss: 0.8306 - val_accuracy: 0.8573 - lr: 1.3509e-04\n",
            "Epoch 72/2000\n",
            "110/110 [==============================] - 1s 14ms/step - loss: 0.0459 - accuracy: 0.9823 - val_loss: 0.7824 - val_accuracy: 0.8643 - lr: 1.3509e-04\n",
            "Epoch 73/2000\n",
            "110/110 [==============================] - 1s 14ms/step - loss: 0.0542 - accuracy: 0.9793 - val_loss: 0.8285 - val_accuracy: 0.8557 - lr: 1.3509e-04\n",
            "Epoch 74/2000\n",
            "110/110 [==============================] - 1s 13ms/step - loss: 0.0505 - accuracy: 0.9799 - val_loss: 0.8358 - val_accuracy: 0.8560 - lr: 1.2158e-04\n",
            "Epoch 75/2000\n",
            "110/110 [==============================] - 1s 13ms/step - loss: 0.0430 - accuracy: 0.9826 - val_loss: 0.8360 - val_accuracy: 0.8543 - lr: 1.2158e-04\n",
            "Epoch 76/2000\n",
            "110/110 [==============================] - 1s 13ms/step - loss: 0.0429 - accuracy: 0.9823 - val_loss: 0.8155 - val_accuracy: 0.8600 - lr: 1.2158e-04\n",
            "Epoch 77/2000\n",
            "110/110 [==============================] - 1s 12ms/step - loss: 0.0519 - accuracy: 0.9813 - val_loss: 0.7945 - val_accuracy: 0.8547 - lr: 1.0942e-04\n",
            "Epoch 78/2000\n",
            "110/110 [==============================] - 1s 13ms/step - loss: 0.0439 - accuracy: 0.9833 - val_loss: 0.7928 - val_accuracy: 0.8620 - lr: 1.0942e-04\n",
            "Epoch 79/2000\n",
            "110/110 [==============================] - 1s 14ms/step - loss: 0.0444 - accuracy: 0.9826 - val_loss: 0.8409 - val_accuracy: 0.8617 - lr: 1.0942e-04\n",
            "Epoch 80/2000\n",
            "110/110 [==============================] - 1s 13ms/step - loss: 0.0473 - accuracy: 0.9810 - val_loss: 0.8089 - val_accuracy: 0.8650 - lr: 9.8477e-05\n",
            "Epoch 81/2000\n",
            "110/110 [==============================] - 1s 13ms/step - loss: 0.0455 - accuracy: 0.9814 - val_loss: 0.7492 - val_accuracy: 0.8637 - lr: 9.8477e-05\n",
            "Epoch 82/2000\n",
            "110/110 [==============================] - 2s 14ms/step - loss: 0.0406 - accuracy: 0.9864 - val_loss: 0.8131 - val_accuracy: 0.8623 - lr: 9.8477e-05\n",
            "Epoch 83/2000\n",
            "110/110 [==============================] - 2s 14ms/step - loss: 0.0392 - accuracy: 0.9856 - val_loss: 0.8182 - val_accuracy: 0.8653 - lr: 8.8629e-05\n",
            "Epoch 84/2000\n",
            "110/110 [==============================] - 2s 14ms/step - loss: 0.0418 - accuracy: 0.9840 - val_loss: 0.8678 - val_accuracy: 0.8617 - lr: 8.8629e-05\n",
            "Epoch 85/2000\n",
            "110/110 [==============================] - 1s 13ms/step - loss: 0.0366 - accuracy: 0.9873 - val_loss: 0.8462 - val_accuracy: 0.8613 - lr: 8.8629e-05\n",
            "Epoch 86/2000\n",
            "110/110 [==============================] - 1s 13ms/step - loss: 0.0418 - accuracy: 0.9854 - val_loss: 0.8462 - val_accuracy: 0.8607 - lr: 7.9766e-05\n",
            "Epoch 87/2000\n",
            "110/110 [==============================] - 1s 13ms/step - loss: 0.0403 - accuracy: 0.9839 - val_loss: 0.9078 - val_accuracy: 0.8540 - lr: 7.9766e-05\n",
            "Epoch 88/2000\n",
            "110/110 [==============================] - 1s 13ms/step - loss: 0.0387 - accuracy: 0.9866 - val_loss: 0.8438 - val_accuracy: 0.8603 - lr: 7.9766e-05\n",
            "Epoch 89/2000\n",
            "110/110 [==============================] - 1s 13ms/step - loss: 0.0427 - accuracy: 0.9833 - val_loss: 0.8210 - val_accuracy: 0.8673 - lr: 7.1790e-05\n",
            "Epoch 90/2000\n",
            "110/110 [==============================] - 2s 14ms/step - loss: 0.0356 - accuracy: 0.9867 - val_loss: 0.8437 - val_accuracy: 0.8607 - lr: 7.1790e-05\n",
            "Epoch 91/2000\n",
            "110/110 [==============================] - 2s 14ms/step - loss: 0.0346 - accuracy: 0.9864 - val_loss: 0.8283 - val_accuracy: 0.8637 - lr: 7.1790e-05\n",
            "Epoch 92/2000\n",
            "110/110 [==============================] - 2s 14ms/step - loss: 0.0353 - accuracy: 0.9879 - val_loss: 0.8993 - val_accuracy: 0.8567 - lr: 6.4611e-05\n",
            "Epoch 93/2000\n",
            "110/110 [==============================] - 1s 13ms/step - loss: 0.0391 - accuracy: 0.9843 - val_loss: 0.8945 - val_accuracy: 0.8587 - lr: 6.4611e-05\n",
            "Epoch 94/2000\n",
            "110/110 [==============================] - 1s 13ms/step - loss: 0.0360 - accuracy: 0.9864 - val_loss: 0.7804 - val_accuracy: 0.8637 - lr: 6.4611e-05\n",
            "Epoch 95/2000\n",
            "110/110 [==============================] - 1s 13ms/step - loss: 0.0409 - accuracy: 0.9844 - val_loss: 0.8294 - val_accuracy: 0.8587 - lr: 5.8150e-05\n",
            "Epoch 96/2000\n",
            "110/110 [==============================] - 1s 13ms/step - loss: 0.0313 - accuracy: 0.9867 - val_loss: 0.8909 - val_accuracy: 0.8650 - lr: 5.8150e-05\n",
            "Epoch 97/2000\n",
            "110/110 [==============================] - 2s 14ms/step - loss: 0.0338 - accuracy: 0.9874 - val_loss: 0.8657 - val_accuracy: 0.8677 - lr: 5.8150e-05\n",
            "Epoch 98/2000\n",
            "110/110 [==============================] - 1s 13ms/step - loss: 0.0350 - accuracy: 0.9874 - val_loss: 0.8900 - val_accuracy: 0.8623 - lr: 5.2335e-05\n",
            "Epoch 99/2000\n",
            "110/110 [==============================] - 1s 13ms/step - loss: 0.0348 - accuracy: 0.9860 - val_loss: 0.8767 - val_accuracy: 0.8593 - lr: 5.2335e-05\n",
            "Epoch 100/2000\n",
            "110/110 [==============================] - 1s 14ms/step - loss: 0.0324 - accuracy: 0.9881 - val_loss: 0.9359 - val_accuracy: 0.8587 - lr: 5.2335e-05\n",
            "Epoch 101/2000\n",
            "110/110 [==============================] - 1s 13ms/step - loss: 0.0314 - accuracy: 0.9877 - val_loss: 0.8649 - val_accuracy: 0.8683 - lr: 4.7101e-05\n",
            "Epoch 102/2000\n",
            "110/110 [==============================] - 1s 13ms/step - loss: 0.0345 - accuracy: 0.9870 - val_loss: 0.9242 - val_accuracy: 0.8543 - lr: 4.7101e-05\n",
            "Epoch 103/2000\n",
            "110/110 [==============================] - 1s 13ms/step - loss: 0.0367 - accuracy: 0.9850 - val_loss: 0.8090 - val_accuracy: 0.8633 - lr: 4.7101e-05\n",
            "Epoch 104/2000\n",
            "110/110 [==============================] - 1s 13ms/step - loss: 0.0370 - accuracy: 0.9860 - val_loss: 0.8064 - val_accuracy: 0.8633 - lr: 4.2391e-05\n",
            "Epoch 105/2000\n",
            "110/110 [==============================] - 1s 13ms/step - loss: 0.0344 - accuracy: 0.9874 - val_loss: 0.8787 - val_accuracy: 0.8550 - lr: 4.2391e-05\n",
            "Epoch 106/2000\n",
            "110/110 [==============================] - 1s 13ms/step - loss: 0.0309 - accuracy: 0.9886 - val_loss: 0.8220 - val_accuracy: 0.8723 - lr: 4.2391e-05\n",
            "Epoch 107/2000\n",
            "110/110 [==============================] - 2s 14ms/step - loss: 0.0349 - accuracy: 0.9881 - val_loss: 0.8593 - val_accuracy: 0.8603 - lr: 3.8152e-05\n",
            "Epoch 108/2000\n",
            "110/110 [==============================] - 2s 14ms/step - loss: 0.0327 - accuracy: 0.9876 - val_loss: 0.8626 - val_accuracy: 0.8563 - lr: 3.8152e-05\n",
            "Epoch 109/2000\n",
            "110/110 [==============================] - 1s 13ms/step - loss: 0.0330 - accuracy: 0.9867 - val_loss: 0.8304 - val_accuracy: 0.8690 - lr: 3.8152e-05\n",
            "Epoch 110/2000\n",
            "110/110 [==============================] - 2s 14ms/step - loss: 0.0330 - accuracy: 0.9877 - val_loss: 0.8940 - val_accuracy: 0.8640 - lr: 3.4337e-05\n",
            "Epoch 111/2000\n",
            "110/110 [==============================] - 2s 14ms/step - loss: 0.0286 - accuracy: 0.9894 - val_loss: 0.8802 - val_accuracy: 0.8670 - lr: 3.4337e-05\n",
            "Epoch 112/2000\n",
            "110/110 [==============================] - 1s 13ms/step - loss: 0.0335 - accuracy: 0.9870 - val_loss: 0.8800 - val_accuracy: 0.8620 - lr: 3.4337e-05\n",
            "Epoch 113/2000\n",
            "110/110 [==============================] - 1s 13ms/step - loss: 0.0303 - accuracy: 0.9889 - val_loss: 0.8235 - val_accuracy: 0.8663 - lr: 3.0903e-05\n",
            "Epoch 114/2000\n",
            "110/110 [==============================] - 1s 13ms/step - loss: 0.0309 - accuracy: 0.9883 - val_loss: 0.9380 - val_accuracy: 0.8690 - lr: 3.0903e-05\n",
            "Epoch 115/2000\n",
            "110/110 [==============================] - 1s 13ms/step - loss: 0.0307 - accuracy: 0.9880 - val_loss: 0.9026 - val_accuracy: 0.8717 - lr: 3.0903e-05\n",
            "Epoch 116/2000\n",
            "110/110 [==============================] - 1s 13ms/step - loss: 0.0310 - accuracy: 0.9880 - val_loss: 0.8441 - val_accuracy: 0.8673 - lr: 2.7813e-05\n",
            "Epoch 117/2000\n",
            "110/110 [==============================] - 1s 13ms/step - loss: 0.0367 - accuracy: 0.9880 - val_loss: 0.8649 - val_accuracy: 0.8640 - lr: 2.7813e-05\n",
            "Epoch 118/2000\n",
            "110/110 [==============================] - 1s 13ms/step - loss: 0.0270 - accuracy: 0.9900 - val_loss: 0.8914 - val_accuracy: 0.8633 - lr: 2.7813e-05\n",
            "Epoch 119/2000\n",
            "110/110 [==============================] - 1s 14ms/step - loss: 0.0308 - accuracy: 0.9873 - val_loss: 0.8249 - val_accuracy: 0.8750 - lr: 2.5032e-05\n",
            "Epoch 120/2000\n",
            "110/110 [==============================] - 2s 14ms/step - loss: 0.0329 - accuracy: 0.9879 - val_loss: 0.9194 - val_accuracy: 0.8607 - lr: 2.5032e-05\n",
            "Epoch 121/2000\n",
            "110/110 [==============================] - 1s 13ms/step - loss: 0.0325 - accuracy: 0.9874 - val_loss: 0.8637 - val_accuracy: 0.8660 - lr: 2.5032e-05\n",
            "Epoch 122/2000\n",
            "110/110 [==============================] - 1s 13ms/step - loss: 0.0301 - accuracy: 0.9903 - val_loss: 0.8713 - val_accuracy: 0.8577 - lr: 2.2528e-05\n",
            "Epoch 123/2000\n",
            "110/110 [==============================] - 1s 13ms/step - loss: 0.0320 - accuracy: 0.9889 - val_loss: 0.8556 - val_accuracy: 0.8627 - lr: 2.2528e-05\n",
            "Epoch 124/2000\n",
            "110/110 [==============================] - 1s 13ms/step - loss: 0.0304 - accuracy: 0.9889 - val_loss: 0.8479 - val_accuracy: 0.8693 - lr: 2.2528e-05\n",
            "Epoch 125/2000\n",
            "110/110 [==============================] - 1s 14ms/step - loss: 0.0269 - accuracy: 0.9900 - val_loss: 0.8246 - val_accuracy: 0.8703 - lr: 2.0276e-05\n",
            "Epoch 126/2000\n",
            "110/110 [==============================] - 1s 13ms/step - loss: 0.0274 - accuracy: 0.9914 - val_loss: 0.9198 - val_accuracy: 0.8600 - lr: 2.0276e-05\n",
            "Epoch 127/2000\n",
            "110/110 [==============================] - 2s 14ms/step - loss: 0.0298 - accuracy: 0.9893 - val_loss: 0.9342 - val_accuracy: 0.8623 - lr: 2.0276e-05\n",
            "Epoch 128/2000\n",
            "110/110 [==============================] - 1s 13ms/step - loss: 0.0308 - accuracy: 0.9874 - val_loss: 0.8591 - val_accuracy: 0.8650 - lr: 1.8248e-05\n",
            "Epoch 129/2000\n",
            "110/110 [==============================] - 2s 14ms/step - loss: 0.0292 - accuracy: 0.9896 - val_loss: 0.8816 - val_accuracy: 0.8683 - lr: 1.8248e-05\n",
            "Epoch 130/2000\n",
            "110/110 [==============================] - 1s 13ms/step - loss: 0.0298 - accuracy: 0.9886 - val_loss: 0.8437 - val_accuracy: 0.8673 - lr: 1.8248e-05\n",
            "Epoch 131/2000\n",
            "110/110 [==============================] - 2s 14ms/step - loss: 0.0300 - accuracy: 0.9880 - val_loss: 0.8395 - val_accuracy: 0.8633 - lr: 1.6423e-05\n",
            "Epoch 132/2000\n",
            "110/110 [==============================] - 1s 13ms/step - loss: 0.0274 - accuracy: 0.9891 - val_loss: 0.9264 - val_accuracy: 0.8673 - lr: 1.6423e-05\n",
            "Epoch 133/2000\n",
            "110/110 [==============================] - 2s 14ms/step - loss: 0.0328 - accuracy: 0.9891 - val_loss: 0.8726 - val_accuracy: 0.8627 - lr: 1.6423e-05\n",
            "Epoch 134/2000\n",
            "110/110 [==============================] - 1s 13ms/step - loss: 0.0295 - accuracy: 0.9891 - val_loss: 0.8847 - val_accuracy: 0.8673 - lr: 1.4781e-05\n",
            "Epoch 135/2000\n",
            "110/110 [==============================] - 2s 14ms/step - loss: 0.0298 - accuracy: 0.9886 - val_loss: 0.9158 - val_accuracy: 0.8623 - lr: 1.4781e-05\n",
            "Epoch 136/2000\n",
            "110/110 [==============================] - 2s 14ms/step - loss: 0.0363 - accuracy: 0.9863 - val_loss: 0.9191 - val_accuracy: 0.8600 - lr: 1.4781e-05\n",
            "Epoch 137/2000\n",
            "110/110 [==============================] - 2s 14ms/step - loss: 0.0283 - accuracy: 0.9887 - val_loss: 0.8277 - val_accuracy: 0.8707 - lr: 1.3303e-05\n",
            "Epoch 138/2000\n",
            "110/110 [==============================] - 2s 14ms/step - loss: 0.0246 - accuracy: 0.9901 - val_loss: 0.8798 - val_accuracy: 0.8643 - lr: 1.3303e-05\n",
            "Epoch 139/2000\n",
            "110/110 [==============================] - 2s 15ms/step - loss: 0.0308 - accuracy: 0.9881 - val_loss: 0.8619 - val_accuracy: 0.8657 - lr: 1.3303e-05\n",
            "Epoch 140/2000\n",
            "110/110 [==============================] - 2s 14ms/step - loss: 0.0286 - accuracy: 0.9879 - val_loss: 0.9436 - val_accuracy: 0.8650 - lr: 1.1973e-05\n",
            "Epoch 141/2000\n",
            "110/110 [==============================] - 2s 14ms/step - loss: 0.0319 - accuracy: 0.9876 - val_loss: 0.8645 - val_accuracy: 0.8640 - lr: 1.1973e-05\n",
            "Epoch 142/2000\n",
            "110/110 [==============================] - 2s 14ms/step - loss: 0.0277 - accuracy: 0.9894 - val_loss: 0.8877 - val_accuracy: 0.8713 - lr: 1.1973e-05\n",
            "Epoch 143/2000\n",
            "110/110 [==============================] - 1s 13ms/step - loss: 0.0257 - accuracy: 0.9914 - val_loss: 0.8854 - val_accuracy: 0.8637 - lr: 1.0775e-05\n",
            "Epoch 144/2000\n",
            "110/110 [==============================] - 1s 13ms/step - loss: 0.0273 - accuracy: 0.9889 - val_loss: 0.9329 - val_accuracy: 0.8497 - lr: 1.0775e-05\n",
            "Epoch 145/2000\n",
            "110/110 [==============================] - 2s 14ms/step - loss: 0.0251 - accuracy: 0.9897 - val_loss: 0.8784 - val_accuracy: 0.8637 - lr: 1.0775e-05\n",
            "Epoch 146/2000\n",
            "110/110 [==============================] - 2s 14ms/step - loss: 0.0276 - accuracy: 0.9894 - val_loss: 0.9001 - val_accuracy: 0.8673 - lr: 9.6977e-06\n",
            "Epoch 147/2000\n",
            "110/110 [==============================] - 1s 14ms/step - loss: 0.0288 - accuracy: 0.9894 - val_loss: 0.9058 - val_accuracy: 0.8560 - lr: 9.6977e-06\n",
            "Epoch 148/2000\n",
            "110/110 [==============================] - 2s 14ms/step - loss: 0.0247 - accuracy: 0.9909 - val_loss: 0.9580 - val_accuracy: 0.8583 - lr: 9.6977e-06\n",
            "Epoch 149/2000\n",
            "110/110 [==============================] - 1s 13ms/step - loss: 0.0228 - accuracy: 0.9931 - val_loss: 0.9599 - val_accuracy: 0.8560 - lr: 8.7280e-06\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f3ec06f6a10>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "#######HYPERPARAMATERS###########\n",
        "epochs = 2000\n",
        "batch_size = 64\n",
        "learning_rate = 0.001\n",
        "#################################\n",
        "  \n",
        "model = Sequential()\n",
        "    \n",
        "model.add(Conv2D(32, kernel_size = (3,3), input_shape=(28,28,1), activation='relu'))\n",
        "model.add(Conv2D(64,(3,3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=2))\n",
        "model.add(PermaDropout(0.5))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(PermaDropout(0.5))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "adam = keras.optimizers.Adam(learning_rate)\n",
        "model.compile(optimizer = adam, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
        "    \n",
        "# print(model.summary())\n",
        "\n",
        "lr_reducer = ReduceLROnPlateau(monitor='val_loss', factor=0.9, patience=3)\n",
        "early_stopper = EarlyStopping(monitor='val_accuracy', min_delta=0, patience=30, mode='auto')\n",
        "checkpointer = ModelCheckpoint('weights.hd5', monitor='val_loss', verbose=1, save_best_only=True)\n",
        "\n",
        "model.fit(\n",
        "          train_data,\n",
        "          train_labels,\n",
        "          epochs = epochs,\n",
        "          batch_size = batch_size,\n",
        "          validation_split = 0.3,\n",
        "          shuffle = True,\n",
        "          callbacks=[lr_reducer, early_stopper]\n",
        "          )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "LVOc3hYIkXrl"
      },
      "outputs": [],
      "source": [
        "model.save('/content/drive/MyDrive/파이썬스터디 프로젝트/labeling_cnn.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "n5D8i_BCkdjS"
      },
      "outputs": [],
      "source": [
        "model = keras.models.load_model('/content/drive/MyDrive/파이썬스터디 프로젝트/labeling_cnn.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TD8ppILhFUrz"
      },
      "source": [
        "## 모델 결과"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "7Ljx2EWA2v2n"
      },
      "outputs": [],
      "source": [
        "def model_eval():\n",
        "  pred_mu = model.predict(test_data)\n",
        "  for i in range(1, 30):\n",
        "    pred_mu += model.predict(test_data)\n",
        "  pred_mu = pred_mu/30\n",
        "  predicted_test_labels = np.argmax(pred_mu, axis=1)\n",
        "  return(accuracy_score(np.argmax(test_labels, axis=1), predicted_test_labels))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OzhQw9NOWjl3",
        "outputId": "c933a4a8-fb29-48cb-c7bc-41e261f0e9af"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8871"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "model = keras.models.load_model('/content/drive/MyDrive/파이썬스터디 프로젝트/labeling_cnn.h5')\n",
        "model_eval()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rcbs04885lTu"
      },
      "source": [
        "# 라벨링"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mAtfoQKLZDJC"
      },
      "source": [
        "## 라벨링; 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "GKJgmFGWhlfl"
      },
      "outputs": [],
      "source": [
        "model = keras.models.load_model('/content/drive/MyDrive/파이썬스터디 프로젝트/labeling_cnn.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J_Jb5VX9ZC3y",
        "outputId": "a89c4cc0-b2b3-4cc6-d54a-cc962fa9de87"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 30/30 [02:25<00:00,  4.83s/it]\n",
            "100%|██████████| 50000/50000 [00:10<00:00, 4597.56it/s]\n"
          ]
        }
      ],
      "source": [
        "# Vars : 분산들\n",
        "# Outs : 결과 값들\n",
        "\n",
        "Vars = []\n",
        "Outs = []\n",
        "\n",
        "temp1 = []\n",
        "\n",
        "for i in tqdm(range(30)):\n",
        "  temp1.append(model.predict(unlab_data))\n",
        "\n",
        "for j in tqdm(range(unlab_data.shape[0])):\n",
        "\n",
        "  temp2 = np.array([0,0,0,0,0,0,0,0,0,0], 'float32')\n",
        "  \n",
        "  for i in range(30):\n",
        "    temp2 += temp1[i][j]\n",
        "  Outs.append(temp2/30)\n",
        "  \n",
        "  outputs=[]\n",
        "\n",
        "  for i in range(30):\n",
        "    outputs.append(temp1[i][j][np.argmax(temp2)])\n",
        "  Vars.append(np.var(outputs))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "-NnAVIXTXlAa"
      },
      "outputs": [],
      "source": [
        "Outs = np.array(Outs)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "class마다 균등하게 선택"
      ],
      "metadata": {
        "id": "XxIFHtGqAF9B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Counter(np.argmax(unlab_labels, axis=1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IGGGKCzvAiZb",
        "outputId": "cc011422-b988-419e-9f76-057934baf0be"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({0: 5058,\n",
              "         1: 4973,\n",
              "         2: 4984,\n",
              "         3: 4981,\n",
              "         4: 5026,\n",
              "         5: 5011,\n",
              "         6: 4979,\n",
              "         7: 4978,\n",
              "         8: 5010,\n",
              "         9: 5000})"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# upper bound of variance?\n",
        "\n",
        "UB = []\n",
        "\n",
        "for h in range(10):\n",
        "  classvars = []\n",
        "  for i in tqdm(range(50000)):\n",
        "    if np.argmax(unlab_labels, axis=1).tolist()[i]==h:\n",
        "      classvars.append(Vars[i])\n",
        "  UB.append(np.percentile(classvars, 50))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uDAwvSCVBLA4",
        "outputId": "ca73df6d-ce58-4d07-8ae4-5d951448377e"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50000/50000 [01:31<00:00, 546.11it/s]\n",
            "100%|██████████| 50000/50000 [01:31<00:00, 546.94it/s]\n",
            "100%|██████████| 50000/50000 [01:30<00:00, 554.81it/s]\n",
            "100%|██████████| 50000/50000 [01:30<00:00, 555.47it/s]\n",
            "100%|██████████| 50000/50000 [01:31<00:00, 547.13it/s]\n",
            "100%|██████████| 50000/50000 [01:30<00:00, 552.03it/s]\n",
            "100%|██████████| 50000/50000 [01:35<00:00, 523.56it/s]\n",
            "100%|██████████| 50000/50000 [01:30<00:00, 553.11it/s]\n",
            "100%|██████████| 50000/50000 [01:32<00:00, 542.91it/s]\n",
            "100%|██████████| 50000/50000 [01:31<00:00, 544.48it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "6BUHoKvtkJ37"
      },
      "outputs": [],
      "source": [
        "lowvars = []\n",
        "ind = 0 \n",
        "\n",
        "for i in Vars:\n",
        "  if i <= UB[np.argmax(unlab_labels, axis=1)[ind]]:\n",
        "    lowvars.append(ind)\n",
        "  ind += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "9WhEDezq362P"
      },
      "outputs": [],
      "source": [
        "highvars = []\n",
        "for i in range(unlab_data.shape[0]):\n",
        "  if i not in lowvars:\n",
        "    highvars.append(i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0uSdhE1VmF5a",
        "outputId": "168fda56-2b09-40da-8a3d-e35b7188dcec"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8926657602175478"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "# 같은 길이의 랜덤하게 고른 data들에 모델로 label 부여 후 정확도 측정\n",
        "randomindx = random.sample(range(50000), len(lowvars))\n",
        "accuracy_score(np.argmax(np.array(Outs)[randomindx], axis=1), np.argmax(unlab_labels[randomindx], axis=1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gtEPD5p5kM-z",
        "outputId": "25e1f61e-ff06-45f0-8dfd-f12e365c8bac"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.972726545629049"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "# 저분산의 data들만 모아서 모델로 label 부여 후 정확도 측정 : 95% 이상\n",
        "accuracy_score(np.argmax(np.array(Outs)[lowvars], axis=1), np.argmax(unlab_labels[lowvars], axis=1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "C2ab4GUWwe30"
      },
      "outputs": [],
      "source": [
        "train_data_1 = np.concatenate([train_data, unlab_data[lowvars]], axis=0)\n",
        "train_labels_1 = np.concatenate([train_labels, Outs[lowvars]], axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "1xahhoBY8mKc"
      },
      "outputs": [],
      "source": [
        "shufindx = random.sample(range(train_data_1.shape[0]),train_data_1.shape[0])\n",
        "train_data_1 = train_data_1[shufindx]\n",
        "train_labels_1 = train_labels_1[shufindx]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_2 = np.concatenate([train_data, unlab_data[randomindx]], axis=0)\n",
        "train_labels_2 = np.concatenate([train_labels, Outs[randomindx]], axis=0)"
      ],
      "metadata": {
        "id": "7gQWZXNojDvb"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shufindx = random.sample(range(train_data_2.shape[0]),train_data_2.shape[0])\n",
        "train_data_2 = train_data_2[shufindx]\n",
        "train_labels_2 = train_labels_2[shufindx]"
      ],
      "metadata": {
        "id": "4tdOxYBQjFGT"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "_t9J8vlJ5TDO"
      },
      "outputs": [],
      "source": [
        "# unlab_data = unlab_data[highvars]\n",
        "# unlab_labels = unlab_labels[highvars]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Counter(np.argmax(train_labels_1, axis=1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z7Jq-n0L8diD",
        "outputId": "bf703f5c-252e-4f89-ee2b-2edbd7e107a5"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({0: 3629,\n",
              "         1: 3523,\n",
              "         2: 3613,\n",
              "         3: 3633,\n",
              "         4: 3466,\n",
              "         5: 3491,\n",
              "         6: 3130,\n",
              "         7: 3506,\n",
              "         8: 3506,\n",
              "         9: 3509})"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Counter(np.argmax(train_labels_2, axis=1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4CLpAKvu8kD6",
        "outputId": "8c859917-03b8-485c-a03d-57e9f59fa1bf"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({0: 3447,\n",
              "         1: 3439,\n",
              "         2: 3556,\n",
              "         3: 3547,\n",
              "         4: 3489,\n",
              "         5: 3416,\n",
              "         6: 3457,\n",
              "         7: 3600,\n",
              "         8: 3530,\n",
              "         9: 3525})"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bOtFA9fr5oDF"
      },
      "source": [
        "## 모델링\n",
        "\n",
        "간단한 모델에서 받은 지식를 복잡한 모델에서 학습 \n",
        "\n",
        "uncertainty aware data vs random sampling data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "m7Pd9SYK5tv_"
      },
      "outputs": [],
      "source": [
        "def PermaDropout(rate):\n",
        "    return Lambda(lambda x: K.dropout(x, level=rate))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W6WgyM3Y5twA",
        "outputId": "0207aecc-8a60-4e09-e179-6b5d0b390a54"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2000\n",
            "383/383 [==============================] - 10s 24ms/step - loss: 0.9095 - accuracy: 0.7146 - val_loss: 0.4576 - val_accuracy: 0.8456 - lr: 0.0010\n",
            "Epoch 2/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.4123 - accuracy: 0.8658 - val_loss: 0.3764 - val_accuracy: 0.8777 - lr: 0.0010\n",
            "Epoch 3/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.3455 - accuracy: 0.8906 - val_loss: 0.3149 - val_accuracy: 0.9012 - lr: 0.0010\n",
            "Epoch 4/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.2991 - accuracy: 0.9072 - val_loss: 0.2862 - val_accuracy: 0.9136 - lr: 0.0010\n",
            "Epoch 5/2000\n",
            "383/383 [==============================] - 9s 22ms/step - loss: 0.2782 - accuracy: 0.9141 - val_loss: 0.3001 - val_accuracy: 0.9114 - lr: 0.0010\n",
            "Epoch 6/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.2581 - accuracy: 0.9211 - val_loss: 0.2684 - val_accuracy: 0.9206 - lr: 0.0010\n",
            "Epoch 7/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.2326 - accuracy: 0.9314 - val_loss: 0.2500 - val_accuracy: 0.9292 - lr: 0.0010\n",
            "Epoch 8/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.2188 - accuracy: 0.9378 - val_loss: 0.2374 - val_accuracy: 0.9324 - lr: 0.0010\n",
            "Epoch 9/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.2146 - accuracy: 0.9410 - val_loss: 0.2360 - val_accuracy: 0.9360 - lr: 0.0010\n",
            "Epoch 10/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.2045 - accuracy: 0.9428 - val_loss: 0.2326 - val_accuracy: 0.9345 - lr: 0.0010\n",
            "Epoch 11/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.2068 - accuracy: 0.9420 - val_loss: 0.2124 - val_accuracy: 0.9394 - lr: 0.0010\n",
            "Epoch 12/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.1929 - accuracy: 0.9474 - val_loss: 0.2118 - val_accuracy: 0.9388 - lr: 0.0010\n",
            "Epoch 13/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.1897 - accuracy: 0.9470 - val_loss: 0.2094 - val_accuracy: 0.9425 - lr: 0.0010\n",
            "Epoch 14/2000\n",
            "383/383 [==============================] - 9s 22ms/step - loss: 0.1917 - accuracy: 0.9465 - val_loss: 0.2192 - val_accuracy: 0.9366 - lr: 0.0010\n",
            "Epoch 15/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.1793 - accuracy: 0.9505 - val_loss: 0.2067 - val_accuracy: 0.9457 - lr: 0.0010\n",
            "Epoch 16/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.1752 - accuracy: 0.9517 - val_loss: 0.2100 - val_accuracy: 0.9443 - lr: 0.0010\n",
            "Epoch 17/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.1782 - accuracy: 0.9514 - val_loss: 0.2125 - val_accuracy: 0.9437 - lr: 0.0010\n",
            "Epoch 18/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.1702 - accuracy: 0.9536 - val_loss: 0.2073 - val_accuracy: 0.9459 - lr: 0.0010\n",
            "Epoch 19/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.1634 - accuracy: 0.9570 - val_loss: 0.2009 - val_accuracy: 0.9478 - lr: 9.0000e-04\n",
            "Epoch 20/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.1623 - accuracy: 0.9562 - val_loss: 0.1985 - val_accuracy: 0.9470 - lr: 9.0000e-04\n",
            "Epoch 21/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.1596 - accuracy: 0.9584 - val_loss: 0.2102 - val_accuracy: 0.9452 - lr: 9.0000e-04\n",
            "Epoch 22/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.1536 - accuracy: 0.9583 - val_loss: 0.2017 - val_accuracy: 0.9470 - lr: 9.0000e-04\n",
            "Epoch 23/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.1607 - accuracy: 0.9572 - val_loss: 0.2064 - val_accuracy: 0.9469 - lr: 9.0000e-04\n",
            "Epoch 24/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.1487 - accuracy: 0.9614 - val_loss: 0.1972 - val_accuracy: 0.9493 - lr: 8.1000e-04\n",
            "Epoch 25/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.1453 - accuracy: 0.9607 - val_loss: 0.1918 - val_accuracy: 0.9512 - lr: 8.1000e-04\n",
            "Epoch 26/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.1416 - accuracy: 0.9622 - val_loss: 0.1959 - val_accuracy: 0.9485 - lr: 8.1000e-04\n",
            "Epoch 27/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.1505 - accuracy: 0.9620 - val_loss: 0.2001 - val_accuracy: 0.9491 - lr: 8.1000e-04\n",
            "Epoch 28/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.1427 - accuracy: 0.9631 - val_loss: 0.1939 - val_accuracy: 0.9515 - lr: 8.1000e-04\n",
            "Epoch 29/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.1413 - accuracy: 0.9646 - val_loss: 0.2041 - val_accuracy: 0.9476 - lr: 7.2900e-04\n",
            "Epoch 30/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.1334 - accuracy: 0.9660 - val_loss: 0.1954 - val_accuracy: 0.9538 - lr: 7.2900e-04\n",
            "Epoch 31/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.1299 - accuracy: 0.9666 - val_loss: 0.2015 - val_accuracy: 0.9531 - lr: 7.2900e-04\n",
            "Epoch 32/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.1223 - accuracy: 0.9702 - val_loss: 0.2003 - val_accuracy: 0.9517 - lr: 6.5610e-04\n",
            "Epoch 33/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.1228 - accuracy: 0.9696 - val_loss: 0.2112 - val_accuracy: 0.9527 - lr: 6.5610e-04\n",
            "Epoch 34/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.1231 - accuracy: 0.9707 - val_loss: 0.1908 - val_accuracy: 0.9515 - lr: 6.5610e-04\n",
            "Epoch 35/2000\n",
            "383/383 [==============================] - 9s 22ms/step - loss: 0.1238 - accuracy: 0.9694 - val_loss: 0.1970 - val_accuracy: 0.9542 - lr: 6.5610e-04\n",
            "Epoch 36/2000\n",
            "383/383 [==============================] - 9s 22ms/step - loss: 0.1214 - accuracy: 0.9691 - val_loss: 0.1980 - val_accuracy: 0.9541 - lr: 6.5610e-04\n",
            "Epoch 37/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.1215 - accuracy: 0.9706 - val_loss: 0.1983 - val_accuracy: 0.9528 - lr: 6.5610e-04\n",
            "Epoch 38/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.1187 - accuracy: 0.9714 - val_loss: 0.1818 - val_accuracy: 0.9571 - lr: 5.9049e-04\n",
            "Epoch 39/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.1190 - accuracy: 0.9716 - val_loss: 0.2017 - val_accuracy: 0.9526 - lr: 5.9049e-04\n",
            "Epoch 40/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.1124 - accuracy: 0.9731 - val_loss: 0.2129 - val_accuracy: 0.9525 - lr: 5.9049e-04\n",
            "Epoch 41/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.1144 - accuracy: 0.9721 - val_loss: 0.2044 - val_accuracy: 0.9534 - lr: 5.9049e-04\n",
            "Epoch 42/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.1062 - accuracy: 0.9745 - val_loss: 0.1967 - val_accuracy: 0.9552 - lr: 5.3144e-04\n",
            "Epoch 43/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.1041 - accuracy: 0.9754 - val_loss: 0.2176 - val_accuracy: 0.9545 - lr: 5.3144e-04\n",
            "Epoch 44/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.1087 - accuracy: 0.9741 - val_loss: 0.2011 - val_accuracy: 0.9549 - lr: 5.3144e-04\n",
            "Epoch 45/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.1026 - accuracy: 0.9771 - val_loss: 0.2015 - val_accuracy: 0.9545 - lr: 4.7830e-04\n",
            "Epoch 46/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.1018 - accuracy: 0.9769 - val_loss: 0.2074 - val_accuracy: 0.9550 - lr: 4.7830e-04\n",
            "Epoch 47/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.1015 - accuracy: 0.9771 - val_loss: 0.2072 - val_accuracy: 0.9551 - lr: 4.7830e-04\n",
            "Epoch 48/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.0994 - accuracy: 0.9781 - val_loss: 0.2040 - val_accuracy: 0.9545 - lr: 4.3047e-04\n",
            "Epoch 49/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.0970 - accuracy: 0.9785 - val_loss: 0.2261 - val_accuracy: 0.9546 - lr: 4.3047e-04\n",
            "Epoch 50/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.0964 - accuracy: 0.9784 - val_loss: 0.2206 - val_accuracy: 0.9561 - lr: 4.3047e-04\n",
            "Epoch 51/2000\n",
            "383/383 [==============================] - 9s 22ms/step - loss: 0.0894 - accuracy: 0.9809 - val_loss: 0.2145 - val_accuracy: 0.9572 - lr: 3.8742e-04\n",
            "Epoch 52/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.0915 - accuracy: 0.9805 - val_loss: 0.2121 - val_accuracy: 0.9561 - lr: 3.8742e-04\n",
            "Epoch 53/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.0911 - accuracy: 0.9816 - val_loss: 0.2135 - val_accuracy: 0.9554 - lr: 3.8742e-04\n",
            "Epoch 54/2000\n",
            "383/383 [==============================] - 9s 22ms/step - loss: 0.0889 - accuracy: 0.9827 - val_loss: 0.2087 - val_accuracy: 0.9581 - lr: 3.4868e-04\n",
            "Epoch 55/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.0878 - accuracy: 0.9817 - val_loss: 0.2030 - val_accuracy: 0.9562 - lr: 3.4868e-04\n",
            "Epoch 56/2000\n",
            "383/383 [==============================] - 9s 22ms/step - loss: 0.0857 - accuracy: 0.9829 - val_loss: 0.2128 - val_accuracy: 0.9594 - lr: 3.4868e-04\n",
            "Epoch 57/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.0867 - accuracy: 0.9827 - val_loss: 0.2172 - val_accuracy: 0.9570 - lr: 3.1381e-04\n",
            "Epoch 58/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.0856 - accuracy: 0.9827 - val_loss: 0.1994 - val_accuracy: 0.9581 - lr: 3.1381e-04\n",
            "Epoch 59/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.0837 - accuracy: 0.9833 - val_loss: 0.2157 - val_accuracy: 0.9563 - lr: 3.1381e-04\n",
            "Epoch 60/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.0813 - accuracy: 0.9845 - val_loss: 0.2254 - val_accuracy: 0.9563 - lr: 2.8243e-04\n",
            "Epoch 61/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.0823 - accuracy: 0.9841 - val_loss: 0.2103 - val_accuracy: 0.9556 - lr: 2.8243e-04\n",
            "Epoch 62/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.0826 - accuracy: 0.9839 - val_loss: 0.2179 - val_accuracy: 0.9584 - lr: 2.8243e-04\n",
            "Epoch 63/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.0802 - accuracy: 0.9852 - val_loss: 0.2015 - val_accuracy: 0.9592 - lr: 2.5419e-04\n",
            "Epoch 64/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.0770 - accuracy: 0.9863 - val_loss: 0.2214 - val_accuracy: 0.9576 - lr: 2.5419e-04\n",
            "Epoch 65/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.0761 - accuracy: 0.9863 - val_loss: 0.2323 - val_accuracy: 0.9575 - lr: 2.5419e-04\n",
            "Epoch 66/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.0793 - accuracy: 0.9850 - val_loss: 0.2194 - val_accuracy: 0.9582 - lr: 2.2877e-04\n",
            "Epoch 67/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.0763 - accuracy: 0.9867 - val_loss: 0.2063 - val_accuracy: 0.9573 - lr: 2.2877e-04\n",
            "Epoch 68/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.0735 - accuracy: 0.9881 - val_loss: 0.2339 - val_accuracy: 0.9575 - lr: 2.2877e-04\n",
            "Epoch 69/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.0741 - accuracy: 0.9878 - val_loss: 0.2206 - val_accuracy: 0.9577 - lr: 2.0589e-04\n",
            "Epoch 70/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.0735 - accuracy: 0.9880 - val_loss: 0.2191 - val_accuracy: 0.9562 - lr: 2.0589e-04\n",
            "Epoch 71/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.0736 - accuracy: 0.9875 - val_loss: 0.2405 - val_accuracy: 0.9583 - lr: 2.0589e-04\n",
            "Epoch 72/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.0714 - accuracy: 0.9881 - val_loss: 0.2245 - val_accuracy: 0.9584 - lr: 1.8530e-04\n",
            "Epoch 73/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.0709 - accuracy: 0.9891 - val_loss: 0.2329 - val_accuracy: 0.9566 - lr: 1.8530e-04\n",
            "Epoch 74/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.0697 - accuracy: 0.9890 - val_loss: 0.2226 - val_accuracy: 0.9570 - lr: 1.8530e-04\n",
            "Epoch 75/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.0715 - accuracy: 0.9889 - val_loss: 0.2180 - val_accuracy: 0.9573 - lr: 1.6677e-04\n",
            "Epoch 76/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.0691 - accuracy: 0.9892 - val_loss: 0.2093 - val_accuracy: 0.9579 - lr: 1.6677e-04\n",
            "Epoch 77/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.0695 - accuracy: 0.9889 - val_loss: 0.2101 - val_accuracy: 0.9583 - lr: 1.6677e-04\n",
            "Epoch 78/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.0721 - accuracy: 0.9883 - val_loss: 0.2201 - val_accuracy: 0.9594 - lr: 1.5009e-04\n",
            "Epoch 79/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.0676 - accuracy: 0.9898 - val_loss: 0.2134 - val_accuracy: 0.9578 - lr: 1.5009e-04\n",
            "Epoch 80/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.0675 - accuracy: 0.9900 - val_loss: 0.2149 - val_accuracy: 0.9584 - lr: 1.5009e-04\n",
            "Epoch 81/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.0686 - accuracy: 0.9898 - val_loss: 0.2266 - val_accuracy: 0.9561 - lr: 1.3509e-04\n",
            "Epoch 82/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.0655 - accuracy: 0.9910 - val_loss: 0.2201 - val_accuracy: 0.9552 - lr: 1.3509e-04\n",
            "Epoch 83/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.0675 - accuracy: 0.9896 - val_loss: 0.2156 - val_accuracy: 0.9587 - lr: 1.3509e-04\n",
            "Epoch 84/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.0669 - accuracy: 0.9901 - val_loss: 0.2083 - val_accuracy: 0.9572 - lr: 1.2158e-04\n",
            "Epoch 85/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.0671 - accuracy: 0.9900 - val_loss: 0.2158 - val_accuracy: 0.9580 - lr: 1.2158e-04\n",
            "Epoch 86/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.0672 - accuracy: 0.9904 - val_loss: 0.2193 - val_accuracy: 0.9585 - lr: 1.2158e-04\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f3ddec9aa10>"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "#######HYPERPARAMATERS###########\n",
        "epochs = 2000\n",
        "batch_size = 64\n",
        "learning_rate = 0.001\n",
        "#################################\n",
        "  \n",
        "model = Sequential()\n",
        "    \n",
        "model.add(Conv2D(32, kernel_size = (3,3), input_shape=(28,28,1), activation='relu'))\n",
        "\n",
        "model.add(Conv2D(64,(3,3), activation='relu'))\n",
        "model.add(Conv2D(64,(3,3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=2))\n",
        "model.add(PermaDropout(0.5))\n",
        "\n",
        "model.add(Conv2D(128,(3,3), activation='relu'))\n",
        "model.add(Conv2D(128,(3,3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=2))\n",
        "model.add(PermaDropout(0.5))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(PermaDropout(0.5))\n",
        "\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "adam = keras.optimizers.Adam(learning_rate)\n",
        "model.compile(optimizer = adam, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
        "    \n",
        "# print(model.summary())\n",
        "\n",
        "lr_reducer = ReduceLROnPlateau(monitor='val_loss', factor=0.9, patience=3)\n",
        "early_stopper = EarlyStopping(monitor='val_accuracy', min_delta=0, patience=30, mode='auto')\n",
        "checkpointer = ModelCheckpoint('weights.hd5', monitor='val_loss', verbose=1, save_best_only=True)\n",
        "\n",
        "\n",
        "model.fit(\n",
        "          train_data_1,\n",
        "          train_labels_1,\n",
        "          epochs = epochs,\n",
        "          batch_size = batch_size,\n",
        "          validation_split = 0.3,\n",
        "          shuffle = True,\n",
        "          callbacks=[lr_reducer, early_stopper]\n",
        "          )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "9_zB1OL252B3"
      },
      "outputs": [],
      "source": [
        "model.save('/content/drive/MyDrive/파이썬스터디 프로젝트/labeling_cnn2.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BbEZKkhn52B4",
        "outputId": "6eb8d6cc-b957-45f0-f10a-1742c2d31e40"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8946"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "model = keras.models.load_model('/content/drive/MyDrive/파이썬스터디 프로젝트/labeling_cnn2.h5')\n",
        "model_eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "742b5c31-1119-4313-c1bf-10a10bfda23f",
        "id": "9KTK643Nkt4E"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2000\n",
            "383/383 [==============================] - 10s 23ms/step - loss: 1.2357 - accuracy: 0.5925 - val_loss: 0.7226 - val_accuracy: 0.7649 - lr: 0.0010\n",
            "Epoch 2/2000\n",
            "383/383 [==============================] - 9s 22ms/step - loss: 0.6191 - accuracy: 0.7907 - val_loss: 0.5807 - val_accuracy: 0.8062 - lr: 0.0010\n",
            "Epoch 3/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.5445 - accuracy: 0.8221 - val_loss: 0.5088 - val_accuracy: 0.8370 - lr: 0.0010\n",
            "Epoch 4/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.4895 - accuracy: 0.8467 - val_loss: 0.4802 - val_accuracy: 0.8510 - lr: 0.0010\n",
            "Epoch 5/2000\n",
            "383/383 [==============================] - 9s 22ms/step - loss: 0.4571 - accuracy: 0.8608 - val_loss: 0.4704 - val_accuracy: 0.8522 - lr: 0.0010\n",
            "Epoch 6/2000\n",
            "383/383 [==============================] - 9s 22ms/step - loss: 0.4338 - accuracy: 0.8697 - val_loss: 0.4286 - val_accuracy: 0.8721 - lr: 0.0010\n",
            "Epoch 7/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.4163 - accuracy: 0.8771 - val_loss: 0.4264 - val_accuracy: 0.8761 - lr: 0.0010\n",
            "Epoch 8/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.4009 - accuracy: 0.8811 - val_loss: 0.4234 - val_accuracy: 0.8740 - lr: 0.0010\n",
            "Epoch 9/2000\n",
            "383/383 [==============================] - 9s 22ms/step - loss: 0.3934 - accuracy: 0.8865 - val_loss: 0.4141 - val_accuracy: 0.8801 - lr: 0.0010\n",
            "Epoch 10/2000\n",
            "383/383 [==============================] - 9s 22ms/step - loss: 0.3862 - accuracy: 0.8887 - val_loss: 0.4140 - val_accuracy: 0.8798 - lr: 0.0010\n",
            "Epoch 11/2000\n",
            "383/383 [==============================] - 9s 22ms/step - loss: 0.3819 - accuracy: 0.8933 - val_loss: 0.4043 - val_accuracy: 0.8843 - lr: 0.0010\n",
            "Epoch 12/2000\n",
            "383/383 [==============================] - 9s 22ms/step - loss: 0.3756 - accuracy: 0.8922 - val_loss: 0.4144 - val_accuracy: 0.8767 - lr: 0.0010\n",
            "Epoch 13/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.3713 - accuracy: 0.8957 - val_loss: 0.3961 - val_accuracy: 0.8842 - lr: 0.0010\n",
            "Epoch 14/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.3651 - accuracy: 0.9002 - val_loss: 0.3941 - val_accuracy: 0.8874 - lr: 0.0010\n",
            "Epoch 15/2000\n",
            "383/383 [==============================] - 9s 22ms/step - loss: 0.3620 - accuracy: 0.8991 - val_loss: 0.3799 - val_accuracy: 0.8938 - lr: 0.0010\n",
            "Epoch 16/2000\n",
            "383/383 [==============================] - 9s 22ms/step - loss: 0.3552 - accuracy: 0.9024 - val_loss: 0.3787 - val_accuracy: 0.8935 - lr: 0.0010\n",
            "Epoch 17/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.3554 - accuracy: 0.9013 - val_loss: 0.3959 - val_accuracy: 0.8911 - lr: 0.0010\n",
            "Epoch 18/2000\n",
            "383/383 [==============================] - 9s 22ms/step - loss: 0.3464 - accuracy: 0.9034 - val_loss: 0.3812 - val_accuracy: 0.8941 - lr: 0.0010\n",
            "Epoch 19/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.3430 - accuracy: 0.9089 - val_loss: 0.3842 - val_accuracy: 0.8934 - lr: 0.0010\n",
            "Epoch 20/2000\n",
            "383/383 [==============================] - 9s 22ms/step - loss: 0.3398 - accuracy: 0.9099 - val_loss: 0.3786 - val_accuracy: 0.8919 - lr: 9.0000e-04\n",
            "Epoch 21/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.3357 - accuracy: 0.9103 - val_loss: 0.3737 - val_accuracy: 0.8995 - lr: 9.0000e-04\n",
            "Epoch 22/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.3343 - accuracy: 0.9109 - val_loss: 0.3701 - val_accuracy: 0.8982 - lr: 9.0000e-04\n",
            "Epoch 23/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.3302 - accuracy: 0.9131 - val_loss: 0.3874 - val_accuracy: 0.8903 - lr: 9.0000e-04\n",
            "Epoch 24/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.3303 - accuracy: 0.9125 - val_loss: 0.3795 - val_accuracy: 0.8928 - lr: 9.0000e-04\n",
            "Epoch 25/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.3278 - accuracy: 0.9129 - val_loss: 0.3667 - val_accuracy: 0.8989 - lr: 9.0000e-04\n",
            "Epoch 26/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.3239 - accuracy: 0.9146 - val_loss: 0.3702 - val_accuracy: 0.9014 - lr: 9.0000e-04\n",
            "Epoch 27/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.3253 - accuracy: 0.9160 - val_loss: 0.3637 - val_accuracy: 0.9014 - lr: 9.0000e-04\n",
            "Epoch 28/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.3189 - accuracy: 0.9170 - val_loss: 0.3635 - val_accuracy: 0.8996 - lr: 9.0000e-04\n",
            "Epoch 29/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.3220 - accuracy: 0.9161 - val_loss: 0.3689 - val_accuracy: 0.9014 - lr: 9.0000e-04\n",
            "Epoch 30/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.3181 - accuracy: 0.9175 - val_loss: 0.3686 - val_accuracy: 0.8942 - lr: 9.0000e-04\n",
            "Epoch 31/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.3197 - accuracy: 0.9175 - val_loss: 0.3787 - val_accuracy: 0.8960 - lr: 9.0000e-04\n",
            "Epoch 32/2000\n",
            "383/383 [==============================] - 9s 22ms/step - loss: 0.3144 - accuracy: 0.9207 - val_loss: 0.3680 - val_accuracy: 0.9026 - lr: 8.1000e-04\n",
            "Epoch 33/2000\n",
            "383/383 [==============================] - 9s 22ms/step - loss: 0.3098 - accuracy: 0.9216 - val_loss: 0.3593 - val_accuracy: 0.9058 - lr: 8.1000e-04\n",
            "Epoch 34/2000\n",
            "383/383 [==============================] - 9s 22ms/step - loss: 0.3084 - accuracy: 0.9225 - val_loss: 0.3643 - val_accuracy: 0.9030 - lr: 8.1000e-04\n",
            "Epoch 35/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.3088 - accuracy: 0.9228 - val_loss: 0.3572 - val_accuracy: 0.9028 - lr: 8.1000e-04\n",
            "Epoch 36/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.3038 - accuracy: 0.9243 - val_loss: 0.3603 - val_accuracy: 0.9013 - lr: 8.1000e-04\n",
            "Epoch 37/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.3025 - accuracy: 0.9258 - val_loss: 0.3623 - val_accuracy: 0.9054 - lr: 8.1000e-04\n",
            "Epoch 38/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.3049 - accuracy: 0.9255 - val_loss: 0.3675 - val_accuracy: 0.9010 - lr: 8.1000e-04\n",
            "Epoch 39/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.2979 - accuracy: 0.9268 - val_loss: 0.3610 - val_accuracy: 0.9022 - lr: 7.2900e-04\n",
            "Epoch 40/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.2967 - accuracy: 0.9261 - val_loss: 0.3581 - val_accuracy: 0.9049 - lr: 7.2900e-04\n",
            "Epoch 41/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.2949 - accuracy: 0.9263 - val_loss: 0.3577 - val_accuracy: 0.9023 - lr: 7.2900e-04\n",
            "Epoch 42/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.2910 - accuracy: 0.9311 - val_loss: 0.3548 - val_accuracy: 0.9042 - lr: 6.5610e-04\n",
            "Epoch 43/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.2891 - accuracy: 0.9306 - val_loss: 0.3546 - val_accuracy: 0.9034 - lr: 6.5610e-04\n",
            "Epoch 44/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.2883 - accuracy: 0.9320 - val_loss: 0.3535 - val_accuracy: 0.9057 - lr: 6.5610e-04\n",
            "Epoch 45/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.2888 - accuracy: 0.9300 - val_loss: 0.3578 - val_accuracy: 0.9048 - lr: 6.5610e-04\n",
            "Epoch 46/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.2858 - accuracy: 0.9319 - val_loss: 0.3553 - val_accuracy: 0.9056 - lr: 6.5610e-04\n",
            "Epoch 47/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.2863 - accuracy: 0.9321 - val_loss: 0.3493 - val_accuracy: 0.9072 - lr: 6.5610e-04\n",
            "Epoch 48/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.2847 - accuracy: 0.9327 - val_loss: 0.3521 - val_accuracy: 0.9076 - lr: 6.5610e-04\n",
            "Epoch 49/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.2822 - accuracy: 0.9340 - val_loss: 0.3496 - val_accuracy: 0.9077 - lr: 6.5610e-04\n",
            "Epoch 50/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.2812 - accuracy: 0.9327 - val_loss: 0.3523 - val_accuracy: 0.9095 - lr: 6.5610e-04\n",
            "Epoch 51/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.2806 - accuracy: 0.9371 - val_loss: 0.3487 - val_accuracy: 0.9079 - lr: 5.9049e-04\n",
            "Epoch 52/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.2772 - accuracy: 0.9344 - val_loss: 0.3450 - val_accuracy: 0.9088 - lr: 5.9049e-04\n",
            "Epoch 53/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.2784 - accuracy: 0.9362 - val_loss: 0.3515 - val_accuracy: 0.9069 - lr: 5.9049e-04\n",
            "Epoch 54/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.2793 - accuracy: 0.9363 - val_loss: 0.3559 - val_accuracy: 0.9082 - lr: 5.9049e-04\n",
            "Epoch 55/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.2755 - accuracy: 0.9389 - val_loss: 0.3500 - val_accuracy: 0.9060 - lr: 5.9049e-04\n",
            "Epoch 56/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.2745 - accuracy: 0.9374 - val_loss: 0.3556 - val_accuracy: 0.9046 - lr: 5.3144e-04\n",
            "Epoch 57/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.2699 - accuracy: 0.9402 - val_loss: 0.3485 - val_accuracy: 0.9083 - lr: 5.3144e-04\n",
            "Epoch 58/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.2660 - accuracy: 0.9434 - val_loss: 0.3486 - val_accuracy: 0.9092 - lr: 5.3144e-04\n",
            "Epoch 59/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.2677 - accuracy: 0.9411 - val_loss: 0.3452 - val_accuracy: 0.9088 - lr: 4.7830e-04\n",
            "Epoch 60/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.2657 - accuracy: 0.9416 - val_loss: 0.3425 - val_accuracy: 0.9115 - lr: 4.7830e-04\n",
            "Epoch 61/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.2656 - accuracy: 0.9425 - val_loss: 0.3418 - val_accuracy: 0.9113 - lr: 4.7830e-04\n",
            "Epoch 62/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.2632 - accuracy: 0.9440 - val_loss: 0.3433 - val_accuracy: 0.9133 - lr: 4.7830e-04\n",
            "Epoch 63/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.2636 - accuracy: 0.9437 - val_loss: 0.3513 - val_accuracy: 0.9088 - lr: 4.7830e-04\n",
            "Epoch 64/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.2638 - accuracy: 0.9438 - val_loss: 0.3497 - val_accuracy: 0.9083 - lr: 4.7830e-04\n",
            "Epoch 65/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.2590 - accuracy: 0.9483 - val_loss: 0.3464 - val_accuracy: 0.9090 - lr: 4.3047e-04\n",
            "Epoch 66/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.2609 - accuracy: 0.9427 - val_loss: 0.3462 - val_accuracy: 0.9070 - lr: 4.3047e-04\n",
            "Epoch 67/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.2585 - accuracy: 0.9461 - val_loss: 0.3444 - val_accuracy: 0.9147 - lr: 4.3047e-04\n",
            "Epoch 68/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.2566 - accuracy: 0.9468 - val_loss: 0.3447 - val_accuracy: 0.9114 - lr: 3.8742e-04\n",
            "Epoch 69/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.2550 - accuracy: 0.9475 - val_loss: 0.3473 - val_accuracy: 0.9093 - lr: 3.8742e-04\n",
            "Epoch 70/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.2544 - accuracy: 0.9484 - val_loss: 0.3479 - val_accuracy: 0.9110 - lr: 3.8742e-04\n",
            "Epoch 71/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.2544 - accuracy: 0.9495 - val_loss: 0.3454 - val_accuracy: 0.9130 - lr: 3.4868e-04\n",
            "Epoch 72/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.2524 - accuracy: 0.9496 - val_loss: 0.3412 - val_accuracy: 0.9104 - lr: 3.4868e-04\n",
            "Epoch 73/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.2505 - accuracy: 0.9502 - val_loss: 0.3409 - val_accuracy: 0.9107 - lr: 3.4868e-04\n",
            "Epoch 74/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.2510 - accuracy: 0.9492 - val_loss: 0.3450 - val_accuracy: 0.9109 - lr: 3.4868e-04\n",
            "Epoch 75/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.2509 - accuracy: 0.9505 - val_loss: 0.3479 - val_accuracy: 0.9110 - lr: 3.4868e-04\n",
            "Epoch 76/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.2498 - accuracy: 0.9517 - val_loss: 0.3409 - val_accuracy: 0.9123 - lr: 3.4868e-04\n",
            "Epoch 77/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.2486 - accuracy: 0.9512 - val_loss: 0.3450 - val_accuracy: 0.9139 - lr: 3.1381e-04\n",
            "Epoch 78/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.2471 - accuracy: 0.9530 - val_loss: 0.3427 - val_accuracy: 0.9099 - lr: 3.1381e-04\n",
            "Epoch 79/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.2493 - accuracy: 0.9512 - val_loss: 0.3453 - val_accuracy: 0.9107 - lr: 3.1381e-04\n",
            "Epoch 80/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.2466 - accuracy: 0.9496 - val_loss: 0.3382 - val_accuracy: 0.9119 - lr: 2.8243e-04\n",
            "Epoch 81/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.2450 - accuracy: 0.9519 - val_loss: 0.3419 - val_accuracy: 0.9162 - lr: 2.8243e-04\n",
            "Epoch 82/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.2439 - accuracy: 0.9531 - val_loss: 0.3505 - val_accuracy: 0.9108 - lr: 2.8243e-04\n",
            "Epoch 83/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.2430 - accuracy: 0.9545 - val_loss: 0.3321 - val_accuracy: 0.9185 - lr: 2.8243e-04\n",
            "Epoch 84/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.2434 - accuracy: 0.9538 - val_loss: 0.3438 - val_accuracy: 0.9108 - lr: 2.8243e-04\n",
            "Epoch 85/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.2419 - accuracy: 0.9550 - val_loss: 0.3471 - val_accuracy: 0.9125 - lr: 2.8243e-04\n",
            "Epoch 86/2000\n",
            "383/383 [==============================] - 9s 24ms/step - loss: 0.2420 - accuracy: 0.9548 - val_loss: 0.3499 - val_accuracy: 0.9094 - lr: 2.8243e-04\n",
            "Epoch 87/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.2418 - accuracy: 0.9553 - val_loss: 0.3425 - val_accuracy: 0.9128 - lr: 2.5419e-04\n",
            "Epoch 88/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.2418 - accuracy: 0.9544 - val_loss: 0.3364 - val_accuracy: 0.9143 - lr: 2.5419e-04\n",
            "Epoch 89/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.2407 - accuracy: 0.9530 - val_loss: 0.3433 - val_accuracy: 0.9120 - lr: 2.5419e-04\n",
            "Epoch 90/2000\n",
            "383/383 [==============================] - 9s 24ms/step - loss: 0.2382 - accuracy: 0.9556 - val_loss: 0.3383 - val_accuracy: 0.9136 - lr: 2.2877e-04\n",
            "Epoch 91/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.2398 - accuracy: 0.9545 - val_loss: 0.3420 - val_accuracy: 0.9139 - lr: 2.2877e-04\n",
            "Epoch 92/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.2385 - accuracy: 0.9557 - val_loss: 0.3429 - val_accuracy: 0.9111 - lr: 2.2877e-04\n",
            "Epoch 93/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.2380 - accuracy: 0.9563 - val_loss: 0.3407 - val_accuracy: 0.9138 - lr: 2.0589e-04\n",
            "Epoch 94/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.2370 - accuracy: 0.9565 - val_loss: 0.3400 - val_accuracy: 0.9098 - lr: 2.0589e-04\n",
            "Epoch 95/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.2370 - accuracy: 0.9569 - val_loss: 0.3412 - val_accuracy: 0.9110 - lr: 2.0589e-04\n",
            "Epoch 96/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.2356 - accuracy: 0.9566 - val_loss: 0.3448 - val_accuracy: 0.9132 - lr: 1.8530e-04\n",
            "Epoch 97/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.2329 - accuracy: 0.9579 - val_loss: 0.3456 - val_accuracy: 0.9085 - lr: 1.8530e-04\n",
            "Epoch 98/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.2324 - accuracy: 0.9584 - val_loss: 0.3446 - val_accuracy: 0.9104 - lr: 1.8530e-04\n",
            "Epoch 99/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.2339 - accuracy: 0.9591 - val_loss: 0.3429 - val_accuracy: 0.9136 - lr: 1.6677e-04\n",
            "Epoch 100/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.2336 - accuracy: 0.9584 - val_loss: 0.3433 - val_accuracy: 0.9131 - lr: 1.6677e-04\n",
            "Epoch 101/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.2327 - accuracy: 0.9588 - val_loss: 0.3439 - val_accuracy: 0.9134 - lr: 1.6677e-04\n",
            "Epoch 102/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.2322 - accuracy: 0.9592 - val_loss: 0.3443 - val_accuracy: 0.9109 - lr: 1.5009e-04\n",
            "Epoch 103/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.2313 - accuracy: 0.9594 - val_loss: 0.3412 - val_accuracy: 0.9145 - lr: 1.5009e-04\n",
            "Epoch 104/2000\n",
            "383/383 [==============================] - 9s 24ms/step - loss: 0.2325 - accuracy: 0.9590 - val_loss: 0.3394 - val_accuracy: 0.9125 - lr: 1.5009e-04\n",
            "Epoch 105/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.2311 - accuracy: 0.9605 - val_loss: 0.3395 - val_accuracy: 0.9166 - lr: 1.3509e-04\n",
            "Epoch 106/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.2305 - accuracy: 0.9582 - val_loss: 0.3409 - val_accuracy: 0.9116 - lr: 1.3509e-04\n",
            "Epoch 107/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.2291 - accuracy: 0.9596 - val_loss: 0.3443 - val_accuracy: 0.9133 - lr: 1.3509e-04\n",
            "Epoch 108/2000\n",
            "383/383 [==============================] - 9s 24ms/step - loss: 0.2296 - accuracy: 0.9607 - val_loss: 0.3410 - val_accuracy: 0.9152 - lr: 1.2158e-04\n",
            "Epoch 109/2000\n",
            "383/383 [==============================] - 9s 24ms/step - loss: 0.2292 - accuracy: 0.9611 - val_loss: 0.3389 - val_accuracy: 0.9142 - lr: 1.2158e-04\n",
            "Epoch 110/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.2287 - accuracy: 0.9606 - val_loss: 0.3442 - val_accuracy: 0.9141 - lr: 1.2158e-04\n",
            "Epoch 111/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.2287 - accuracy: 0.9629 - val_loss: 0.3399 - val_accuracy: 0.9157 - lr: 1.0942e-04\n",
            "Epoch 112/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.2276 - accuracy: 0.9611 - val_loss: 0.3362 - val_accuracy: 0.9114 - lr: 1.0942e-04\n",
            "Epoch 113/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.2277 - accuracy: 0.9614 - val_loss: 0.3369 - val_accuracy: 0.9154 - lr: 1.0942e-04\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f3ec01c2e50>"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "#######HYPERPARAMATERS###########\n",
        "epochs = 2000\n",
        "batch_size = 64\n",
        "learning_rate = 0.001\n",
        "#################################\n",
        "\n",
        "model = Sequential()\n",
        "    \n",
        "model.add(Conv2D(32, kernel_size = (3,3), input_shape=(28,28,1), activation='relu'))\n",
        "\n",
        "model.add(Conv2D(64,(3,3), activation='relu'))\n",
        "model.add(Conv2D(64,(3,3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=2))\n",
        "model.add(PermaDropout(0.5))\n",
        "\n",
        "model.add(Conv2D(128,(3,3), activation='relu'))\n",
        "model.add(Conv2D(128,(3,3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=2))\n",
        "model.add(PermaDropout(0.5))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(PermaDropout(0.5))\n",
        "\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "adam = keras.optimizers.Adam(learning_rate)\n",
        "model.compile(optimizer = adam, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
        "    \n",
        "# print(model.summary())\n",
        "\n",
        "lr_reducer = ReduceLROnPlateau(monitor='val_loss', factor=0.9, patience=3)\n",
        "early_stopper = EarlyStopping(monitor='val_accuracy', min_delta=0, patience=30, mode='auto')\n",
        "checkpointer = ModelCheckpoint('weights.hd5', monitor='val_loss', verbose=1, save_best_only=True)\n",
        "\n",
        "model.fit(\n",
        "          train_data_2,\n",
        "          train_labels_2,\n",
        "          epochs = epochs,\n",
        "          batch_size = batch_size,\n",
        "          validation_split = 0.3,\n",
        "          shuffle = True,\n",
        "          callbacks=[lr_reducer, early_stopper]\n",
        "          )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "4d3W-766kt4H"
      },
      "outputs": [],
      "source": [
        "model.save('/content/drive/MyDrive/파이썬스터디 프로젝트/labeling_cnn_no.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "it79cIfekt4H",
        "outputId": "1f47430b-601d-4180-b8c0-bd3b1096392f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8928"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ],
      "source": [
        "model = keras.models.load_model('/content/drive/MyDrive/파이썬스터디 프로젝트/labeling_cnn_no.h5')\n",
        "model_eval()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "G84gMPYdXQPO"
      },
      "execution_count": 38,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "uncertainty 기반 labeling.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}