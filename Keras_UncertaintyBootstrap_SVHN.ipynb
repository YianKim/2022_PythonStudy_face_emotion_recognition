{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YianKim/2022_uncertainty_aware_semisupervise/blob/main/Keras_UncertaintyBootstrap_SVHN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install tensorflow_addons"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gAyYZmY-fK6R",
        "outputId": "6df5327a-e712-4723-891e-73d643decd63"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow_addons\n",
            "  Downloading tensorflow_addons-0.17.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 9.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow_addons) (2.7.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from tensorflow_addons) (21.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->tensorflow_addons) (3.0.9)\n",
            "Installing collected packages: tensorflow-addons\n",
            "Successfully installed tensorflow-addons-0.17.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Ik7Qx5iO8lQ_"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import clone_model\n",
        "\n",
        "import PIL\n",
        "from PIL import Image\n",
        "\n",
        "import pickle\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "from collections import Counter\n",
        "\n",
        "from keras.layers.core import Lambda\n",
        "from keras import backend as K\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.regularizers import l2\n",
        "from keras.layers import Activation\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import MaxPooling2D, AveragePooling2D\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Reshape\n",
        "from keras import optimizers\n",
        "from keras.callbacks import *\n",
        "from sklearn.metrics import *\n",
        "from keras.models import load_model\n",
        "import tensorflow_addons as tfa\n",
        "\n",
        "from torchvision import transforms\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras.backend as backend\n",
        "import math\n",
        "import gc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Hmq32hTH-Jv"
      },
      "source": [
        "# SVHN"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u1t_K15MfUe5",
        "outputId": "17366d3f-2da3-43ec-f7de-88fe131369bf"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "HUCvct_dH5m1"
      },
      "outputs": [],
      "source": [
        "from scipy.io import loadmat\n",
        "train_raw = loadmat('/content/drive/MyDrive/SVHN/train_32x32.mat')\n",
        "test_raw = loadmat('/content/drive/MyDrive/SVHN/test_32x32.mat')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "XzWKzGmGtk2h"
      },
      "outputs": [],
      "source": [
        "def dummy_labels(labels):\n",
        "  zero_labels = np.zeros([labels.shape[0], 10], np.int8)  \n",
        "  for i in range(labels.shape[0]):\n",
        "    zero_labels[i][labels[i]] = 1\n",
        "  return(zero_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "65QFu6LVMxl9"
      },
      "outputs": [],
      "source": [
        "train_images = train_raw['X']\n",
        "train_labels = train_raw['y']\n",
        "\n",
        "test_images = test_raw['X']\n",
        "test_labels = dummy_labels(test_raw['y']-1)\n",
        "\n",
        "train_images = train_images.swapaxes(2,3).swapaxes(1,2).swapaxes(0,1)\n",
        "test_images = test_images.swapaxes(2,3).swapaxes(1,2).swapaxes(0,1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "fm_NgimXNonL"
      },
      "outputs": [],
      "source": [
        "temp = [0,0,0,0,0,0,0,0,0,0]\n",
        "label_indx = []\n",
        "unlabel_indx = []\n",
        "\n",
        "for i in range(73257) :\n",
        "  if temp[(train_labels).reshape([-1])[i]-1] < 25 :\n",
        "    temp[(train_labels).reshape([-1])[i]-1] += 1\n",
        "    label_indx.append(i)\n",
        "  else :\n",
        "    unlabel_indx.append(i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "3ZADJPIIOZD2"
      },
      "outputs": [],
      "source": [
        "lbl_train_images = train_images[label_indx]\n",
        "lbl_train_labels = dummy_labels(train_labels[label_indx]-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "fHe18DTWUu3-"
      },
      "outputs": [],
      "source": [
        "ubl_train_images = train_images[unlabel_indx]\n",
        "ubl_train_labels = dummy_labels(train_labels[unlabel_indx]-1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q7hfth6hMMxW"
      },
      "source": [
        "#MAin\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "iKyn6Njs7vqa"
      },
      "outputs": [],
      "source": [
        "class SGDR(Callback):\n",
        "\n",
        "    def __init__(self, min_lr=0.0, max_lr=0.03, base_epochs=20, mul_epochs=2):\n",
        "        super(SGDR, self).__init__()\n",
        "\n",
        "        self.min_lr = min_lr\n",
        "        self.max_lr = max_lr\n",
        "        self.base_epochs = base_epochs\n",
        "        self.mul_epochs = mul_epochs\n",
        "\n",
        "        self.cycles = 0.\n",
        "        self.cycle_iterations = 0.\n",
        "        self.trn_iterations = 0.\n",
        "\n",
        "        self._reset()\n",
        "\n",
        "    def _reset(self, new_min_lr=None, new_max_lr=None,\n",
        "               new_base_epochs=None, new_mul_epochs=None):\n",
        "        \"\"\"Resets cycle iterations.\"\"\"\n",
        "        \n",
        "        if new_min_lr != None:\n",
        "            self.min_lr = new_min_lr\n",
        "        if new_max_lr != None:\n",
        "            self.max_lr = new_max_lr\n",
        "        if new_base_epochs != None:\n",
        "            self.base_epochs = new_base_epochs\n",
        "        if new_mul_epochs != None:\n",
        "            self.mul_epochs = new_mul_epochs\n",
        "        self.cycles = 0.\n",
        "        self.cycle_iterations = 0.\n",
        "        \n",
        "    def sgdr(self):\n",
        "        \n",
        "        cycle_epochs = self.base_epochs * (self.mul_epochs ** self.cycles)\n",
        "        tide = ((self.cycles == 0) * 1) * (self.cycle_iterations*self.max_lr + (self.base_epochs - self.cycle_iterations)*self.min_lr) / self.base_epochs + ((self.cycles != 0) * 1)*(self.min_lr + 0.5 * (self.max_lr - self.min_lr) * (1 + np.cos(np.pi * (self.cycle_iterations + 1) / cycle_epochs)))\n",
        "        return tide\n",
        "        \n",
        "    def on_train_begin(self, logs=None):\n",
        "        \n",
        "        if self.cycle_iterations == 0:\n",
        "            K.set_value(self.model.optimizer.lr, self.max_lr)\n",
        "        else:\n",
        "            K.set_value(self.model.optimizer.lr, self.sgdr())\n",
        "            \n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        \n",
        "        logs = logs or {}\n",
        "        logs['lr'] = K.get_value(self.model.optimizer.lr)\n",
        "        \n",
        "        self.trn_iterations += 1\n",
        "        self.cycle_iterations += 1\n",
        "        if self.cycle_iterations >= self.base_epochs * (self.mul_epochs ** self.cycles):\n",
        "            self.cycles += 1\n",
        "            self.cycle_iterations = 0\n",
        "            K.set_value(self.model.optimizer.lr, self.max_lr)\n",
        "        else:\n",
        "            K.set_value(self.model.optimizer.lr, self.sgdr())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def PermaDropout(rate):\n",
        "    return Lambda(lambda x: K.dropout(x, level=rate))\n",
        "\n",
        "def create_cnn_1():\n",
        "  conv1a = Conv2D(32, (3,3), padding = 'same')\n",
        "  bn1a = BatchNormalization()\n",
        "  conv1b = Conv2D(32, (3,3), padding = 'same')\n",
        "  bn1b = BatchNormalization()\n",
        "  conv1c = Conv2D(32, (3,3), padding = 'same')\n",
        "  bn1c = BatchNormalization()\n",
        "  pl1 = MaxPooling2D(2, 2)\n",
        "  MCdrop1 = PermaDropout(0.4)\n",
        "\n",
        "  conv2a = Conv2D(64, (3,3), padding = 'same')\n",
        "  bn2a = BatchNormalization()\n",
        "  conv2b = Conv2D(64, (3,3), padding = 'same')\n",
        "  bn2b = BatchNormalization()\n",
        "  conv2c = Conv2D(64, (3,3), padding = 'same')\n",
        "  bn2c = BatchNormalization()\n",
        "  pl2 = MaxPooling2D(2, 2)\n",
        "  MCdrop2 = PermaDropout(0.4)\n",
        "\n",
        "  conv3a = Conv2D(128, (3,3))\n",
        "  bn3a = BatchNormalization()\n",
        "  conv3b = Conv2D(128, (3,3))\n",
        "  bn3b = BatchNormalization()\n",
        "  conv3c = Conv2D(128, (3,3))\n",
        "  bn3c = BatchNormalization()\n",
        "  pl3 = AveragePooling2D(4, 1)\n",
        "  MCdrop3 = PermaDropout(0.4)\n",
        "\n",
        "  fc1 = Dense(128)\n",
        "  fc2 = Dense(10)\n",
        "  activ = keras.layers.LeakyReLU(0.1)\n",
        "\n",
        "  model = Sequential([\n",
        "                      keras.Input(shape=(32, 32, 3)), \n",
        "                      tfa.layers.WeightNormalization(conv1a), bn1a, activ,\n",
        "                      tfa.layers.WeightNormalization(conv1b), bn1b, activ,\n",
        "                      # tfa.layers.WeightNormalization(conv1c), bn1c, activ,\n",
        "                      pl1, MCdrop1,\n",
        "\n",
        "                      tfa.layers.WeightNormalization(conv2a), bn2a, activ,\n",
        "                      tfa.layers.WeightNormalization(conv2b), bn2b, activ,\n",
        "                      # tfa.layers.WeightNormalization(conv2c), bn2c, activ,\n",
        "                      pl2, MCdrop2,\n",
        "\n",
        "                      tfa.layers.WeightNormalization(conv3a), bn3a, activ,\n",
        "                      tfa.layers.WeightNormalization(conv3b), bn3b, activ,\n",
        "                      # tfa.layers.WeightNormalization(conv3c), bn3c, activ,\n",
        "                      pl3, MCdrop3, Flatten(),\n",
        "                      \n",
        "                      fc1, activ, fc2\n",
        "                      ])\n",
        "  \n",
        "  return model\n",
        "\n",
        "def create_cnn_2():\n",
        "  conv1a = Conv2D(32, (3,3), padding = 'same')\n",
        "  bn1a = BatchNormalization()\n",
        "  conv1b = Conv2D(32, (3,3), padding = 'same')\n",
        "  bn1b = BatchNormalization()\n",
        "  conv1c = Conv2D(32, (3,3), padding = 'same')\n",
        "  bn1c = BatchNormalization()\n",
        "  pl1 = MaxPooling2D(2, 2)\n",
        "  MCdrop1 = PermaDropout(0.4)\n",
        "\n",
        "  conv2a = Conv2D(64, (3,3), padding = 'same')\n",
        "  bn2a = BatchNormalization()\n",
        "  conv2b = Conv2D(64, (3,3), padding = 'same')\n",
        "  bn2b = BatchNormalization()\n",
        "  conv2c = Conv2D(64, (3,3), padding = 'same')\n",
        "  bn2c = BatchNormalization()\n",
        "  pl2 = MaxPooling2D(2, 2)\n",
        "  MCdrop2 = PermaDropout(0.4)\n",
        "\n",
        "  conv3a = Conv2D(128, (3,3))\n",
        "  bn3a = BatchNormalization()\n",
        "  conv3b = Conv2D(128, (3,3))\n",
        "  bn3b = BatchNormalization()\n",
        "  conv3c = Conv2D(128, (3,3))\n",
        "  bn3c = BatchNormalization()\n",
        "  pl3 = AveragePooling2D()\n",
        "  MCdrop3 = PermaDropout(0.4)\n",
        "\n",
        "  fc1 = Dense(128)\n",
        "  fc2 = Dense(10)\n",
        "  activ = keras.layers.LeakyReLU(0.1)\n",
        "\n",
        "  model = Sequential([\n",
        "                      keras.Input(shape=(32, 32, 3)), \n",
        "                      tfa.layers.WeightNormalization(conv1a), bn1a, activ,\n",
        "                      tfa.layers.WeightNormalization(conv1b), bn1b, activ,\n",
        "                      tfa.layers.WeightNormalization(conv1c), bn1c, activ,\n",
        "                      pl1, MCdrop1,\n",
        "\n",
        "                      tfa.layers.WeightNormalization(conv2a), bn2a, activ,\n",
        "                      tfa.layers.WeightNormalization(conv2b), bn2b, activ,\n",
        "                      tfa.layers.WeightNormalization(conv2c), bn2c, activ,\n",
        "                      pl2, MCdrop2,\n",
        "\n",
        "                      tfa.layers.WeightNormalization(conv3a), bn3a, activ,\n",
        "                      tfa.layers.WeightNormalization(conv3b), bn3b, activ,\n",
        "                      tfa.layers.WeightNormalization(conv3c), bn3c, activ,\n",
        "                      pl3, MCdrop3, Flatten(),\n",
        "                      \n",
        "                      fc1, activ, fc2\n",
        "                      ])\n",
        "  \n",
        "  return model"
      ],
      "metadata": {
        "id": "9o26bJwvta8-"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "YRCDNliwfudJ"
      },
      "outputs": [],
      "source": [
        "def compile_cnn(model):\n",
        "\n",
        "  if control_lrschedule == 0 :\n",
        "    opt = keras.optimizers.Adam(0.003)\n",
        "  else :\n",
        "    opt = keras.optimizers.Adam(0.001)\n",
        "\n",
        "  model.compile(\n",
        "    optimizer = opt,\n",
        "    loss=keras.losses.CategoricalCrossentropy(from_logits=True),\n",
        "    metrics=['accuracy']\n",
        "  )\n",
        "\n",
        "  return model\n",
        "\n",
        "def cnn_13():\n",
        "\n",
        "  if control_lrschedule == 0:\n",
        "    model = create_cnn_1()\n",
        "  if control_lrschedule == 1:\n",
        "    model = create_cnn_2()\n",
        "  model = compile_cnn(model)\n",
        "\n",
        "  return model\n",
        "\n",
        "def fit_and_labeling_cnn_13(Epoch, Batch):\n",
        "\n",
        "  lr_reducer = ReduceLROnPlateau(monitor='val_loss', factor=0.9, patience=3)\n",
        "  early_stopper = EarlyStopping(monitor='val_loss', min_delta=0, patience=30, mode='auto')\n",
        "  sgdr = SGDR(min_lr=0.0, max_lr=0.03, base_epochs=20) #스케줄러\n",
        "\n",
        "  model.fit(\n",
        "      x=X,\n",
        "      y=y,\n",
        "      epochs=Epoch,\n",
        "      verbose=1,\n",
        "      batch_size=Batch\n",
        "      )\n",
        "    \n",
        "  model_test_eval(model, test_images, test_labels)\n",
        "  T = 1\n",
        "\n",
        "  for predsamples in (range(10)):\n",
        "    if predsamples == 0 :\n",
        "      predictions = np.array(tf.nn.softmax(model.predict(ubl_train_images)/T))\n",
        "      predictions = predictions.reshape((1,) + predictions.shape)\n",
        "    else:\n",
        "      pred = np.array(tf.nn.softmax(model.predict(ubl_train_images)/T))\n",
        "      pred = pred.reshape((1,) + pred.shape)\n",
        "      predictions = np.concatenate((predictions, pred))\n",
        "\n",
        "  return predictions\n",
        "\n",
        "def model_test_eval(model, test_images, test_labels):\n",
        "  T = 1\n",
        "  pred = np.array(tf.nn.softmax(model.predict(test_images)/T))\n",
        "  for i in range(1,10):\n",
        "    pred += np.array(tf.nn.softmax(model.predict(test_images)))\n",
        "  acc = (np.argmax(pred,axis=1) == np.argmax(test_labels,axis=1))*1\n",
        "  acc = sum(acc)/len(acc)\n",
        "  print(\"test set 성능 : \" + str(acc))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "Y72KJdy-evFy"
      },
      "outputs": [],
      "source": [
        "def basic_augmentation(imagearray):\n",
        "  image = Image.fromarray(imagearray)\n",
        "  tr2 = transforms.RandomRotation(10)\n",
        "  tr3 = transforms.ColorJitter(brightness=0.5, contrast=0.5, saturation=0.5, hue=0.5)\n",
        "  image = tr2(tr3(image))\n",
        "  return(np.array(image))\n",
        "\n",
        "def makeaugs(n, input):\n",
        "  augs = []\n",
        "  for j in range(n):\n",
        "    for i in input:\n",
        "      augs.append(basic_augmentation(np.array(i, np.uint8)))\n",
        "  return(np.array(augs))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vz5CFL960tsP",
        "outputId": "fb832cf6-a527-43d1-d9f9-ffd1c8036346"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "< preparation evaluation >\n",
            "Epoch 1/100\n",
            "83/83 [==============================] - 3s 12ms/step - loss: 2.3177 - accuracy: 0.1326\n",
            "Epoch 2/100\n",
            "83/83 [==============================] - 1s 11ms/step - loss: 2.0310 - accuracy: 0.2808\n",
            "Epoch 3/100\n",
            "83/83 [==============================] - 1s 11ms/step - loss: 1.3997 - accuracy: 0.5284\n",
            "Epoch 4/100\n",
            "83/83 [==============================] - 1s 13ms/step - loss: 0.8571 - accuracy: 0.7190\n",
            "Epoch 5/100\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.5595 - accuracy: 0.8223\n",
            "Epoch 6/100\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.4573 - accuracy: 0.8531\n",
            "Epoch 7/100\n",
            "83/83 [==============================] - 1s 10ms/step - loss: 0.3394 - accuracy: 0.8899\n",
            "Epoch 8/100\n",
            "83/83 [==============================] - 1s 10ms/step - loss: 0.3325 - accuracy: 0.8928\n",
            "Epoch 9/100\n",
            "83/83 [==============================] - 1s 10ms/step - loss: 0.1963 - accuracy: 0.9417\n",
            "Epoch 10/100\n",
            "83/83 [==============================] - 1s 11ms/step - loss: 0.2079 - accuracy: 0.9345\n",
            "Epoch 11/100\n",
            "83/83 [==============================] - 1s 11ms/step - loss: 0.2242 - accuracy: 0.9316\n",
            "Epoch 12/100\n",
            "83/83 [==============================] - 1s 10ms/step - loss: 0.1885 - accuracy: 0.9387\n",
            "Epoch 13/100\n",
            "83/83 [==============================] - 1s 11ms/step - loss: 0.3196 - accuracy: 0.9027\n",
            "Epoch 14/100\n",
            "83/83 [==============================] - 1s 10ms/step - loss: 0.1394 - accuracy: 0.9585\n",
            "Epoch 15/100\n",
            "83/83 [==============================] - 1s 11ms/step - loss: 0.0813 - accuracy: 0.9764\n",
            "Epoch 16/100\n",
            "83/83 [==============================] - 1s 11ms/step - loss: 0.1324 - accuracy: 0.9587\n",
            "Epoch 17/100\n",
            "83/83 [==============================] - 1s 11ms/step - loss: 0.0728 - accuracy: 0.9768\n",
            "Epoch 18/100\n",
            "83/83 [==============================] - 1s 11ms/step - loss: 0.0517 - accuracy: 0.9855\n",
            "Epoch 19/100\n",
            "83/83 [==============================] - 1s 11ms/step - loss: 0.1329 - accuracy: 0.9585\n",
            "Epoch 20/100\n",
            "83/83 [==============================] - 1s 10ms/step - loss: 0.0962 - accuracy: 0.9663\n",
            "Epoch 21/100\n",
            "83/83 [==============================] - 1s 11ms/step - loss: 0.0496 - accuracy: 0.9861\n",
            "Epoch 22/100\n",
            "83/83 [==============================] - 1s 11ms/step - loss: 0.1739 - accuracy: 0.9499\n",
            "Epoch 23/100\n",
            "83/83 [==============================] - 1s 11ms/step - loss: 0.1037 - accuracy: 0.9676\n",
            "Epoch 24/100\n",
            "83/83 [==============================] - 1s 11ms/step - loss: 0.1704 - accuracy: 0.9469\n",
            "Epoch 25/100\n",
            "83/83 [==============================] - 1s 11ms/step - loss: 0.0638 - accuracy: 0.9771\n",
            "Epoch 26/100\n",
            "83/83 [==============================] - 1s 10ms/step - loss: 0.0435 - accuracy: 0.9867\n",
            "Epoch 27/100\n",
            "83/83 [==============================] - 1s 11ms/step - loss: 0.1309 - accuracy: 0.9602\n",
            "Epoch 28/100\n",
            "83/83 [==============================] - 1s 11ms/step - loss: 0.0710 - accuracy: 0.9779\n",
            "Epoch 29/100\n",
            "83/83 [==============================] - 1s 11ms/step - loss: 0.0332 - accuracy: 0.9922\n",
            "Epoch 30/100\n",
            "83/83 [==============================] - 1s 10ms/step - loss: 0.0540 - accuracy: 0.9825\n",
            "Epoch 31/100\n",
            "83/83 [==============================] - 1s 11ms/step - loss: 0.1137 - accuracy: 0.9629\n",
            "Epoch 32/100\n",
            "83/83 [==============================] - 1s 11ms/step - loss: 0.0406 - accuracy: 0.9886\n",
            "Epoch 33/100\n",
            "83/83 [==============================] - 1s 11ms/step - loss: 0.0324 - accuracy: 0.9909\n",
            "Epoch 34/100\n",
            "83/83 [==============================] - 1s 10ms/step - loss: 0.0226 - accuracy: 0.9935\n",
            "Epoch 35/100\n",
            "83/83 [==============================] - 1s 11ms/step - loss: 0.1200 - accuracy: 0.9636\n",
            "Epoch 36/100\n",
            "83/83 [==============================] - 1s 11ms/step - loss: 0.0822 - accuracy: 0.9762\n",
            "Epoch 37/100\n",
            "83/83 [==============================] - 1s 11ms/step - loss: 0.0893 - accuracy: 0.9701\n",
            "Epoch 38/100\n",
            "83/83 [==============================] - 1s 11ms/step - loss: 0.0314 - accuracy: 0.9918\n",
            "Epoch 39/100\n",
            "83/83 [==============================] - 1s 11ms/step - loss: 0.1083 - accuracy: 0.9684\n",
            "Epoch 40/100\n",
            "83/83 [==============================] - 1s 11ms/step - loss: 0.1315 - accuracy: 0.9585\n",
            "Epoch 41/100\n",
            "83/83 [==============================] - 1s 11ms/step - loss: 0.0754 - accuracy: 0.9750\n",
            "Epoch 42/100\n",
            "83/83 [==============================] - 1s 11ms/step - loss: 0.0348 - accuracy: 0.9886\n",
            "Epoch 43/100\n",
            "83/83 [==============================] - 1s 11ms/step - loss: 0.0273 - accuracy: 0.9918\n",
            "Epoch 44/100\n",
            "83/83 [==============================] - 1s 11ms/step - loss: 0.0283 - accuracy: 0.9918\n",
            "Epoch 45/100\n",
            "83/83 [==============================] - 1s 11ms/step - loss: 0.1171 - accuracy: 0.9630\n",
            "Epoch 46/100\n",
            "83/83 [==============================] - 1s 10ms/step - loss: 0.0818 - accuracy: 0.9724\n",
            "Epoch 47/100\n",
            "83/83 [==============================] - 1s 11ms/step - loss: 0.0652 - accuracy: 0.9804\n",
            "Epoch 48/100\n",
            "83/83 [==============================] - 1s 11ms/step - loss: 0.0991 - accuracy: 0.9730\n",
            "Epoch 49/100\n",
            "83/83 [==============================] - 1s 11ms/step - loss: 0.0825 - accuracy: 0.9741\n",
            "Epoch 50/100\n",
            "83/83 [==============================] - 1s 11ms/step - loss: 0.0774 - accuracy: 0.9766\n",
            "Epoch 51/100\n",
            "83/83 [==============================] - 1s 10ms/step - loss: 0.0321 - accuracy: 0.9901\n",
            "Epoch 52/100\n",
            "83/83 [==============================] - 1s 11ms/step - loss: 0.0872 - accuracy: 0.9733\n",
            "Epoch 53/100\n",
            "83/83 [==============================] - 1s 11ms/step - loss: 0.0328 - accuracy: 0.9903\n",
            "Epoch 54/100\n",
            "83/83 [==============================] - 1s 11ms/step - loss: 0.0370 - accuracy: 0.9890\n",
            "Epoch 55/100\n",
            "83/83 [==============================] - 1s 11ms/step - loss: 0.0203 - accuracy: 0.9933\n",
            "Epoch 56/100\n",
            "83/83 [==============================] - 1s 10ms/step - loss: 0.0252 - accuracy: 0.9930\n",
            "Epoch 57/100\n",
            "83/83 [==============================] - 1s 11ms/step - loss: 0.0309 - accuracy: 0.9912\n",
            "Epoch 58/100\n",
            "83/83 [==============================] - 1s 11ms/step - loss: 0.0792 - accuracy: 0.9747\n",
            "Epoch 59/100\n",
            "83/83 [==============================] - 1s 11ms/step - loss: 0.0708 - accuracy: 0.9781\n",
            "Epoch 60/100\n",
            "83/83 [==============================] - 1s 11ms/step - loss: 0.0244 - accuracy: 0.9931\n",
            "Epoch 61/100\n",
            "83/83 [==============================] - 1s 11ms/step - loss: 0.0914 - accuracy: 0.9731\n",
            "Epoch 62/100\n",
            "83/83 [==============================] - 1s 11ms/step - loss: 0.0666 - accuracy: 0.9785\n",
            "Epoch 63/100\n",
            "83/83 [==============================] - 1s 11ms/step - loss: 0.0472 - accuracy: 0.9850\n",
            "Epoch 64/100\n",
            "83/83 [==============================] - 1s 11ms/step - loss: 0.0989 - accuracy: 0.9676\n",
            "Epoch 65/100\n",
            "83/83 [==============================] - 1s 11ms/step - loss: 0.0509 - accuracy: 0.9846\n",
            "Epoch 66/100\n",
            "83/83 [==============================] - 1s 11ms/step - loss: 0.0206 - accuracy: 0.9939\n",
            "Epoch 67/100\n",
            "83/83 [==============================] - 1s 11ms/step - loss: 0.0146 - accuracy: 0.9971\n",
            "Epoch 68/100\n",
            "83/83 [==============================] - 1s 11ms/step - loss: 0.0328 - accuracy: 0.9895\n",
            "Epoch 69/100\n",
            "83/83 [==============================] - 1s 11ms/step - loss: 0.0382 - accuracy: 0.9884\n",
            "Epoch 70/100\n",
            "83/83 [==============================] - 1s 11ms/step - loss: 0.0604 - accuracy: 0.9813\n",
            "Epoch 71/100\n",
            "83/83 [==============================] - 1s 11ms/step - loss: 0.0546 - accuracy: 0.9823\n",
            "Epoch 72/100\n",
            "83/83 [==============================] - 1s 11ms/step - loss: 0.0319 - accuracy: 0.9891\n",
            "Epoch 73/100\n",
            "83/83 [==============================] - 1s 11ms/step - loss: 0.0135 - accuracy: 0.9970\n",
            "Epoch 74/100\n",
            "83/83 [==============================] - 1s 11ms/step - loss: 0.0142 - accuracy: 0.9956\n",
            "Epoch 75/100\n",
            "83/83 [==============================] - 1s 11ms/step - loss: 0.0177 - accuracy: 0.9958\n",
            "Epoch 76/100\n",
            "83/83 [==============================] - 1s 11ms/step - loss: 0.0556 - accuracy: 0.9819\n",
            "Epoch 77/100\n",
            "83/83 [==============================] - 1s 11ms/step - loss: 0.0284 - accuracy: 0.9916\n",
            "Epoch 78/100\n",
            "83/83 [==============================] - 1s 11ms/step - loss: 0.0578 - accuracy: 0.9829\n",
            "Epoch 79/100\n",
            "83/83 [==============================] - 1s 11ms/step - loss: 0.1143 - accuracy: 0.9659\n",
            "Epoch 80/100\n",
            "83/83 [==============================] - 1s 11ms/step - loss: 0.0719 - accuracy: 0.9770\n",
            "Epoch 81/100\n",
            "83/83 [==============================] - 1s 11ms/step - loss: 0.0233 - accuracy: 0.9930\n",
            "Epoch 82/100\n",
            "83/83 [==============================] - 1s 11ms/step - loss: 0.0207 - accuracy: 0.9945\n",
            "Epoch 83/100\n",
            "83/83 [==============================] - 1s 11ms/step - loss: 0.0122 - accuracy: 0.9968\n",
            "Epoch 84/100\n",
            "83/83 [==============================] - 1s 11ms/step - loss: 0.0633 - accuracy: 0.9813\n",
            "Epoch 85/100\n",
            "83/83 [==============================] - 1s 11ms/step - loss: 0.0815 - accuracy: 0.9773\n",
            "Epoch 86/100\n",
            "83/83 [==============================] - 1s 11ms/step - loss: 0.0451 - accuracy: 0.9874\n",
            "Epoch 87/100\n",
            "83/83 [==============================] - 1s 11ms/step - loss: 0.0461 - accuracy: 0.9844\n",
            "Epoch 88/100\n",
            "83/83 [==============================] - 1s 11ms/step - loss: 0.0679 - accuracy: 0.9823\n",
            "Epoch 89/100\n",
            "83/83 [==============================] - 1s 11ms/step - loss: 0.0202 - accuracy: 0.9943\n",
            "Epoch 90/100\n",
            "83/83 [==============================] - 1s 11ms/step - loss: 0.0206 - accuracy: 0.9949\n",
            "Epoch 91/100\n",
            "83/83 [==============================] - 1s 11ms/step - loss: 0.0336 - accuracy: 0.9884\n",
            "Epoch 92/100\n",
            "83/83 [==============================] - 1s 11ms/step - loss: 0.0328 - accuracy: 0.9901\n",
            "Epoch 93/100\n",
            "83/83 [==============================] - 1s 11ms/step - loss: 0.0142 - accuracy: 0.9962\n",
            "Epoch 94/100\n",
            "83/83 [==============================] - 1s 11ms/step - loss: 0.0097 - accuracy: 0.9979\n",
            "Epoch 95/100\n",
            "83/83 [==============================] - 1s 11ms/step - loss: 0.0156 - accuracy: 0.9964\n",
            "Epoch 96/100\n",
            "83/83 [==============================] - 1s 11ms/step - loss: 0.0128 - accuracy: 0.9964\n",
            "Epoch 97/100\n",
            "83/83 [==============================] - 1s 11ms/step - loss: 0.0102 - accuracy: 0.9975\n",
            "Epoch 98/100\n",
            "83/83 [==============================] - 1s 11ms/step - loss: 0.0440 - accuracy: 0.9870\n",
            "Epoch 99/100\n",
            "83/83 [==============================] - 1s 11ms/step - loss: 0.0482 - accuracy: 0.9836\n",
            "Epoch 100/100\n",
            "83/83 [==============================] - 1s 11ms/step - loss: 0.0181 - accuracy: 0.9956\n",
            "test set 성능 : 0.6992547633681623\n",
            "296.2423071861267\n"
          ]
        }
      ],
      "source": [
        "first = time.time()\n",
        "control_lrschedule = 0\n",
        "model = cnn_13()\n",
        "X = lbl_train_images\n",
        "y = lbl_train_labels\n",
        "\n",
        "X = np.concatenate([makeaugs(20, X), X])\n",
        "y = np.concatenate([y,y,y,y,y,\n",
        "                    y,y,y,y,y,\n",
        "                    y,y,y,y,y,\n",
        "                    y,y,y,y,y, y])\n",
        "\n",
        "print(\"< preparation evaluation >\")\n",
        "predictions = fit_and_labeling_cnn_13(100, 64)\n",
        "print(time.time() - first)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w4F_8DJWevFz",
        "outputId": "cf8407da-7d23-4ec8-b1c1-3f0cf3ac47a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "< iter 0 evaluation >\n",
            "Epoch 1/25\n",
            "4692/4692 [==============================] - 75s 15ms/step - loss: 0.1199 - accuracy: 0.9616\n",
            "Epoch 2/25\n",
            "4692/4692 [==============================] - 71s 15ms/step - loss: 0.0355 - accuracy: 0.9887\n",
            "Epoch 3/25\n",
            "4692/4692 [==============================] - 71s 15ms/step - loss: 0.0273 - accuracy: 0.9912\n",
            "Epoch 4/25\n",
            "4692/4692 [==============================] - 71s 15ms/step - loss: 0.0219 - accuracy: 0.9930\n",
            "Epoch 5/25\n",
            "4692/4692 [==============================] - 71s 15ms/step - loss: 0.0181 - accuracy: 0.9941\n",
            "Epoch 6/25\n",
            "4692/4692 [==============================] - 70s 15ms/step - loss: 0.0168 - accuracy: 0.9946\n",
            "Epoch 7/25\n",
            "4692/4692 [==============================] - 70s 15ms/step - loss: 0.0145 - accuracy: 0.9953\n",
            "Epoch 8/25\n",
            "4692/4692 [==============================] - 71s 15ms/step - loss: 0.0126 - accuracy: 0.9959\n",
            "Epoch 9/25\n",
            "4692/4692 [==============================] - 70s 15ms/step - loss: 0.0120 - accuracy: 0.9961\n",
            "Epoch 10/25\n",
            "4692/4692 [==============================] - 70s 15ms/step - loss: 0.0110 - accuracy: 0.9964\n",
            "Epoch 11/25\n",
            "4692/4692 [==============================] - 71s 15ms/step - loss: 0.0104 - accuracy: 0.9966\n",
            "Epoch 12/25\n",
            "4692/4692 [==============================] - 72s 15ms/step - loss: 0.0098 - accuracy: 0.9968\n",
            "Epoch 13/25\n",
            "4692/4692 [==============================] - 70s 15ms/step - loss: 0.0089 - accuracy: 0.9971\n",
            "Epoch 14/25\n",
            "4692/4692 [==============================] - 70s 15ms/step - loss: 0.0089 - accuracy: 0.9970\n",
            "Epoch 15/25\n",
            "4692/4692 [==============================] - 71s 15ms/step - loss: 0.0081 - accuracy: 0.9974\n",
            "Epoch 16/25\n",
            "4692/4692 [==============================] - 70s 15ms/step - loss: 0.0077 - accuracy: 0.9974\n",
            "Epoch 17/25\n",
            "4692/4692 [==============================] - 71s 15ms/step - loss: 0.0073 - accuracy: 0.9976\n",
            "Epoch 18/25\n",
            "4692/4692 [==============================] - 71s 15ms/step - loss: 0.0071 - accuracy: 0.9977\n",
            "Epoch 19/25\n",
            "4692/4692 [==============================] - 72s 15ms/step - loss: 0.0065 - accuracy: 0.9978\n",
            "Epoch 20/25\n",
            "4692/4692 [==============================] - 71s 15ms/step - loss: 0.0065 - accuracy: 0.9979\n",
            "Epoch 21/25\n",
            "4692/4692 [==============================] - 71s 15ms/step - loss: 0.0063 - accuracy: 0.9980\n",
            "Epoch 22/25\n",
            "4692/4692 [==============================] - 71s 15ms/step - loss: 0.0057 - accuracy: 0.9981\n",
            "Epoch 23/25\n",
            "4692/4692 [==============================] - 70s 15ms/step - loss: 0.0059 - accuracy: 0.9980\n",
            "Epoch 24/25\n",
            "4692/4692 [==============================] - 70s 15ms/step - loss: 0.0058 - accuracy: 0.9981\n",
            "Epoch 25/25\n",
            "4692/4692 [==============================] - 71s 15ms/step - loss: 0.0054 - accuracy: 0.9981\n",
            "test set 성능 : 0.7658650891210818\n",
            "2940.08345079422\n",
            "< iter 1 evaluation >\n",
            "Epoch 1/10\n",
            "4692/4692 [==============================] - 72s 15ms/step - loss: 0.0373 - accuracy: 0.9880\n",
            "Epoch 2/10\n",
            "4692/4692 [==============================] - 71s 15ms/step - loss: 0.0288 - accuracy: 0.9906\n",
            "Epoch 3/10\n",
            "4692/4692 [==============================] - 71s 15ms/step - loss: 0.0259 - accuracy: 0.9916\n",
            "Epoch 4/10\n",
            "4692/4692 [==============================] - 71s 15ms/step - loss: 0.0239 - accuracy: 0.9923\n",
            "Epoch 5/10\n",
            "4692/4692 [==============================] - 72s 15ms/step - loss: 0.0223 - accuracy: 0.9925\n",
            "Epoch 6/10\n",
            "4692/4692 [==============================] - 71s 15ms/step - loss: 0.0205 - accuracy: 0.9934\n",
            "Epoch 7/10\n",
            "4692/4692 [==============================] - 70s 15ms/step - loss: 0.0194 - accuracy: 0.9937\n",
            "Epoch 8/10\n",
            "4692/4692 [==============================] - 70s 15ms/step - loss: 0.0184 - accuracy: 0.9939\n",
            "Epoch 9/10\n",
            "4692/4692 [==============================] - 70s 15ms/step - loss: 0.0180 - accuracy: 0.9940\n",
            "Epoch 10/10\n",
            "4692/4692 [==============================] - 71s 15ms/step - loss: 0.0169 - accuracy: 0.9942\n",
            "test set 성능 : 0.789681929932391\n",
            "4125.175510168076\n",
            "< iter 2 evaluation >\n",
            "Epoch 1/10\n",
            "4692/4692 [==============================] - 71s 15ms/step - loss: 0.0285 - accuracy: 0.9909\n",
            "Epoch 2/10\n",
            "4692/4692 [==============================] - 71s 15ms/step - loss: 0.0247 - accuracy: 0.9917\n",
            "Epoch 3/10\n",
            "4692/4692 [==============================] - 71s 15ms/step - loss: 0.0229 - accuracy: 0.9924\n",
            "Epoch 4/10\n",
            "4692/4692 [==============================] - 73s 16ms/step - loss: 0.0211 - accuracy: 0.9930\n",
            "Epoch 5/10\n",
            "4692/4692 [==============================] - 72s 15ms/step - loss: 0.0206 - accuracy: 0.9933\n",
            "Epoch 6/10\n",
            "4692/4692 [==============================] - 71s 15ms/step - loss: 0.0193 - accuracy: 0.9936\n",
            "Epoch 7/10\n",
            "4692/4692 [==============================] - 71s 15ms/step - loss: 0.0179 - accuracy: 0.9939\n",
            "Epoch 8/10\n",
            "4692/4692 [==============================] - 71s 15ms/step - loss: 0.0181 - accuracy: 0.9939\n",
            "Epoch 9/10\n",
            "4692/4692 [==============================] - 71s 15ms/step - loss: 0.0168 - accuracy: 0.9944\n",
            "Epoch 10/10\n",
            "4692/4692 [==============================] - 70s 15ms/step - loss: 0.0164 - accuracy: 0.9945\n",
            "test set 성능 : 0.7924861708666256\n",
            "5291.832659244537\n",
            "< iter 3 evaluation >\n",
            "Epoch 1/10\n",
            "4692/4692 [==============================] - 71s 15ms/step - loss: 0.0264 - accuracy: 0.9914\n",
            "Epoch 2/10\n",
            "4692/4692 [==============================] - 71s 15ms/step - loss: 0.0232 - accuracy: 0.9923\n",
            "Epoch 3/10\n",
            "4692/4692 [==============================] - 70s 15ms/step - loss: 0.0210 - accuracy: 0.9931\n",
            "Epoch 4/10\n",
            "4692/4692 [==============================] - 70s 15ms/step - loss: 0.0197 - accuracy: 0.9934\n",
            "Epoch 5/10\n",
            "4692/4692 [==============================] - 70s 15ms/step - loss: 0.0189 - accuracy: 0.9936\n",
            "Epoch 6/10\n",
            "4692/4692 [==============================] - 70s 15ms/step - loss: 0.0179 - accuracy: 0.9940\n",
            "Epoch 7/10\n",
            "4692/4692 [==============================] - 71s 15ms/step - loss: 0.0166 - accuracy: 0.9943\n",
            "Epoch 8/10\n",
            "4692/4692 [==============================] - 72s 15ms/step - loss: 0.0166 - accuracy: 0.9944\n",
            "Epoch 9/10\n",
            "4692/4692 [==============================] - 72s 15ms/step - loss: 0.0160 - accuracy: 0.9948\n",
            "Epoch 10/10\n",
            "4692/4692 [==============================] - 71s 15ms/step - loss: 0.0159 - accuracy: 0.9948\n",
            "test set 성능 : 0.8047787338660111\n",
            "6471.131722450256\n",
            "< iter 4 evaluation >\n",
            "Epoch 1/10\n",
            "4692/4692 [==============================] - 71s 15ms/step - loss: 0.0246 - accuracy: 0.9920\n",
            "Epoch 2/10\n",
            "4692/4692 [==============================] - 71s 15ms/step - loss: 0.0217 - accuracy: 0.9927\n",
            "Epoch 3/10\n",
            "4692/4692 [==============================] - 71s 15ms/step - loss: 0.0199 - accuracy: 0.9934\n",
            "Epoch 4/10\n",
            "4692/4692 [==============================] - 71s 15ms/step - loss: 0.0185 - accuracy: 0.9938\n",
            "Epoch 5/10\n",
            "4692/4692 [==============================] - 71s 15ms/step - loss: 0.0179 - accuracy: 0.9941\n",
            "Epoch 6/10\n",
            "4692/4692 [==============================] - 70s 15ms/step - loss: 0.0169 - accuracy: 0.9945\n",
            "Epoch 7/10\n",
            "4692/4692 [==============================] - 70s 15ms/step - loss: 0.0164 - accuracy: 0.9946\n",
            "Epoch 8/10\n",
            "4692/4692 [==============================] - 71s 15ms/step - loss: 0.0157 - accuracy: 0.9946\n",
            "Epoch 9/10\n",
            "4692/4692 [==============================] - 70s 15ms/step - loss: 0.0156 - accuracy: 0.9947\n",
            "Epoch 10/10\n",
            "4692/4692 [==============================] - 70s 15ms/step - loss: 0.0149 - accuracy: 0.9950\n",
            "test set 성능 : 0.8151505838967424\n",
            "7645.741042375565\n",
            "< iter 5 evaluation >\n",
            "Epoch 1/10\n",
            "4692/4692 [==============================] - 72s 15ms/step - loss: 0.0290 - accuracy: 0.9904\n",
            "Epoch 2/10\n",
            "4692/4692 [==============================] - 70s 15ms/step - loss: 0.0249 - accuracy: 0.9916\n",
            "Epoch 3/10\n",
            "4692/4692 [==============================] - 71s 15ms/step - loss: 0.0227 - accuracy: 0.9924\n",
            "Epoch 4/10\n",
            "4692/4692 [==============================] - 71s 15ms/step - loss: 0.0219 - accuracy: 0.9927\n",
            "Epoch 5/10\n",
            "4692/4692 [==============================] - 71s 15ms/step - loss: 0.0212 - accuracy: 0.9929\n",
            "Epoch 6/10\n",
            "4692/4692 [==============================] - 71s 15ms/step - loss: 0.0196 - accuracy: 0.9934\n",
            "Epoch 7/10\n",
            "4692/4692 [==============================] - 71s 15ms/step - loss: 0.0191 - accuracy: 0.9936\n",
            "Epoch 8/10\n",
            "4692/4692 [==============================] - 70s 15ms/step - loss: 0.0184 - accuracy: 0.9938\n",
            "Epoch 9/10\n",
            "4692/4692 [==============================] - 70s 15ms/step - loss: 0.0179 - accuracy: 0.9939\n",
            "Epoch 10/10\n",
            "4692/4692 [==============================] - 71s 15ms/step - loss: 0.0173 - accuracy: 0.9942\n",
            "test set 성능 : 0.818799938537185\n",
            "8839.227120637894\n",
            "< iter 6 evaluation >\n",
            "Epoch 1/10\n",
            "4692/4692 [==============================] - 72s 15ms/step - loss: 0.0268 - accuracy: 0.9912\n",
            "Epoch 2/10\n",
            "4692/4692 [==============================] - 71s 15ms/step - loss: 0.0239 - accuracy: 0.9920\n",
            "Epoch 3/10\n",
            "4692/4692 [==============================] - 71s 15ms/step - loss: 0.0221 - accuracy: 0.9925\n",
            "Epoch 4/10\n",
            "4692/4692 [==============================] - 71s 15ms/step - loss: 0.0207 - accuracy: 0.9930\n",
            "Epoch 5/10\n",
            "4692/4692 [==============================] - 71s 15ms/step - loss: 0.0198 - accuracy: 0.9932\n",
            "Epoch 6/10\n",
            "4692/4692 [==============================] - 71s 15ms/step - loss: 0.0186 - accuracy: 0.9938\n",
            "Epoch 7/10\n",
            "4692/4692 [==============================] - 71s 15ms/step - loss: 0.0180 - accuracy: 0.9938\n",
            "Epoch 8/10\n",
            "4692/4692 [==============================] - 71s 15ms/step - loss: 0.0176 - accuracy: 0.9940\n",
            "Epoch 9/10\n",
            "4692/4692 [==============================] - 71s 15ms/step - loss: 0.0171 - accuracy: 0.9941\n",
            "Epoch 10/10\n",
            "4692/4692 [==============================] - 71s 15ms/step - loss: 0.0166 - accuracy: 0.9941\n",
            "test set 성능 : 0.8214121081745543\n",
            "9986.223907709122\n",
            "< iter 7 evaluation >\n",
            "Epoch 1/10\n",
            "4692/4692 [==============================] - 71s 15ms/step - loss: 0.0266 - accuracy: 0.9910\n",
            "Epoch 2/10\n",
            "4692/4692 [==============================] - 71s 15ms/step - loss: 0.0227 - accuracy: 0.9921\n",
            "Epoch 3/10\n",
            "4692/4692 [==============================] - 72s 15ms/step - loss: 0.0212 - accuracy: 0.9927\n",
            "Epoch 4/10\n",
            "4692/4692 [==============================] - 71s 15ms/step - loss: 0.0201 - accuracy: 0.9931\n",
            "Epoch 5/10\n",
            "4692/4692 [==============================] - 71s 15ms/step - loss: 0.0193 - accuracy: 0.9934\n",
            "Epoch 6/10\n",
            "4692/4692 [==============================] - 71s 15ms/step - loss: 0.0179 - accuracy: 0.9939\n",
            "Epoch 7/10\n",
            "4692/4692 [==============================] - 72s 15ms/step - loss: 0.0180 - accuracy: 0.9939\n",
            "Epoch 8/10\n",
            "4692/4692 [==============================] - 70s 15ms/step - loss: 0.0172 - accuracy: 0.9941\n",
            "Epoch 9/10\n",
            "4692/4692 [==============================] - 70s 15ms/step - loss: 0.0161 - accuracy: 0.9946\n",
            "Epoch 10/10\n",
            "4692/4692 [==============================] - 70s 15ms/step - loss: 0.0158 - accuracy: 0.9946\n",
            "test set 성능 : 0.8259834050399508\n",
            "11180.394757509232\n",
            "< iter 8 evaluation >\n",
            "Epoch 1/10\n",
            "4692/4692 [==============================] - 72s 15ms/step - loss: 0.0258 - accuracy: 0.9915\n",
            "Epoch 2/10\n",
            "4692/4692 [==============================] - 71s 15ms/step - loss: 0.0227 - accuracy: 0.9924\n",
            "Epoch 3/10\n",
            "4692/4692 [==============================] - 71s 15ms/step - loss: 0.0215 - accuracy: 0.9927\n",
            "Epoch 4/10\n",
            "4692/4692 [==============================] - 71s 15ms/step - loss: 0.0196 - accuracy: 0.9934\n",
            "Epoch 5/10\n",
            "4692/4692 [==============================] - 72s 15ms/step - loss: 0.0189 - accuracy: 0.9936\n",
            "Epoch 6/10\n",
            "4692/4692 [==============================] - 71s 15ms/step - loss: 0.0182 - accuracy: 0.9939\n",
            "Epoch 7/10\n",
            "4692/4692 [==============================] - 70s 15ms/step - loss: 0.0183 - accuracy: 0.9937\n",
            "Epoch 8/10\n",
            "4692/4692 [==============================] - 70s 15ms/step - loss: 0.0164 - accuracy: 0.9944\n",
            "Epoch 9/10\n",
            "4692/4692 [==============================] - 71s 15ms/step - loss: 0.0165 - accuracy: 0.9943\n",
            "Epoch 10/10\n",
            "4692/4692 [==============================] - 71s 15ms/step - loss: 0.0165 - accuracy: 0.9944\n",
            "test set 성능 : 0.8239090350338045\n",
            "12369.08213877678\n",
            "< iter 9 evaluation >\n",
            "Epoch 1/10\n",
            "4692/4692 [==============================] - 72s 15ms/step - loss: 0.0242 - accuracy: 0.9919\n",
            "Epoch 2/10\n",
            "4692/4692 [==============================] - 71s 15ms/step - loss: 0.0207 - accuracy: 0.9930\n",
            "Epoch 3/10\n",
            "4692/4692 [==============================] - 71s 15ms/step - loss: 0.0200 - accuracy: 0.9933\n",
            "Epoch 4/10\n",
            "4692/4692 [==============================] - 72s 15ms/step - loss: 0.0190 - accuracy: 0.9934\n",
            "Epoch 5/10\n",
            "4692/4692 [==============================] - 70s 15ms/step - loss: 0.0179 - accuracy: 0.9938\n",
            "Epoch 6/10\n",
            "4692/4692 [==============================] - 71s 15ms/step - loss: 0.0179 - accuracy: 0.9938\n",
            "Epoch 7/10\n",
            "4692/4692 [==============================] - 71s 15ms/step - loss: 0.0167 - accuracy: 0.9943\n",
            "Epoch 8/10\n",
            "4692/4692 [==============================] - 72s 15ms/step - loss: 0.0164 - accuracy: 0.9943\n",
            "Epoch 9/10\n",
            "4692/4692 [==============================] - 71s 15ms/step - loss: 0.0157 - accuracy: 0.9947\n",
            "Epoch 10/10\n",
            "4692/4692 [==============================] - 71s 15ms/step - loss: 0.0156 - accuracy: 0.9947\n",
            "test set 성능 : 0.8325906576521205\n",
            "13576.20222902298\n",
            "< iter 10 evaluation >\n",
            "Epoch 1/10\n",
            "4692/4692 [==============================] - 71s 15ms/step - loss: 0.0313 - accuracy: 0.9896\n",
            "Epoch 2/10\n",
            "4692/4692 [==============================] - 71s 15ms/step - loss: 0.0262 - accuracy: 0.9912\n",
            "Epoch 3/10\n",
            "4692/4692 [==============================] - 73s 15ms/step - loss: 0.0254 - accuracy: 0.9913\n",
            "Epoch 4/10\n",
            "4692/4692 [==============================] - 71s 15ms/step - loss: 0.0229 - accuracy: 0.9922\n",
            "Epoch 5/10\n",
            "4692/4692 [==============================] - 72s 15ms/step - loss: 0.0229 - accuracy: 0.9923\n",
            "Epoch 6/10\n",
            "4692/4692 [==============================] - 72s 15ms/step - loss: 0.0212 - accuracy: 0.9927\n",
            "Epoch 7/10\n",
            "4692/4692 [==============================] - 72s 15ms/step - loss: 0.0210 - accuracy: 0.9929\n",
            "Epoch 8/10\n",
            "4692/4692 [==============================] - 71s 15ms/step - loss: 0.0199 - accuracy: 0.9930\n",
            "Epoch 9/10\n",
            "4692/4692 [==============================] - 71s 15ms/step - loss: 0.0194 - accuracy: 0.9933\n",
            "Epoch 10/10\n",
            "4692/4692 [==============================] - 71s 15ms/step - loss: 0.0193 - accuracy: 0.9935\n",
            "test set 성능 : 0.8327443146896127\n",
            "14765.94449186325\n",
            "< iter 11 evaluation >\n",
            "Epoch 1/10\n",
            "4692/4692 [==============================] - 72s 15ms/step - loss: 0.0297 - accuracy: 0.9900\n",
            "Epoch 2/10\n",
            "4692/4692 [==============================] - 72s 15ms/step - loss: 0.0261 - accuracy: 0.9914\n",
            "Epoch 3/10\n",
            "4692/4692 [==============================] - 73s 15ms/step - loss: 0.0249 - accuracy: 0.9917\n",
            "Epoch 4/10\n",
            "2601/4692 [===============>..............] - ETA: 32s - loss: 0.0229 - accuracy: 0.9920"
          ]
        }
      ],
      "source": [
        "schedule = list(2**np.array(list(range(5)))/(2**5))\n",
        "schedule = [[i,i,i,i,i] for i in schedule]\n",
        "schedule = np.array(schedule).reshape([-1])\n",
        "\n",
        "alpha = 0.6\n",
        "control_lrschedule = 1\n",
        "\n",
        "model = cnn_13()\n",
        "epoch = 25\n",
        "\n",
        "for iter in range(len(schedule)):\n",
        "    pseudo = np.argmax(np.mean(predictions, axis=0), axis=1)\n",
        "    conf = np.max(np.mean(predictions, axis=0), axis=1)\n",
        "    uncert = np.std(predictions, axis=0)\n",
        "    uncert = np.array([uncert[i][pseudo[i]] for i in range(len(pseudo))])\n",
        "    cert = 1-uncert\n",
        "    \n",
        "    ubl_pseudo_labels = []\n",
        "    for i in pseudo:\n",
        "        temp = [0,0,0,0,0,0,0,0,0,0]\n",
        "        temp[i] = 1\n",
        "        ubl_pseudo_labels.append(temp)\n",
        "    ubl_pseudo_labels = np.array(ubl_pseudo_labels)\n",
        "\n",
        "    score = alpha*conf + (1-alpha)*cert\n",
        "    score = (score-min(score))/(max(score)-min(score))+0.0001\n",
        "    score = np.exp(score/schedule[iter])\n",
        "    score = score/sum(score)\n",
        "\n",
        "    indx = np.random.choice(len(score), 300000, p = score)\n",
        "\n",
        "    X = ubl_train_images[indx]\n",
        "    y = ubl_pseudo_labels[indx]\n",
        "\n",
        "    X = np.concatenate([lbl_train_images, X])\n",
        "    y = np.concatenate([lbl_train_labels, y])\n",
        "\n",
        "    augimage = makeaugs(1, X)\n",
        "    X = augimage\n",
        "\n",
        "    print(\"< iter \"+str(iter)+\" evaluation >\")\n",
        "    predictions = fit_and_labeling_cnn_13(epoch, 64)\n",
        "    print(time.time() - first)\n",
        "    \n",
        "    epoch = 10\n",
        "    del augimage, X, y\n",
        "    gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Pw61myYSit7W"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Keras_UncertaintyBootstrap_SVHN.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}